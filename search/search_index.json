{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Amazon MSK Train-The-Trainer Workshop","text":"<p>This workshop contains exercises for the 2-day Amazon MSK Workshop Training.</p>"},{"location":"#exercises","title":"Exercises","text":""},{"location":"#day-1","title":"Day-1","text":""},{"location":"#overview","title":"Overview","text":"<ol> <li>Custom configuration</li> <li>Cluster</li> <li>Architecture </li> </ol>"},{"location":"#prerequisites","title":"Prerequisites","text":"<ol> <li>Choose Region</li> <li>Create an MSK security group</li> </ol>"},{"location":"#part-1-kafka-overview-amazon-msk-cluster-creation","title":"Part 1 - Kafka overview &amp; Amazon MSK Cluster Creation","text":"<ol> <li>Launching MSK cluster (Provisoned) (Console)</li> <li>Launching MSK cluster (Provisoned) (CLI)</li> </ol>"},{"location":"#day-2","title":"Day-2","text":""},{"location":"setup/","title":"Setup","text":"<p>Perform the following steps to login to the event engine.</p> <ol> <li>Type Event Engine URL on to your browser. (Right click this link -&gt; Open in new tab).</li> <li>Enter the hash provided to you. Accept Terms &amp; Login. </li> <li>Choose \u201cEmail One-Time Password\u201d. Provide your email ID where your 9-digit OTP will be sent within 5 mins. </li> <li>Once you receive OTP over your email, enter it to sign in to the Team Dashboard.  </li> <li>Click on the SSH Key and download the key to your local desktop. Click Ok once done. </li> <li>Click on AWS Console and Open AWS Console. You can also retrieve AWS_DEFAULT_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_SESSION_TOKEN from this Team Dashboard whenever required for your exercises. </li> <li>Make a note of your account ID in the top right corner of the AWS Console and store it in a notepad. </li> <li>Go to CloudFormation and verify that the Cloudformation templates \"msk-labs-default\", \"msk-labs-default-MSKVPCStack-xxxxxxxxx\" and \"aws-cloud9-msk-labs-default-Cloud9EC2Bastion-xxxxxxxx\" are created.</li> </ol> <p></p>"},{"location":"day1/part1/1_provisoned/exercise/","title":"Launching an MSK cluster (Console)","text":"<p>This exercise is meant to show you different options and features available while trying to create an MSK cluster. MSK clusters required are already created in your event engine accounts which we will use for our exercises.</p>"},{"location":"day1/part1/1_provisoned/exercise/#create-msk-cluster-console","title":"Create MSK Cluster (Console)","text":"<p>Go to the MSK Landing Page (Right click -&gt; Open Link in New Tab).</p>"},{"location":"day1/part1/1_provisoned/exercise/#cluster-settings","title":"Cluster Settings","text":"<ol> <li>Sign-in to the AWS Console in the account you want to create your cluster in</li> <li>Browse to the MSK create cluster wizard  to start the creation</li> <li>Select Custom create for the Creation method</li> <li>Enter the cluster name - MSKWorkshopCluster</li> <li>In Cluster type, Choose the option Provisioned</li> <li>Select the version of Kafka you want to run on the cluster (ex: 2.8.1) </li> </ol>"},{"location":"day1/part1/1_provisoned/exercise/#brokers","title":"Brokers","text":"<ol> <li>Select kafka.m5.large as the Broker Instance Type</li> <li>Select the number of zones (availability zones) you want to deploy in to 3</li> <li>Enter 1 for the number of brokers per zone</li> </ol> <p>(Your cluster will have 3 total brokers, distributed evenly across your 3 Availability Zones.)</p> <p></p>"},{"location":"day1/part1/1_provisoned/exercise/#storage","title":"Storage","text":"<ol> <li>Enter 100 GiB</li> <li>Leave others options as default</li> </ol>"},{"location":"day1/part1/1_provisoned/exercise/#configuration-section","title":"Configuration Section","text":"<p>We are going to create a custom configuration that the cluster will run. We will enable the following features:</p> <p>auto.create.topics.enable - allow topics to be created automatically by producers and consumers. This is not typically enabled in a production cluster, but it is handy for development and testing to lower the operational overhead</p> <p>delete.topic.enable - enables topic deletion on the server. If topic deletion is not enabled, you cannot delete topics. You likely want to turn this on on all clusters you build unless you have a specific need not to.</p> <p>log.retention.hours - we will set this to 8 hours for the lab. Note that this is the default configuration, it can still be overridden at the topic level </p>"},{"location":"day1/part1/1_provisoned/exercise/#create-configuration-object","title":"Create Configuration Object","text":"<ol> <li>Select Custom configuration for the Cluster configuration</li> <li>Click on Create configuration  </li> <li>Give your configuration a name - MSK-workshop</li> <li>Add a description for the config - MSK workshop - Auto topic creation; topic deletion; 8hrs retention</li> <li>Under Configuration Properties, ensure the following options are set/overridden - you can leave the Version as None <p>auto.create.topics.enable=true</p> <p>delete.topic.enable=true</p> <p>log.retention.hours=8</p> </li> </ol> <p> 6. Click Create - this will take you to the Cluster Configurations page. You can close this browser tab now   7. Back in the Cluster Creation workflow, you can hit the refresh icon beside the cluster configuration box (the circle icon) then select the configuration you created  </p>"},{"location":"day1/part1/1_provisoned/exercise/#networking","title":"Networking","text":"<ol> <li>Select the VPC you want to deploy your cluster in (MSKVPC if you created the VPC using our provided CloudFormation)</li> <li>Select us-east-1a for the first Availability Zone (AZ), then the subnet (PrivateSubnetMSKOne)</li> <li>Select us-east-1b for the second AZ, and the appropriate subnet (PrivateSubnetMSKTwo)</li> <li>Select us-east-1c for the third AZ, and the appropriate subnet (PrivateSubnetMSKThree) </li> </ol>"},{"location":"day1/part1/1_provisoned/exercise/#security-group","title":"Security Group","text":"<ol> <li> <p>In the Security groups in Amazon EC2 section, click Browse and select the msk-labs-default-MSKSecurityGroup-xxxx security group we created in prerequisites steps. </p> </li> <li> <p>Click Choose </p> </li> </ol> <p></p>"},{"location":"day1/part1/1_provisoned/exercise/#security","title":"Security","text":""},{"location":"day1/part1/1_provisoned/exercise/#access-control-methods-authentication","title":"Access control methods (Authentication)","text":"<ol> <li>Select Unauthenticated access for Access control methods. Leave the other access control methods blank as they will be explored in other labs. </li> </ol>"},{"location":"day1/part1/1_provisoned/exercise/#encryption","title":"Encryption","text":"<p>Note: You cannot enable encryption on an already created cluster, nor can you turn it off on a cluster configured with encryption, so plan your use carefully to avoid rebuilding to change these settings</p> <ol> <li> <p>In the Encryption section, select both TLS encryption and Plaintext for encryption between clients and brokers. This will enable 2 different service ports on the cluster (9092 and 9094). You will be able to communicate in both an encrypted and unencrypted manner - choose based on your data needs. For this workshop we will experiment with both, but you should choose what fits your production environment best.</p> </li> <li> <p>Select TLS encryption for encryption within the cluster</p> <p>Note: that this can impact the performance  of the cluster in production. If you don't need this level of encryption consider leaving it off.</p> </li> <li> <p>Select Use AWS managed key. This means Amazon MSK will manage the encryption key for you. </p> </li> <li> <p>Click Next</p> </li> </ol>"},{"location":"day1/part1/1_provisoned/exercise/#monitoring","title":"Monitoring","text":"<p>There are 2 types of monitoring available for Amazon MSK - Cloudwatch monitoring which is available in 4 flavours (Basic, Enhanced broker-level, Enhanced topic-level, and Enhanced partition-level), as well as the Open Monitoring with Prometheus. We will use both.</p> <ol> <li> <p>Select Enhanced topic-level monitoring. This will enable collection of metrics from each broker at the topic level. This generates more metrics and incurs additional costs, but will also let you troubleshoot and understand your traffic better.</p> </li> <li> <p>Select Enable open monitoring with Prometheus</p> </li> </ol> <p></p>"},{"location":"day1/part1/1_provisoned/exercise/#broker-log-delivery","title":"Broker Log Delivery","text":"<p>We are going to configure the cluster to send any broker logs to Cloudwatch Logs, which will provide us with an easy way to work with the logs.</p> <ol> <li>Click Deliver to Amazon CloudWatch Logs - this will expand a new section where you will enter the ARN for the log group. To do this we will need to create a log group first.</li> <li>Click on visit Amazon CloudWatch Logs console - this will open a new tab in the CloudWatch Logs console </li> <li>Click on Create Log Group in the top right corner </li> <li>Enter your log group name - MSKClusterLogs and click Create </li> <li>You can now close this tab </li> <li>You should be back in your MSK Cluster Creation window - click Browse button, and then check the circle beside MSKClusterLogs and then click Choose </li> </ol>"},{"location":"day1/part1/1_provisoned/exercise/#cluster-tags","title":"Cluster tags","text":"<ol> <li>Under key enter Name and in value MSKLabCluster.</li> <li>Click Next</li> </ol>"},{"location":"day1/part1/1_provisoned/exercise/#review-and-create","title":"Review and create","text":"<p>Scroll to the bottom and click Create cluster - voila! Your cluster is being built. This can take 10-15 minutes, so it's a good time to grab a coffee, read ahead in the lab, or explore the MSK Documentation </p> <p></p>"},{"location":"day1/part1/2_cli/exercise/","title":"Launching an MSK cluster (CLI)","text":"<p>In this exercise you will create an Amazon MSK cluster using the AWS CLI.</p>"},{"location":"day1/part1/2_cli/exercise/#prepare-the-enviroment","title":"Prepare the Enviroment","text":""},{"location":"day1/part1/2_cli/exercise/#setting-up-your-cloud9-workstation-environment","title":"Setting Up Your Cloud9 Workstation Environment","text":"<p>AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser while providing you with access to a full Linux server.</p> <p>You will use AWS Cloud9 as your workstation enviroment to run shell commands, Python scripts and SQL queries for the labs.</p>"},{"location":"day1/part1/2_cli/exercise/#accessing-aws-cloud9-terminal-ide","title":"Accessing AWS Cloud9 Terminal IDE","text":"<ol> <li>Go to the AWS Cloud9 Console  and you should see a Cloud9 Environment named msk-labs-default-Cloud9EC2Bastion. (Make sure you are in the right AWS Region).</li> <li>Click on Open to launch your AWS Cloud9 Terminal IDE. A new tab will open in your Browser! <p>Tip: Now, you can close the first AWS Cloud9 tab in your browser and stick to the new AWS Cloud9 Terminal IDE tab that just opened (the one that partially says msk-labs-default-Cloud9EC2Bastion).</p> </li> <li>Allow for the AWS Cloud9 IDE quick setup to finish, then close the Welcome tab</li> <li>To run commands in Cloud9 you need a terminal. Click on the green plus icon (+) and select new terminal to add a new Command Line Terminal tab:  <p>From now on, you will use this terminal window throughout this workshop lab to execute all the AWS CLI commands and scripts.</p> </li> </ol>"},{"location":"day1/part1/2_cli/exercise/#create-msk-cluster-cli","title":"Create MSK Cluster (CLI)","text":""},{"location":"day1/part1/2_cli/exercise/#step-1-get-subnet-information","title":"Step-1: Get Subnet Information","text":"<p>We need to get the subnets to deploy the brokers in to. For that, we need to know the VPC ID for the lab.</p> <ol> <li>Use the cli to get a list of VPCs in your account  <p>aws ec2 describe-vpcs --output table </p> </li> <li>Look in the table for the VPC you're using for the exercise.  If you are using the VPC created as part of the workshop event, it will be named MSKVPC. </li> <li>Copy the VPCid (example: vpc-0eb566c1948800933) to your notepad </li> <li>Use the cli to get a list of subnets in that VPC <p>aws ec2 describe-subnets --filters \"Name=vpc-id,Values=vpc-001ed0757fbb9e2b5\" --output table | egrep \"Name|AvailabilityZone|SubnetId\"</p> </li> </ol> <p>This will list the subnets in the selected VPC, then grab only the AZ, SubnetID, and Name, making it easier for you to grab the SubnetIds for the 3 private subnets in 3 different AZs. Add these to your notepad for later use. Example: (Highlighted in green) </p>"},{"location":"day1/part1/2_cli/exercise/#step-2-create-a-custom-cluster-configuration","title":"Step-2: Create a custom cluster configuration","text":"<p>We are going to enable your new Amazon MSK cluster to have the following settings:</p> Configuration Name Details auto.create.topics.enable allow topics to be created automatically by producers and consumers. This is not typically enabled in a production cluster, but it is handy for development and testing to lower the operational overhead delete.topic.enable enables topic deletion on the server. If topic deletion is not enabled, you cannot delete topics. You likely want to turn this on on all clusters you build unless you have a specific need not to. log.retention.hours we will set this to 8 hours for the lab. Note that this is the default configuration, it can still be overridden at the topic level <ol> <li> <p>On your Cloud9 terminal, create a file called 'cluster_config.txt' with the following command:</p> <p>vi ~/cluster_config.txt</p> </li> <li> <p>Put in the following content (hit i to enter insert mode):</p> <p>auto.create.topics.enable = true</p> <p>delete.topic.enable = true</p> <p>log.retention.hours = 8</p> </li> <li> <p>Press  to exit insert mode, then type :wq! to save and exit <li>Confirm if the file is created successfully, using below command:  <p>cat ~/cluster_config.txt</p> </li> <p></p>"},{"location":"day1/part1/2_cli/exercise/#step-3-create-the-configuration-object","title":"Step-3: Create the configuration object","text":"<p>Run the following command to push the configuration to the Amazon MSK service for use at cluster creation time:</p> <p>aws kafka create-configuration --name \"WorkshopMSKConfig\" --description \"Configuration used for MSK workshop - Auto topic creation; topic deletion; 8hrs retention\" --kafka-versions \"2.8.1\" \"2.7.0\" --server-properties fileb://cluster_config.txt</p> <p>The --kafka-versions option is used to tell Amazon MSK which versions of Amazon MSK this configuration is allowed to be used with. If you see an error like the following, then ensure that you've typed in the kafka version string correctly (including quotes):</p> <p>An error occurred (BadRequestException) when calling the CreateConfiguration operation: Unsupported KafkaVersion [2.7.1]. Valid values: [1.1.1, 2.1.0, 2.2.1, 2.3.1]</p> <p>When the command is run, it will return a JSON object, including the ARN for the configuration object. You should copy and paste this in to your text editor for use later, or assign it to an environment variable (export CLUSTER_ARN=\"arn:...\"). Example:</p> <p></p>"},{"location":"day1/part1/2_cli/exercise/#review-the-configuration-created","title":"Review the configuration created","text":"<p>You can review the configuration using the CLI. Using the ARN provided in the output Step above (or retrieved from aws kafka list-configurations) you can query for your saved configuration:</p> <p>aws kafka describe-configuration --arn $CLUSTER_ARN</p> <p>The output: </p> <p>For more details on creating and managing Amazon MSK Cluster Configuration, see the MSK Configuration Operations  document.</p>"},{"location":"day1/part1/2_cli/exercise/#step-4-create-the-cluster-definition-file","title":"Step-4: Create the cluster definition file","text":"<p>To complete this Step, you need the following:</p> <ol> <li>Private SubnetID us-east-1a (from step 1 above)</li> <li>Private SubnetID us-east-1b (from step 1 above)</li> <li>Private SubnetID us-east-1c (from step 1 above)</li> <li>Securitygroup ID for the SG \"MSKWorkshop-KafkaService\" (from Prerequisites lab)</li> <li>Cluster configuration ARN (from step 2 above)</li> </ol> <p>You will now combine the data above into a cluster definition file (clusterinfo.json). It will look something like this, where you will replace the values with the values from above:</p> <p>Example of a complete file:</p> <pre><code>{\n  \"BrokerNodeGroupInfo\": {\n     \"BrokerAZDistribution\": \"DEFAULT\",\n     \"InstanceType\": \"kafka.m5.large\",\n     \"ClientSubnets\": [\n         \"subnet-0777309bbfe01c152\", \"subnet-0d629834c7436ba42\", \"subnet-01236bbb66a65708d\"\n     ],\n     \"SecurityGroups\": [\n         \"sg-0b4e02d3f8487d13a\"\n     ],\n     \"StorageInfo\": {\n         \"EbsStorageInfo\": {\n            \"VolumeSize\": 100\n         }\n     }\n  },\n  \"ClusterName\": \"MSKWorkshopCluster-cli\",\n  \"ConfigurationInfo\": {\n     \"Arn\": \"arn:aws:kafka:us-east-1:&lt;aws-account-number&gt;:configuration/WorkshopMSKConfig/68151d80-d2fe-491b-8632-9e090cd7e2ea-21\",\n     \"Revision\": 1\n  },\n  \"EncryptionInfo\": {\n     \"EncryptionAtRest\": {\n         \"DataVolumeKMSKeyId\": \"\"\n     },\n     \"EncryptionInTransit\": {\n         \"InCluster\": true,\n         \"ClientBroker\": \"TLS_PLAINTEXT\"\n     }\n  },\n  \"EnhancedMonitoring\": \"PER_TOPIC_PER_BROKER\",\n  \"KafkaVersion\": \"2.8.1\",\n  \"NumberOfBrokerNodes\": 3,\n  \"OpenMonitoring\": {\n     \"Prometheus\": {\n         \"JmxExporter\": {\n            \"EnabledInBroker\": true\n         },\n         \"NodeExporter\": {\n            \"EnabledInBroker\": true\n         }\n     }\n  }\n}\n</code></pre>"},{"location":"day1/part1/2_cli/exercise/#step-5-create-the-cluster","title":"Step 5 - Create the cluster","text":"<p>We can now use the command line tool and the cluster definition to create the cluster:</p> <p>aws kafka create-cluster --cli-input-json file://~/clusterinfo.json </p> <p>The command will return a JSON object that containers your cluster ARN, name and state. Grab the ARN.</p> <p></p> <p>This step will take some time. You can move on to the next step to see how to monitor progress and review the cluster deployment.</p>"},{"location":"day1/part1/2_cli/exercise/#step-6-review-the-cluster-deployed","title":"Step 6 - Review the cluster deployed","text":"<p>You can check on your cluster configuration and status by using the cli and the --describe-cluster option. You will need the cluster arn for this, which you got from the last step.</p> <p>Use the ARN and get the cluster configuration and state, changing the example ARN to the one from the command above:</p> <p>aws kafka describe-cluster --cluster-arn arn:aws:kafka:us-east-1:xyz:cluster/MSKWorkshop/20a94343-552f-4298-9076-99673162e023-6 | grep -i state</p> <p></p> <p>You can alternatively check the same on the MSK Console (Right click -&gt; Open Link in New Tab).</p> <p></p> <p>When the cluster is ready, you will get the state as \"ACTIVE\".</p> <p></p> <p>You are done here! Proceed to Next Lab.</p>"},{"location":"day1/part1/Prerequisites/exercise/","title":"Prerequisites for running in AWS Event Account**","text":"<p>Please choose the region 'us-east-1'</p> <p></p>"},{"location":"day1/part1/Prerequisites/exercise/#preparation","title":"Preparation","text":"<p>The following steps will prepare you for the creation of the Amazon MSK cluster in this lab.</p> <p>Note that running this module will launch AWS resources that have an associated cost. If you are not running this lab as part of an Amazon MSK workshop using provided accounts, remember to clean up when you are done to keep from incurring ongoing charges for resources left running.</p>"},{"location":"day1/part1/Prerequisites/exercise/#get-the-client-security-group-from-cloudformation","title":"Get the Client Security Group from Cloudformation","text":"<p>By default, the cluster will be attached to the 'default' security group, which allows all ports between all members of the group. This is fine for testing, but it's not a best practice in production.</p> <p>We need two security groups - one to attach to producers, consumers, and admin hosts, and the other to attach to the Amazon MSK cluster that references the first.</p> <p>The CloudFormation template already created one of them - the Client security group. Look at the Outputs tab of the CloudFormation stack - msk-labs-default created and copy the value for the key KafkaClientEC2InstanceSecurityGroupId.</p> <p></p>"},{"location":"day1/part1/Prerequisites/exercise/#create-an-msk-security-group","title":"Create an MSK security group","text":"<ol> <li>Click on Services in the top left corner of the console, and select EC2</li> <li>Go to the EC2 - Security Groups Page (Right click -&gt; Open Link in New Tab).</li> <li>Click Create Security Group</li> </ol>"},{"location":"day1/part1/Prerequisites/exercise/#fill-out-the-form-as-follows","title":"Fill out the form as follows:","text":"<ol> <li>Security group name: MSKWorkshop-KafkaService</li> <li>Description: Access to the Kafka service on the MSK cluster</li> <li>VPC: [select the VPC you are using for your lab (MSKVPC)]</li> <li> <p>Create rules (Under the Inbound rules section. Use the below mentioned configuration)</p> </li> <li> <p>Click Create security group </p> </li> <li> <p>In the security group list, select the Group ID for the MSKWorkshop-KafkaService SG, and copy it to your notepad/text editor</p> </li> </ol> <p></p> <p>You are done here! Proceed to Launching MSK Cluster.</p>"},{"location":"day1/part1/Prerequisites/exercise/#a-click-add-rule-plaintext-kafka-broker-access","title":"(a). Click Add rule [Plaintext Kafka Broker Access]","text":"<ul> <li>Type: Custom TCP</li> <li>Protocol: TCP</li> <li>Port range: 9092</li> <li>Source: [paste the value of the KafkaClientEC2InstanceSecurityGroupId SG you copied in the previous step, from Cloudformation Outputs (msklab-KafkaClientInstance...)]</li> <li>Description: Plaintext Kafka</li> </ul>"},{"location":"day1/part1/Prerequisites/exercise/#b-click-add-rule-encrypted-kafka-broker-access","title":"(b). Click Add Rule [Encrypted Kafka Broker Access]","text":"<ul> <li>Type: Custom TCP</li> <li>Protocol: TCP</li> <li>Port range: 9094</li> <li>Source: [paste the value of the * KafkaClientEC2InstanceSecurityGroupId SG you copied in the previous step, from Cloudformation Outputs (msklab-KafkaClientInstance...)]</li> <li>Description: Encrypted Kafka</li> </ul>"},{"location":"day1/part1/Prerequisites/exercise/#c-click-add-rule-zookeeper-access","title":"(c). Click Add Rule [Zookeeper Access]","text":"<ul> <li>Type: Custom TCP</li> <li>Protocol: TCP</li> <li>Port range: 2181</li> <li>Source: [paste the value of the KafkaClientEC2InstanceSecurityGroupId SG you copied in the previous step, from Cloudformation Outputs (msklab-KafkaClientInstance...)]</li> <li>Description: Zookeeper access</li> </ul>"},{"location":"day1/part1/overview/exercise/","title":"Overview","text":"<p>This module will walk you through how to use the Console to create a custom configuration and an Amazon MSK Cluster.</p>"},{"location":"day1/part1/overview/exercise/#custom-configuration","title":"Custom Configuration","text":"<p>The custom configuration will enable us to provide a special configuration to the cluster. Review the available options to make sure you have what you need. For more information about configuration properties, see Apache Kafka Configuration.</p> <p>To learn how you can create a custom MSK configuration, list all configurations, or describe them, see Amazon MSK configuration operations. To create an MSK cluster with a custom MSK configuration, or to update a cluster with a new custom configuration, see Amazon MSK: How it works.</p> <p>When you update your existing MSK cluster with a custom MSK configuration, Amazon MSK does rolling restarts when necessary, and uses best practices to minimize customer downtime. For example, after Amazon MSK restarts each broker, Amazon MSK tries to let the broker catch up on data that the broker might have missed during the configuration update before it moves to the next broker.</p>"},{"location":"day1/part1/overview/exercise/#cluster","title":"Cluster","text":"<p>The cluster will be deployed into an existing VPC, with brokers deployed in 3 private subnets (one per AZ). We will use m5.large nodes for this exercise. If you are using an existing VPC, please ensure that there is a private subnet in each AZ into which you can deploy.</p> <p>Amazon MSK detects and automatically recovers from the most common failure scenarios for clusters so that your producer and consumer applications can continue their write and read operations with minimal impact. When Amazon MSK detects a broker failure, it mitigates the failure or replaces the unhealthy or unreachable broker with a new one. In addition, where possible, it reuses the storage from the older broker to reduce the data that Apache Kafka needs to replicate. Your availability impact is limited to the time required for Amazon MSK to complete the detection and recovery. After a recovery, your producer and consumer apps can continue to communicate with the same broker IP addresses that they used before the failure.</p>"},{"location":"day1/part1/overview/exercise/#architecture","title":"Architecture","text":"<p>The diagram demonstrates the interaction between the following components:</p>"},{"location":"day1/part1/overview/exercise/#broker-nodes","title":"Broker nodes","text":"<p>When creating an Amazon MSK cluster, you specify how many broker nodes you want Amazon MSK to create in each Availability Zone. In the example cluster shown in this diagram, there's one broker per Availability Zone. Each Availability Zone has its own virtual private cloud (VPC) subnet. Amazon MSK offers a 3 AZ or a 2 AZ Apache Kafka node layout. Currently, a 1 AZ (single AZ) Amazon MSK cluster is not available.</p>"},{"location":"day1/part1/overview/exercise/#zookeeper-nodes","title":"ZooKeeper nodes","text":"<p>Amazon MSK also creates the Apache ZooKeeper nodes for you. Apache ZooKeeper is an open-source server that enables highly reliable, distributed coordination. There is a dedicated ZooKeeper ensemble created for each Amazon MSK cluster that is fully obfuscated and included with each cluster at no additional cost.</p>"},{"location":"day1/part1/overview/exercise/#producers-consumers-and-topic-creators","title":"Producers, consumers, and topic creators","text":"<p>Amazon MSK lets you use Apache Kafka data-plane operations to create topics and to produce and consume data.**</p> <p>AWS CLI - You can use the AWS Command Line Interface (AWS CLI) or the APIs in the SDK to perform control-plane operations. For example, you can use the AWS CLI or the SDK to create or delete an Amazon MSK cluster, list all the clusters in an account, or view the properties of a cluster.</p>"}]}