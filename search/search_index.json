{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Amazon MSK Train-The-Trainer Workshop \u00b6 This workshop contains exercises for the 2-day Amazon MSK Workshop Training. Exercises \u00b6 Day-1 \u00b6 Overview \u00b6 Custom configuration Cluster Architecture Prerequisites \u00b6 Choose Region Create an MSK security group Part 1 - Kafka overview & Amazon MSK Cluster Creation \u00b6 Launching MSK cluster (Provisoned) (Console) Launching MSK cluster (Provisoned) (CLI) Day-2 \u00b6 Part 4 - Building a Serverless Apache Kafka Data Pipeline \u00b6 Architecture Introduction Setup MSK Serverless cluster Produce clickstream data to MSK Serverless using Elastic Container Service Consume data from MSK Serverless using Lambda Create Quicksight Dashboard Consume using Kinesis Data Analytics and write to Part 5 - MSK Integration with Athena and Redshift \u00b6 Architecture Introduction Prerequisites Integration with Athena Integration with Redshift","title":"Introduction"},{"location":"#welcome-to-amazon-msk-train-the-trainer-workshop","text":"This workshop contains exercises for the 2-day Amazon MSK Workshop Training.","title":"Welcome to Amazon MSK Train-The-Trainer Workshop"},{"location":"#exercises","text":"","title":"Exercises"},{"location":"#day-1","text":"","title":"Day-1"},{"location":"#overview","text":"Custom configuration Cluster Architecture","title":"Overview"},{"location":"#prerequisites","text":"Choose Region Create an MSK security group","title":"Prerequisites"},{"location":"#part-1-kafka-overview-amazon-msk-cluster-creation","text":"Launching MSK cluster (Provisoned) (Console) Launching MSK cluster (Provisoned) (CLI)","title":"Part 1 - Kafka overview &amp; Amazon MSK Cluster Creation"},{"location":"#day-2","text":"","title":"Day-2"},{"location":"#part-4-building-a-serverless-apache-kafka-data-pipeline","text":"Architecture Introduction Setup MSK Serverless cluster Produce clickstream data to MSK Serverless using Elastic Container Service Consume data from MSK Serverless using Lambda Create Quicksight Dashboard Consume using Kinesis Data Analytics and write to","title":"Part 4 - Building a Serverless Apache Kafka Data Pipeline"},{"location":"#part-5-msk-integration-with-athena-and-redshift","text":"Architecture Introduction Prerequisites Integration with Athena Integration with Redshift","title":"Part 5 - MSK Integration with Athena and Redshift"},{"location":"setup/","text":"Setup \u00b6 Perform the following steps to login to the event engine. Type Event Engine URL on to your browser. (Right click this link -> Open in new tab). Enter the hash provided to you. Accept Terms & Login. Choose \u201cEmail One-Time Password\u201d. Provide your email ID where your 9-digit OTP will be sent within 5 mins. Once you receive OTP over your email, enter it to sign in to the Team Dashboard. Click on the SSH Key and download the key to your local desktop. Click Ok once done. Click on AWS Console and Open AWS Console. You can also retrieve AWS_DEFAULT_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_SESSION_TOKEN from this Team Dashboard whenever required for your exercises. Make a note of your account ID in the top right corner of the AWS Console and store it in a notepad. Go to CloudFormation and verify that the Cloudformation templates \"msk-labs-default\" , \"msk-labs-default-MSKVPCStack-xxxxxxxxx\" and \"aws-cloud9-msk-labs-default-Cloud9EC2Bastion-xxxxxxxx\" are created.","title":"Setup"},{"location":"setup/#setup","text":"Perform the following steps to login to the event engine. Type Event Engine URL on to your browser. (Right click this link -> Open in new tab). Enter the hash provided to you. Accept Terms & Login. Choose \u201cEmail One-Time Password\u201d. Provide your email ID where your 9-digit OTP will be sent within 5 mins. Once you receive OTP over your email, enter it to sign in to the Team Dashboard. Click on the SSH Key and download the key to your local desktop. Click Ok once done. Click on AWS Console and Open AWS Console. You can also retrieve AWS_DEFAULT_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_SESSION_TOKEN from this Team Dashboard whenever required for your exercises. Make a note of your account ID in the top right corner of the AWS Console and store it in a notepad. Go to CloudFormation and verify that the Cloudformation templates \"msk-labs-default\" , \"msk-labs-default-MSKVPCStack-xxxxxxxxx\" and \"aws-cloud9-msk-labs-default-Cloud9EC2Bastion-xxxxxxxx\" are created.","title":"Setup"},{"location":"day1/part1/1_provisoned/exercise/","text":"Launching an MSK cluster (Console) \u00b6 This exercise is meant to show you different options and features available while trying to create an MSK cluster. MSK clusters required are already created in your event engine accounts which we will use for our exercises. Create MSK Cluster (Console) \u00b6 Go to the MSK Landing Page (Right click -> Open Link in New Tab). Cluster Settings \u00b6 Sign-in to the AWS Console in the account you want to create your cluster in Browse to the MSK create cluster wizard to start the creation Select Custom create for the Creation method Enter the cluster name - MSKWorkshopCluster In Cluster type, Choose the option Provisioned Select the version of Kafka you want to run on the cluster (ex: 2.8.1 ) Brokers \u00b6 Select kafka.m5.large as the Broker Instance Type Select the number of zones (availability zones) you want to deploy in to 3 Enter 1 for the number of brokers per zone (Your cluster will have 3 total brokers, distributed evenly across your 3 Availability Zones.) Storage \u00b6 Enter 100 GiB Leave others options as default Configuration Section \u00b6 We are going to create a custom configuration that the cluster will run. We will enable the following features: auto.create.topics.enable - allow topics to be created automatically by producers and consumers. This is not typically enabled in a production cluster, but it is handy for development and testing to lower the operational overhead delete.topic.enable - enables topic deletion on the server. If topic deletion is not enabled, you cannot delete topics. You likely want to turn this on on all clusters you build unless you have a specific need not to. log.retention.hours - we will set this to 8 hours for the lab. Note that this is the default configuration, it can still be overridden at the topic level Create Configuration Object \u00b6 Select Custom configuration for the Cluster configuration Click on Create configuration Give your configuration a name - MSK-workshop Add a description for the config - MSK workshop - Auto topic creation; topic deletion; 8hrs retention Under Configuration Properties, ensure the following options are set/overridden - you can leave the Version as None auto.create.topics.enable=true delete.topic.enable=true log.retention.hours=8 6. Click Create - this will take you to the Cluster Configurations page. You can close this browser tab now 7. Back in the Cluster Creation workflow, you can hit the refresh icon beside the cluster configuration box (the circle icon) then select the configuration you created Networking \u00b6 Select the VPC you want to deploy your cluster in ( MSKVPC if you created the VPC using our provided CloudFormation) Select us-east-1a for the first Availability Zone (AZ), then the subnet (PrivateSubnetMSKOne) Select us-east-1b for the second AZ, and the appropriate subnet (PrivateSubnetMSKTwo) Select us-east-1c for the third AZ, and the appropriate subnet (PrivateSubnetMSKThree) Security Group \u00b6 In the Security groups in Amazon EC2 section, click Browse and select the msk-labs-default-MSKSecurityGroup-xxxx security group we created in prerequisites steps. Click Choose Security \u00b6 Access control methods (Authentication) \u00b6 Select Unauthenticated access for Access control methods. Leave the other access control methods blank as they will be explored in other labs. Encryption \u00b6 Note: You cannot enable encryption on an already created cluster, nor can you turn it off on a cluster configured with encryption, so plan your use carefully to avoid rebuilding to change these settings In the Encryption section, select both TLS encryption and Plaintext for encryption between clients and brokers. This will enable 2 different service ports on the cluster (9092 and 9094). You will be able to communicate in both an encrypted and unencrypted manner - choose based on your data needs. For this workshop we will experiment with both, but you should choose what fits your production environment best. Select TLS encryption for encryption within the cluster Note: that this can impact the performance of the cluster in production. If you don't need this level of encryption consider leaving it off. Select Use AWS managed key. This means Amazon MSK will manage the encryption key for you. Click Next Monitoring \u00b6 There are 2 types of monitoring available for Amazon MSK - Cloudwatch monitoring which is available in 4 flavours (Basic, Enhanced broker-level, Enhanced topic-level, and Enhanced partition-level) , as well as the Open Monitoring with Prometheus. We will use both. Select Enhanced topic-level monitoring. This will enable collection of metrics from each broker at the topic level. This generates more metrics and incurs additional costs, but will also let you troubleshoot and understand your traffic better. Select Enable open monitoring with Prometheus Broker Log Delivery \u00b6 We are going to configure the cluster to send any broker logs to Cloudwatch Logs, which will provide us with an easy way to work with the logs. Click Deliver to Amazon CloudWatch Log s - this will expand a new section where you will enter the ARN for the log group. To do this we will need to create a log group first. Click on visit Amazon CloudWatch Logs console - this will open a new tab in the CloudWatch Logs console Click on Create Log Group in the top right corner Enter your log group name - MSKClusterLogs and click Create You can now close this tab You should be back in your MSK Cluster Creation window - click Browse button, and then check the circle beside MSKClusterLogs and then click Choose Cluster tags \u00b6 Under key enter Name and in value MSKLabCluster . Click Next Review and create \u00b6 Scroll to the bottom and click Create cluster - voila! Your cluster is being built. This can take 10-15 minutes, so it's a good time to grab a coffee, read ahead in the lab, or explore the MSK Documentation","title":"3 - Launching MSK cluster (Provisoned)(Console)"},{"location":"day1/part1/1_provisoned/exercise/#launching-an-msk-cluster-console","text":"This exercise is meant to show you different options and features available while trying to create an MSK cluster. MSK clusters required are already created in your event engine accounts which we will use for our exercises.","title":"Launching an MSK cluster (Console)"},{"location":"day1/part1/1_provisoned/exercise/#create-msk-cluster-console","text":"Go to the MSK Landing Page (Right click -> Open Link in New Tab).","title":"Create MSK Cluster (Console)"},{"location":"day1/part1/1_provisoned/exercise/#cluster-settings","text":"Sign-in to the AWS Console in the account you want to create your cluster in Browse to the MSK create cluster wizard to start the creation Select Custom create for the Creation method Enter the cluster name - MSKWorkshopCluster In Cluster type, Choose the option Provisioned Select the version of Kafka you want to run on the cluster (ex: 2.8.1 )","title":"Cluster Settings"},{"location":"day1/part1/1_provisoned/exercise/#brokers","text":"Select kafka.m5.large as the Broker Instance Type Select the number of zones (availability zones) you want to deploy in to 3 Enter 1 for the number of brokers per zone (Your cluster will have 3 total brokers, distributed evenly across your 3 Availability Zones.)","title":"Brokers"},{"location":"day1/part1/1_provisoned/exercise/#storage","text":"Enter 100 GiB Leave others options as default","title":"Storage"},{"location":"day1/part1/1_provisoned/exercise/#configuration-section","text":"We are going to create a custom configuration that the cluster will run. We will enable the following features: auto.create.topics.enable - allow topics to be created automatically by producers and consumers. This is not typically enabled in a production cluster, but it is handy for development and testing to lower the operational overhead delete.topic.enable - enables topic deletion on the server. If topic deletion is not enabled, you cannot delete topics. You likely want to turn this on on all clusters you build unless you have a specific need not to. log.retention.hours - we will set this to 8 hours for the lab. Note that this is the default configuration, it can still be overridden at the topic level","title":"Configuration Section"},{"location":"day1/part1/1_provisoned/exercise/#create-configuration-object","text":"Select Custom configuration for the Cluster configuration Click on Create configuration Give your configuration a name - MSK-workshop Add a description for the config - MSK workshop - Auto topic creation; topic deletion; 8hrs retention Under Configuration Properties, ensure the following options are set/overridden - you can leave the Version as None auto.create.topics.enable=true delete.topic.enable=true log.retention.hours=8 6. Click Create - this will take you to the Cluster Configurations page. You can close this browser tab now 7. Back in the Cluster Creation workflow, you can hit the refresh icon beside the cluster configuration box (the circle icon) then select the configuration you created","title":"Create Configuration Object"},{"location":"day1/part1/1_provisoned/exercise/#networking","text":"Select the VPC you want to deploy your cluster in ( MSKVPC if you created the VPC using our provided CloudFormation) Select us-east-1a for the first Availability Zone (AZ), then the subnet (PrivateSubnetMSKOne) Select us-east-1b for the second AZ, and the appropriate subnet (PrivateSubnetMSKTwo) Select us-east-1c for the third AZ, and the appropriate subnet (PrivateSubnetMSKThree)","title":"Networking"},{"location":"day1/part1/1_provisoned/exercise/#security-group","text":"In the Security groups in Amazon EC2 section, click Browse and select the msk-labs-default-MSKSecurityGroup-xxxx security group we created in prerequisites steps. Click Choose","title":"Security Group"},{"location":"day1/part1/1_provisoned/exercise/#security","text":"","title":"Security"},{"location":"day1/part1/1_provisoned/exercise/#access-control-methods-authentication","text":"Select Unauthenticated access for Access control methods. Leave the other access control methods blank as they will be explored in other labs.","title":"Access control methods (Authentication)"},{"location":"day1/part1/1_provisoned/exercise/#encryption","text":"Note: You cannot enable encryption on an already created cluster, nor can you turn it off on a cluster configured with encryption, so plan your use carefully to avoid rebuilding to change these settings In the Encryption section, select both TLS encryption and Plaintext for encryption between clients and brokers. This will enable 2 different service ports on the cluster (9092 and 9094). You will be able to communicate in both an encrypted and unencrypted manner - choose based on your data needs. For this workshop we will experiment with both, but you should choose what fits your production environment best. Select TLS encryption for encryption within the cluster Note: that this can impact the performance of the cluster in production. If you don't need this level of encryption consider leaving it off. Select Use AWS managed key. This means Amazon MSK will manage the encryption key for you. Click Next","title":"Encryption"},{"location":"day1/part1/1_provisoned/exercise/#monitoring","text":"There are 2 types of monitoring available for Amazon MSK - Cloudwatch monitoring which is available in 4 flavours (Basic, Enhanced broker-level, Enhanced topic-level, and Enhanced partition-level) , as well as the Open Monitoring with Prometheus. We will use both. Select Enhanced topic-level monitoring. This will enable collection of metrics from each broker at the topic level. This generates more metrics and incurs additional costs, but will also let you troubleshoot and understand your traffic better. Select Enable open monitoring with Prometheus","title":"Monitoring"},{"location":"day1/part1/1_provisoned/exercise/#broker-log-delivery","text":"We are going to configure the cluster to send any broker logs to Cloudwatch Logs, which will provide us with an easy way to work with the logs. Click Deliver to Amazon CloudWatch Log s - this will expand a new section where you will enter the ARN for the log group. To do this we will need to create a log group first. Click on visit Amazon CloudWatch Logs console - this will open a new tab in the CloudWatch Logs console Click on Create Log Group in the top right corner Enter your log group name - MSKClusterLogs and click Create You can now close this tab You should be back in your MSK Cluster Creation window - click Browse button, and then check the circle beside MSKClusterLogs and then click Choose","title":"Broker Log Delivery"},{"location":"day1/part1/1_provisoned/exercise/#cluster-tags","text":"Under key enter Name and in value MSKLabCluster . Click Next","title":"Cluster tags"},{"location":"day1/part1/1_provisoned/exercise/#review-and-create","text":"Scroll to the bottom and click Create cluster - voila! Your cluster is being built. This can take 10-15 minutes, so it's a good time to grab a coffee, read ahead in the lab, or explore the MSK Documentation","title":"Review and create"},{"location":"day1/part1/2_cli/exercise/","text":"Launching an MSK cluster (CLI) \u00b6 In this exercise you will create an Amazon MSK cluster using the AWS CLI. Prepare the Enviroment \u00b6 Setting Up Your Cloud9 Workstation Environment \u00b6 AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser while providing you with access to a full Linux server. You will use AWS Cloud9 as your workstation enviroment to run shell commands, Python scripts and SQL queries for the labs. Accessing AWS Cloud9 Terminal IDE \u00b6 Go to the AWS Cloud9 Console and you should see a Cloud9 Environment named msk-labs-default-Cloud9EC2Bastion . (Make sure you are in the right AWS Region). Click on Open to launch your AWS Cloud9 Terminal IDE. A new tab will open in your Browser! Tip: Now, you can close the first AWS Cloud9 tab in your browser and stick to the new AWS Cloud9 Terminal IDE tab that just opened (the one that partially says msk-labs-default-Cloud9EC2Bastion). Allow for the AWS Cloud9 IDE quick setup to finish, then close the Welcome tab To run commands in Cloud9 you need a terminal. Click on the green plus icon (+) and select new terminal to add a new Command Line Terminal tab: From now on, you will use this terminal window throughout this workshop lab to execute all the AWS CLI commands and scripts. Create MSK Cluster (CLI) \u00b6 Step-1: Get Subnet Information \u00b6 We need to get the subnets to deploy the brokers in to. For that, we need to know the VPC ID for the lab. Use the cli to get a list of VPCs in your account aws ec2 describe-vpcs --output table Look in the table for the VPC you're using for the exercise. If you are using the VPC created as part of the workshop event, it will be named MSKVPC . Copy the VPCid (example: vpc-0eb566c1948800933) to your notepad Use the cli to get a list of subnets in that VPC aws ec2 describe-subnets --filters \"Name=vpc-id,Values=vpc-001ed0757fbb9e2b5\" --output table | egrep \"Name|AvailabilityZone|SubnetId\" This will list the subnets in the selected VPC, then grab only the AZ, SubnetID, and Name, making it easier for you to grab the SubnetIds for the 3 private subnets in 3 different AZs. Add these to your notepad for later use. Example: (Highlighted in green) Step-2: Create a custom cluster configuration \u00b6 We are going to enable your new Amazon MSK cluster to have the following settings: Configuration Name Details auto.create.topics.enable allow topics to be created automatically by producers and consumers. This is not typically enabled in a production cluster, but it is handy for development and testing to lower the operational overhead delete.topic.enable enables topic deletion on the server. If topic deletion is not enabled, you cannot delete topics. You likely want to turn this on on all clusters you build unless you have a specific need not to. log.retention.hours we will set this to 8 hours for the lab. Note that this is the default configuration, it can still be overridden at the topic level On your Cloud9 terminal, create a file called 'cluster_config.txt' with the following command: vi ~/cluster_config.txt Put in the following content (hit i to enter insert mode): auto.create.topics.enable = true delete.topic.enable = true log.retention.hours = 8 Press to exit insert mode, then type :wq! to save and exit Confirm if the file is created successfully, using below command: cat ~/cluster_config.txt Step-3: Create the configuration object \u00b6 Run the following command to push the configuration to the Amazon MSK service for use at cluster creation time: aws kafka create-configuration --name \"WorkshopMSKConfig\" --description \"Configuration used for MSK workshop - Auto topic creation; topic deletion; 8hrs retention\" --kafka-versions \"2.8.1\" \"2.7.0\" --server-properties fileb://cluster_config.txt The --kafka-versions option is used to tell Amazon MSK which versions of Amazon MSK this configuration is allowed to be used with. If you see an error like the following, then ensure that you've typed in the kafka version string correctly (including quotes): An error occurred (BadRequestException) when calling the CreateConfiguration operation: Unsupported KafkaVersion [2.7.1]. Valid values: [1.1.1, 2.1.0, 2.2.1, 2.3.1] When the command is run, it will return a JSON object, including the ARN for the configuration object. You should copy and paste this in to your text editor for use later, or assign it to an environment variable (export CLUSTER_ARN=\"arn:...\"). Example: Review the configuration created \u00b6 You can review the configuration using the CLI. Using the ARN provided in the output Step above (or retrieved from aws kafka list-configurations) you can query for your saved configuration: aws kafka describe-configuration --arn $CLUSTER_ARN The output: For more details on creating and managing Amazon MSK Cluster Configuration, see the MSK Configuration Operations document. Step-4: Create the cluster definition file \u00b6 To complete this Step, you need the following: Private SubnetID us-east-1a (from step 1 above) Private SubnetID us-east-1b (from step 1 above) Private SubnetID us-east-1c (from step 1 above) Securitygroup ID for the SG \"MSKWorkshop-KafkaService\" (from Prerequisites lab) Cluster configuration ARN (from step 2 above) You will now combine the data above into a cluster definition file (clusterinfo.json). It will look something like this, where you will replace the values with the values from above: Example of a complete file: { \"BrokerNodeGroupInfo\": { \"BrokerAZDistribution\": \"DEFAULT\", \"InstanceType\": \"kafka.m5.large\", \"ClientSubnets\": [ \"subnet-0777309bbfe01c152\", \"subnet-0d629834c7436ba42\", \"subnet-01236bbb66a65708d\" ], \"SecurityGroups\": [ \"sg-0b4e02d3f8487d13a\" ], \"StorageInfo\": { \"EbsStorageInfo\": { \"VolumeSize\": 100 } } }, \"ClusterName\": \"MSKWorkshopCluster-cli\", \"ConfigurationInfo\": { \"Arn\": \"arn:aws:kafka:us-east-1:<aws-account-number>:configuration/WorkshopMSKConfig/68151d80-d2fe-491b-8632-9e090cd7e2ea-21\", \"Revision\": 1 }, \"EncryptionInfo\": { \"EncryptionAtRest\": { \"DataVolumeKMSKeyId\": \"\" }, \"EncryptionInTransit\": { \"InCluster\": true, \"ClientBroker\": \"TLS_PLAINTEXT\" } }, \"EnhancedMonitoring\": \"PER_TOPIC_PER_BROKER\", \"KafkaVersion\": \"2.8.1\", \"NumberOfBrokerNodes\": 3, \"OpenMonitoring\": { \"Prometheus\": { \"JmxExporter\": { \"EnabledInBroker\": true }, \"NodeExporter\": { \"EnabledInBroker\": true } } } } Step 5 - Create the cluster \u00b6 We can now use the command line tool and the cluster definition to create the cluster: aws kafka create-cluster --cli-input-json file://~/clusterinfo.json The command will return a JSON object that containers your cluster ARN, name and state. Grab the ARN. This step will take some time. You can move on to the next step to see how to monitor progress and review the cluster deployment. Step 6 - Review the cluster deployed \u00b6 You can check on your cluster configuration and status by using the cli and the --describe-cluster option. You will need the cluster arn for this, which you got from the last step. Use the ARN and get the cluster configuration and state, changing the example ARN to the one from the command above: aws kafka describe-cluster --cluster-arn arn:aws:kafka:us-east-1:< AWS_Account_Number >:cluster/MSKWorkshop/20a94343-552f-4298-9076-99673162e023-6 | grep -i state You can alternatively check the same on the MSK Console (Right click -> Open Link in New Tab). When the cluster is ready, you will get the state as \"ACTIVE\". You are done here! Proceed to Next Lab.","title":"4 - Launching MSK cluster (Provisoned)(CLI)"},{"location":"day1/part1/2_cli/exercise/#launching-an-msk-cluster-cli","text":"In this exercise you will create an Amazon MSK cluster using the AWS CLI.","title":"Launching an MSK cluster (CLI)"},{"location":"day1/part1/2_cli/exercise/#prepare-the-enviroment","text":"","title":"Prepare the Enviroment"},{"location":"day1/part1/2_cli/exercise/#setting-up-your-cloud9-workstation-environment","text":"AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser while providing you with access to a full Linux server. You will use AWS Cloud9 as your workstation enviroment to run shell commands, Python scripts and SQL queries for the labs.","title":"Setting Up Your Cloud9 Workstation Environment"},{"location":"day1/part1/2_cli/exercise/#accessing-aws-cloud9-terminal-ide","text":"Go to the AWS Cloud9 Console and you should see a Cloud9 Environment named msk-labs-default-Cloud9EC2Bastion . (Make sure you are in the right AWS Region). Click on Open to launch your AWS Cloud9 Terminal IDE. A new tab will open in your Browser! Tip: Now, you can close the first AWS Cloud9 tab in your browser and stick to the new AWS Cloud9 Terminal IDE tab that just opened (the one that partially says msk-labs-default-Cloud9EC2Bastion). Allow for the AWS Cloud9 IDE quick setup to finish, then close the Welcome tab To run commands in Cloud9 you need a terminal. Click on the green plus icon (+) and select new terminal to add a new Command Line Terminal tab: From now on, you will use this terminal window throughout this workshop lab to execute all the AWS CLI commands and scripts.","title":"Accessing AWS Cloud9 Terminal IDE"},{"location":"day1/part1/2_cli/exercise/#create-msk-cluster-cli","text":"","title":"Create MSK Cluster (CLI)"},{"location":"day1/part1/2_cli/exercise/#step-1-get-subnet-information","text":"We need to get the subnets to deploy the brokers in to. For that, we need to know the VPC ID for the lab. Use the cli to get a list of VPCs in your account aws ec2 describe-vpcs --output table Look in the table for the VPC you're using for the exercise. If you are using the VPC created as part of the workshop event, it will be named MSKVPC . Copy the VPCid (example: vpc-0eb566c1948800933) to your notepad Use the cli to get a list of subnets in that VPC aws ec2 describe-subnets --filters \"Name=vpc-id,Values=vpc-001ed0757fbb9e2b5\" --output table | egrep \"Name|AvailabilityZone|SubnetId\" This will list the subnets in the selected VPC, then grab only the AZ, SubnetID, and Name, making it easier for you to grab the SubnetIds for the 3 private subnets in 3 different AZs. Add these to your notepad for later use. Example: (Highlighted in green)","title":"Step-1: Get Subnet Information"},{"location":"day1/part1/2_cli/exercise/#step-2-create-a-custom-cluster-configuration","text":"We are going to enable your new Amazon MSK cluster to have the following settings: Configuration Name Details auto.create.topics.enable allow topics to be created automatically by producers and consumers. This is not typically enabled in a production cluster, but it is handy for development and testing to lower the operational overhead delete.topic.enable enables topic deletion on the server. If topic deletion is not enabled, you cannot delete topics. You likely want to turn this on on all clusters you build unless you have a specific need not to. log.retention.hours we will set this to 8 hours for the lab. Note that this is the default configuration, it can still be overridden at the topic level On your Cloud9 terminal, create a file called 'cluster_config.txt' with the following command: vi ~/cluster_config.txt Put in the following content (hit i to enter insert mode): auto.create.topics.enable = true delete.topic.enable = true log.retention.hours = 8 Press to exit insert mode, then type :wq! to save and exit Confirm if the file is created successfully, using below command: cat ~/cluster_config.txt","title":"Step-2: Create a custom cluster configuration"},{"location":"day1/part1/2_cli/exercise/#step-3-create-the-configuration-object","text":"Run the following command to push the configuration to the Amazon MSK service for use at cluster creation time: aws kafka create-configuration --name \"WorkshopMSKConfig\" --description \"Configuration used for MSK workshop - Auto topic creation; topic deletion; 8hrs retention\" --kafka-versions \"2.8.1\" \"2.7.0\" --server-properties fileb://cluster_config.txt The --kafka-versions option is used to tell Amazon MSK which versions of Amazon MSK this configuration is allowed to be used with. If you see an error like the following, then ensure that you've typed in the kafka version string correctly (including quotes): An error occurred (BadRequestException) when calling the CreateConfiguration operation: Unsupported KafkaVersion [2.7.1]. Valid values: [1.1.1, 2.1.0, 2.2.1, 2.3.1] When the command is run, it will return a JSON object, including the ARN for the configuration object. You should copy and paste this in to your text editor for use later, or assign it to an environment variable (export CLUSTER_ARN=\"arn:...\"). Example:","title":"Step-3: Create the configuration object"},{"location":"day1/part1/2_cli/exercise/#review-the-configuration-created","text":"You can review the configuration using the CLI. Using the ARN provided in the output Step above (or retrieved from aws kafka list-configurations) you can query for your saved configuration: aws kafka describe-configuration --arn $CLUSTER_ARN The output: For more details on creating and managing Amazon MSK Cluster Configuration, see the MSK Configuration Operations document.","title":"Review the configuration created"},{"location":"day1/part1/2_cli/exercise/#step-4-create-the-cluster-definition-file","text":"To complete this Step, you need the following: Private SubnetID us-east-1a (from step 1 above) Private SubnetID us-east-1b (from step 1 above) Private SubnetID us-east-1c (from step 1 above) Securitygroup ID for the SG \"MSKWorkshop-KafkaService\" (from Prerequisites lab) Cluster configuration ARN (from step 2 above) You will now combine the data above into a cluster definition file (clusterinfo.json). It will look something like this, where you will replace the values with the values from above: Example of a complete file: { \"BrokerNodeGroupInfo\": { \"BrokerAZDistribution\": \"DEFAULT\", \"InstanceType\": \"kafka.m5.large\", \"ClientSubnets\": [ \"subnet-0777309bbfe01c152\", \"subnet-0d629834c7436ba42\", \"subnet-01236bbb66a65708d\" ], \"SecurityGroups\": [ \"sg-0b4e02d3f8487d13a\" ], \"StorageInfo\": { \"EbsStorageInfo\": { \"VolumeSize\": 100 } } }, \"ClusterName\": \"MSKWorkshopCluster-cli\", \"ConfigurationInfo\": { \"Arn\": \"arn:aws:kafka:us-east-1:<aws-account-number>:configuration/WorkshopMSKConfig/68151d80-d2fe-491b-8632-9e090cd7e2ea-21\", \"Revision\": 1 }, \"EncryptionInfo\": { \"EncryptionAtRest\": { \"DataVolumeKMSKeyId\": \"\" }, \"EncryptionInTransit\": { \"InCluster\": true, \"ClientBroker\": \"TLS_PLAINTEXT\" } }, \"EnhancedMonitoring\": \"PER_TOPIC_PER_BROKER\", \"KafkaVersion\": \"2.8.1\", \"NumberOfBrokerNodes\": 3, \"OpenMonitoring\": { \"Prometheus\": { \"JmxExporter\": { \"EnabledInBroker\": true }, \"NodeExporter\": { \"EnabledInBroker\": true } } } }","title":"Step-4: Create the cluster definition file"},{"location":"day1/part1/2_cli/exercise/#step-5-create-the-cluster","text":"We can now use the command line tool and the cluster definition to create the cluster: aws kafka create-cluster --cli-input-json file://~/clusterinfo.json The command will return a JSON object that containers your cluster ARN, name and state. Grab the ARN. This step will take some time. You can move on to the next step to see how to monitor progress and review the cluster deployment.","title":"Step 5 - Create the cluster"},{"location":"day1/part1/2_cli/exercise/#step-6-review-the-cluster-deployed","text":"You can check on your cluster configuration and status by using the cli and the --describe-cluster option. You will need the cluster arn for this, which you got from the last step. Use the ARN and get the cluster configuration and state, changing the example ARN to the one from the command above: aws kafka describe-cluster --cluster-arn arn:aws:kafka:us-east-1:< AWS_Account_Number >:cluster/MSKWorkshop/20a94343-552f-4298-9076-99673162e023-6 | grep -i state You can alternatively check the same on the MSK Console (Right click -> Open Link in New Tab). When the cluster is ready, you will get the state as \"ACTIVE\". You are done here! Proceed to Next Lab.","title":"Step 6 - Review the cluster deployed"},{"location":"day1/part1/Prerequisites/exercise/","text":"Prerequisites for running in AWS Event Account** \u00b6 Please choose the region 'us-east-1' Preparation \u00b6 The following steps will prepare you for the creation of the Amazon MSK cluster in this lab. Note that running this module will launch AWS resources that have an associated cost. If you are not running this lab as part of an Amazon MSK workshop using provided accounts, remember to clean up when you are done to keep from incurring ongoing charges for resources left running. Get the Client Security Group from Cloudformation \u00b6 By default, the cluster will be attached to the 'default' security group, which allows all ports between all members of the group. This is fine for testing, but it's not a best practice in production. We need two security groups - one to attach to producers, consumers, and admin hosts, and the other to attach to the Amazon MSK cluster that references the first. The CloudFormation template already created one of them - the Client security group . Look at the Outputs tab of the CloudFormation stack - msk-labs-default created and copy the value for the key KafkaClientEC2InstanceSecurityGroupId. Create an MSK security group \u00b6 Click on Services in the top left corner of the console, and select EC2 Go to the EC2 - Security Groups Page (Right click -> Open Link in New Tab). Click Create Security Group Fill out the form as follows: \u00b6 Security group name: MSKWorkshop-KafkaService Description: Access to the Kafka service on the MSK cluster VPC: [select the VPC you are using for your lab (MSKVPC) ] Create rules (Under the Inbound rules section. Use the below mentioned configuration) (a). Click Add rule [Plaintext Kafka Broker Access] \u00b6 Type: Custom TCP Protocol: TCP Port range: 9092 Source: [paste the value of the KafkaClientEC2InstanceSecurityGroupId SG you copied in the previous step, from Cloudformation Outputs (msklab-KafkaClientInstance...)] Description: Plaintext Kafka (b). Click Add Rule [Encrypted Kafka Broker Access] \u00b6 Type: Custom TCP Protocol: TCP Port range: 9094 Source: [paste the value of the * KafkaClientEC2InstanceSecurityGroupId SG you copied in the previous step, from Cloudformation Outputs (msklab-KafkaClientInstance...)] Description: Encrypted Kafka (c). Click Add Rule [Zookeeper Access] \u00b6 Type: Custom TCP Protocol: TCP Port range: 2181 Source: [paste the value of the KafkaClientEC2InstanceSecurityGroupId SG you copied in the previous step, from Cloudformation Outputs (msklab-KafkaClientInstance...)] Description: Zookeeper access Click Create security group In the security group list, select the Group ID for the MSKWorkshop-KafkaService SG, and copy it to your notepad/text editor You are done here! Proceed to Launching MSK Cluster.","title":"2 - Prerequisites"},{"location":"day1/part1/Prerequisites/exercise/#prerequisites-for-running-in-aws-event-account","text":"Please choose the region 'us-east-1'","title":"Prerequisites for running in AWS Event Account**"},{"location":"day1/part1/Prerequisites/exercise/#preparation","text":"The following steps will prepare you for the creation of the Amazon MSK cluster in this lab. Note that running this module will launch AWS resources that have an associated cost. If you are not running this lab as part of an Amazon MSK workshop using provided accounts, remember to clean up when you are done to keep from incurring ongoing charges for resources left running.","title":"Preparation"},{"location":"day1/part1/Prerequisites/exercise/#get-the-client-security-group-from-cloudformation","text":"By default, the cluster will be attached to the 'default' security group, which allows all ports between all members of the group. This is fine for testing, but it's not a best practice in production. We need two security groups - one to attach to producers, consumers, and admin hosts, and the other to attach to the Amazon MSK cluster that references the first. The CloudFormation template already created one of them - the Client security group . Look at the Outputs tab of the CloudFormation stack - msk-labs-default created and copy the value for the key KafkaClientEC2InstanceSecurityGroupId.","title":"Get the Client Security Group from Cloudformation"},{"location":"day1/part1/Prerequisites/exercise/#create-an-msk-security-group","text":"Click on Services in the top left corner of the console, and select EC2 Go to the EC2 - Security Groups Page (Right click -> Open Link in New Tab). Click Create Security Group","title":"Create an MSK security group"},{"location":"day1/part1/Prerequisites/exercise/#fill-out-the-form-as-follows","text":"Security group name: MSKWorkshop-KafkaService Description: Access to the Kafka service on the MSK cluster VPC: [select the VPC you are using for your lab (MSKVPC) ] Create rules (Under the Inbound rules section. Use the below mentioned configuration)","title":"Fill out the form as follows:"},{"location":"day1/part1/Prerequisites/exercise/#a-click-add-rule-plaintext-kafka-broker-access","text":"Type: Custom TCP Protocol: TCP Port range: 9092 Source: [paste the value of the KafkaClientEC2InstanceSecurityGroupId SG you copied in the previous step, from Cloudformation Outputs (msklab-KafkaClientInstance...)] Description: Plaintext Kafka","title":"(a). Click Add rule [Plaintext Kafka Broker Access]"},{"location":"day1/part1/Prerequisites/exercise/#b-click-add-rule-encrypted-kafka-broker-access","text":"Type: Custom TCP Protocol: TCP Port range: 9094 Source: [paste the value of the * KafkaClientEC2InstanceSecurityGroupId SG you copied in the previous step, from Cloudformation Outputs (msklab-KafkaClientInstance...)] Description: Encrypted Kafka","title":"(b). Click Add Rule [Encrypted Kafka Broker Access]"},{"location":"day1/part1/Prerequisites/exercise/#c-click-add-rule-zookeeper-access","text":"Type: Custom TCP Protocol: TCP Port range: 2181 Source: [paste the value of the KafkaClientEC2InstanceSecurityGroupId SG you copied in the previous step, from Cloudformation Outputs (msklab-KafkaClientInstance...)] Description: Zookeeper access Click Create security group In the security group list, select the Group ID for the MSKWorkshop-KafkaService SG, and copy it to your notepad/text editor You are done here! Proceed to Launching MSK Cluster.","title":"(c). Click Add Rule [Zookeeper Access]"},{"location":"day1/part1/overview/exercise/","text":"Overview \u00b6 This module will walk you through how to use the Console to create a custom configuration and an Amazon MSK Cluster. Mandatory step : \u00b6 Download the CloudFormation template Navigate to the CloudFormation Console and deploy the CloudFormation using AWS Console by clicking Create stack on the top right and choose With new resources (standard) option Select Upload a template file and choose the mskid-full.yml file you downloaded and click Next Provide Stack name: msk-labs-default and click Next Scroll down completely and click Next Scroll down completely and Check box both options in Capabilities section click Submit Custom Configuration \u00b6 The custom configuration will enable us to provide a special configuration to the cluster. Review the available options to make sure you have what you need. For more information about configuration properties, see Apache Kafka Configuration . To learn how you can create a custom MSK configuration, list all configurations, or describe them, see Amazon MSK configuration operations . To create an MSK cluster with a custom MSK configuration, or to update a cluster with a new custom configuration, see Amazon MSK: How it works . When you update your existing MSK cluster with a custom MSK configuration, Amazon MSK does rolling restarts when necessary, and uses best practices to minimize customer downtime. For example, after Amazon MSK restarts each broker, Amazon MSK tries to let the broker catch up on data that the broker might have missed during the configuration update before it moves to the next broker. Cluster \u00b6 The cluster will be deployed into an existing VPC, with brokers deployed in 3 private subnets (one per AZ). We will use m5.large nodes for this exercise. If you are using an existing VPC, please ensure that there is a private subnet in each AZ into which you can deploy. Amazon MSK detects and automatically recovers from the most common failure scenarios for clusters so that your producer and consumer applications can continue their write and read operations with minimal impact. When Amazon MSK detects a broker failure, it mitigates the failure or replaces the unhealthy or unreachable broker with a new one. In addition, where possible, it reuses the storage from the older broker to reduce the data that Apache Kafka needs to replicate. Your availability impact is limited to the time required for Amazon MSK to complete the detection and recovery. After a recovery, your producer and consumer apps can continue to communicate with the same broker IP addresses that they used before the failure. Architecture \u00b6 The diagram demonstrates the interaction between the following components: Broker nodes \u00b6 When creating an Amazon MSK cluster, you specify how many broker nodes you want Amazon MSK to create in each Availability Zone. In the example cluster shown in this diagram, there's one broker per Availability Zone. Each Availability Zone has its own virtual private cloud (VPC) subnet. Amazon MSK offers a 3 AZ or a 2 AZ Apache Kafka node layout. Currently, a 1 AZ (single AZ) Amazon MSK cluster is not available. ZooKeeper nodes \u00b6 Amazon MSK also creates the Apache ZooKeeper nodes for you. Apache ZooKeeper is an open-source server that enables highly reliable, distributed coordination. There is a dedicated ZooKeeper ensemble created for each Amazon MSK cluster that is fully obfuscated and included with each cluster at no additional cost. Producers, consumers, and topic creators \u00b6 Amazon MSK lets you use Apache Kafka data-plane operations to create topics and to produce and consume data.** AWS CLI - You can use the AWS Command Line Interface (AWS CLI) or the APIs in the SDK to perform control-plane operations. For example, you can use the AWS CLI or the SDK to create or delete an Amazon MSK cluster, list all the clusters in an account, or view the properties of a cluster.","title":"1 - Overview"},{"location":"day1/part1/overview/exercise/#overview","text":"This module will walk you through how to use the Console to create a custom configuration and an Amazon MSK Cluster.","title":"Overview"},{"location":"day1/part1/overview/exercise/#mandatory-step","text":"Download the CloudFormation template Navigate to the CloudFormation Console and deploy the CloudFormation using AWS Console by clicking Create stack on the top right and choose With new resources (standard) option Select Upload a template file and choose the mskid-full.yml file you downloaded and click Next Provide Stack name: msk-labs-default and click Next Scroll down completely and click Next Scroll down completely and Check box both options in Capabilities section click Submit","title":"Mandatory step:"},{"location":"day1/part1/overview/exercise/#custom-configuration","text":"The custom configuration will enable us to provide a special configuration to the cluster. Review the available options to make sure you have what you need. For more information about configuration properties, see Apache Kafka Configuration . To learn how you can create a custom MSK configuration, list all configurations, or describe them, see Amazon MSK configuration operations . To create an MSK cluster with a custom MSK configuration, or to update a cluster with a new custom configuration, see Amazon MSK: How it works . When you update your existing MSK cluster with a custom MSK configuration, Amazon MSK does rolling restarts when necessary, and uses best practices to minimize customer downtime. For example, after Amazon MSK restarts each broker, Amazon MSK tries to let the broker catch up on data that the broker might have missed during the configuration update before it moves to the next broker.","title":"Custom Configuration"},{"location":"day1/part1/overview/exercise/#cluster","text":"The cluster will be deployed into an existing VPC, with brokers deployed in 3 private subnets (one per AZ). We will use m5.large nodes for this exercise. If you are using an existing VPC, please ensure that there is a private subnet in each AZ into which you can deploy. Amazon MSK detects and automatically recovers from the most common failure scenarios for clusters so that your producer and consumer applications can continue their write and read operations with minimal impact. When Amazon MSK detects a broker failure, it mitigates the failure or replaces the unhealthy or unreachable broker with a new one. In addition, where possible, it reuses the storage from the older broker to reduce the data that Apache Kafka needs to replicate. Your availability impact is limited to the time required for Amazon MSK to complete the detection and recovery. After a recovery, your producer and consumer apps can continue to communicate with the same broker IP addresses that they used before the failure.","title":"Cluster"},{"location":"day1/part1/overview/exercise/#architecture","text":"The diagram demonstrates the interaction between the following components:","title":"Architecture"},{"location":"day1/part1/overview/exercise/#broker-nodes","text":"When creating an Amazon MSK cluster, you specify how many broker nodes you want Amazon MSK to create in each Availability Zone. In the example cluster shown in this diagram, there's one broker per Availability Zone. Each Availability Zone has its own virtual private cloud (VPC) subnet. Amazon MSK offers a 3 AZ or a 2 AZ Apache Kafka node layout. Currently, a 1 AZ (single AZ) Amazon MSK cluster is not available.","title":"Broker nodes"},{"location":"day1/part1/overview/exercise/#zookeeper-nodes","text":"Amazon MSK also creates the Apache ZooKeeper nodes for you. Apache ZooKeeper is an open-source server that enables highly reliable, distributed coordination. There is a dedicated ZooKeeper ensemble created for each Amazon MSK cluster that is fully obfuscated and included with each cluster at no additional cost.","title":"ZooKeeper nodes"},{"location":"day1/part1/overview/exercise/#producers-consumers-and-topic-creators","text":"Amazon MSK lets you use Apache Kafka data-plane operations to create topics and to produce and consume data.** AWS CLI - You can use the AWS Command Line Interface (AWS CLI) or the APIs in the SDK to perform control-plane operations. For example, you can use the AWS CLI or the SDK to create or delete an Amazon MSK cluster, list all the clusters in an account, or view the properties of a cluster.","title":"Producers, consumers, and topic creators"},{"location":"day1/part2/intro/exercise/","text":"Introduction \u00b6 Open monitoring with Prometheus in Amazon Managed Streaming for Apache Kafka (MSK) refers to the integration of Prometheus, an open-source monitoring and alerting toolkit, with Amazon MSK clusters. Prometheus is a popular monitoring solution widely used in the cloud-native ecosystem. With open monitoring, you can collect metrics and monitor the health and performance of your Kafka clusters. Prometheus, in conjunction with other tools such as Grafana, allows you to gather, store, and analyze various metrics related to your Kafka cluster, such as broker and topic-level statistics, consumer lag, and network throughput. By following this workshop, you will be able to establish a comprehensive monitoring system for your Amazon MSK cluster and gain valuable insights into its performance and health.","title":"1 - Overview"},{"location":"day1/part2/intro/exercise/#introduction","text":"Open monitoring with Prometheus in Amazon Managed Streaming for Apache Kafka (MSK) refers to the integration of Prometheus, an open-source monitoring and alerting toolkit, with Amazon MSK clusters. Prometheus is a popular monitoring solution widely used in the cloud-native ecosystem. With open monitoring, you can collect metrics and monitor the health and performance of your Kafka clusters. Prometheus, in conjunction with other tools such as Grafana, allows you to gather, store, and analyze various metrics related to your Kafka cluster, such as broker and topic-level statistics, consumer lag, and network throughput. By following this workshop, you will be able to establish a comprehensive monitoring system for your Amazon MSK cluster and gain valuable insights into its performance and health.","title":"Introduction"},{"location":"day1/part2/run_grafana/exercise/","text":"Run Grafana using Docker \u00b6 Our plan involves utilizing Grafana, an effective tool for visualizing and creating dashboards, to display the metrics of an MSK cluster and its topics. These metrics are collected by Prometheus, which provides a functional interface for reviewing individual metrics. However, when operating Amazon MSK in a production environment, it is preferable to have comprehensive and visually appealing dashboards. To simplify the process, we will use Docker to run Grafana within the Cloud9 IDE environment. This approach ensures simplicity and ease of use. Launch a shell within the Cloud9 environment. Initiate Grafana using Docker by executing the following command: docker run -d -p 3000 :3000 --name = grafana -e \"GF_INSTALL_PLUGINS=grafana-clock-panel\" grafana/grafana This command starts a Docker container named \"grafana\" based on the Grafana image. The container is set to run in detached mode (-d), and it maps port 3000 of the container to port 3000 of the host. Access Grafana by opening a web browser and entering the Cloud9 public IP Address followed by port 3000 (http://$CLOUD9_EXTERNAL:3000). This allows you to connect to the Grafana user interface. Log in to Grafana using the username \"admin\" and password \"admin\". Configure Grafana \u00b6 Now, we need to configure a Data Source to fetch Time Series data from Prometheus. Follow these steps: Click on the \"Add Data Source\" option. Hover over the \"Prometheus\" option and click on the \"Select\" button. Fill out the configuration details as follows: URL: Enter http://$CLOUD9_INTERNAL:9090. Access: Keep the default setting as \"Server\". Please note that when configuring the URL for the Prometheus Data Source , you should use the Private IPv4 address of your Cloud9 environment . This address ensures that the communication between Grafana and Prometheus remains within the private network . Replace the placeholder $C LOUD9_INTERNAL with the actual Private IPv4 address of your Cloud9 environment when filling out the configuration . Click on \"Save and Test\". If everything is set up correctly, the test results should come back as green, indicating that the Data Source is functioning properly. If you encounter an error, double-check if your security groups were properly set up during the preparation step. On the Configuration page, locate the \"Dashboards\" option at the top and click on it. Then, select \"Import\" next to the \"Prometheus 2.0 Stats\" option. This action will import a pre-built dashboard specifically designed for monitoring the Prometheus service itself. Import Grafana Dashboard \u00b6 Download this file to your workstation. This file contains the configuration for a basic Grafana dashboard that provides an overview of your MSK cluster using metrics collected by Prometheus. Return to the Grafana user interface in your web browser. In the left pane, click on the Dashboard icon, typically represented by four squares. Click on the \"New\" option. Click on the \"Import\" button. On the top of the screen, click on \"Upload .json file.\" Select the JSON file you previously downloaded (msk_grafana_dashboard.json) from your workstation. After clicking the \"Import\" button and successfully uploading the JSON file, you will be directed to a screen that displays the imported Grafana dashboard. This screen will resemble the provided screenshot, showing the newly imported dashboard for your MSK cluster. The displayed Grafana dashboard is designed to showcase the metrics collected from your Amazon MSK cluster through the Prometheus service. It provides visual representations and insights into various aspects of your MSK cluster's performance, allowing you to monitor and analyze key metrics in real-time. With this dashboard, you can gain a thorough understanding of the health and behavior of your MSK cluster, facilitating effective management and troubleshooting.","title":"4 - Run Grafana"},{"location":"day1/part2/run_grafana/exercise/#run-grafana-using-docker","text":"Our plan involves utilizing Grafana, an effective tool for visualizing and creating dashboards, to display the metrics of an MSK cluster and its topics. These metrics are collected by Prometheus, which provides a functional interface for reviewing individual metrics. However, when operating Amazon MSK in a production environment, it is preferable to have comprehensive and visually appealing dashboards. To simplify the process, we will use Docker to run Grafana within the Cloud9 IDE environment. This approach ensures simplicity and ease of use. Launch a shell within the Cloud9 environment. Initiate Grafana using Docker by executing the following command: docker run -d -p 3000 :3000 --name = grafana -e \"GF_INSTALL_PLUGINS=grafana-clock-panel\" grafana/grafana This command starts a Docker container named \"grafana\" based on the Grafana image. The container is set to run in detached mode (-d), and it maps port 3000 of the container to port 3000 of the host. Access Grafana by opening a web browser and entering the Cloud9 public IP Address followed by port 3000 (http://$CLOUD9_EXTERNAL:3000). This allows you to connect to the Grafana user interface. Log in to Grafana using the username \"admin\" and password \"admin\".","title":"Run Grafana using Docker"},{"location":"day1/part2/run_grafana/exercise/#configure-grafana","text":"Now, we need to configure a Data Source to fetch Time Series data from Prometheus. Follow these steps: Click on the \"Add Data Source\" option. Hover over the \"Prometheus\" option and click on the \"Select\" button. Fill out the configuration details as follows: URL: Enter http://$CLOUD9_INTERNAL:9090. Access: Keep the default setting as \"Server\". Please note that when configuring the URL for the Prometheus Data Source , you should use the Private IPv4 address of your Cloud9 environment . This address ensures that the communication between Grafana and Prometheus remains within the private network . Replace the placeholder $C LOUD9_INTERNAL with the actual Private IPv4 address of your Cloud9 environment when filling out the configuration . Click on \"Save and Test\". If everything is set up correctly, the test results should come back as green, indicating that the Data Source is functioning properly. If you encounter an error, double-check if your security groups were properly set up during the preparation step. On the Configuration page, locate the \"Dashboards\" option at the top and click on it. Then, select \"Import\" next to the \"Prometheus 2.0 Stats\" option. This action will import a pre-built dashboard specifically designed for monitoring the Prometheus service itself.","title":"Configure Grafana"},{"location":"day1/part2/run_grafana/exercise/#import-grafana-dashboard","text":"Download this file to your workstation. This file contains the configuration for a basic Grafana dashboard that provides an overview of your MSK cluster using metrics collected by Prometheus. Return to the Grafana user interface in your web browser. In the left pane, click on the Dashboard icon, typically represented by four squares. Click on the \"New\" option. Click on the \"Import\" button. On the top of the screen, click on \"Upload .json file.\" Select the JSON file you previously downloaded (msk_grafana_dashboard.json) from your workstation. After clicking the \"Import\" button and successfully uploading the JSON file, you will be directed to a screen that displays the imported Grafana dashboard. This screen will resemble the provided screenshot, showing the newly imported dashboard for your MSK cluster. The displayed Grafana dashboard is designed to showcase the metrics collected from your Amazon MSK cluster through the Prometheus service. It provides visual representations and insights into various aspects of your MSK cluster's performance, allowing you to monitor and analyze key metrics in real-time. With this dashboard, you can gain a thorough understanding of the health and behavior of your MSK cluster, facilitating effective management and troubleshooting.","title":"Import Grafana Dashboard"},{"location":"day1/part2/run_prometheus/exercise/","text":"Run Prometheus using Docker \u00b6 Open Cloud9 terminal. Create a prometheus directory to work in mkdir prometheus cd prometheus Create a service configuration file and name it prometheus.yml # file: prometheus.yml # my global config global : scrape_interval : 10s # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs : # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config. - job_name : 'prometheus' static_configs : # 9090 is the prometheus server port - targets : [ 'localhost:9090' ] - job_name : 'broker' file_sd_configs : - files : - 'targets.json' Navigate to the Cluster details section, and under the Properties tab, copy the broker endpoints. Please create a new file called targets.json . In this file, replace the placeholders <broker_dns_[1,2,N]> with the actual values of your broker endpoints that were collected in step 3. [ { \"labels\" : { \"job\" : \"jmx\" }, \"targets\" : [ \"<broker_dns_1>:11001\" , \"<broker_dns_2>:11001\" , \"<broker_dns_N>:11001\" ] }, { \"labels\" : { \"job\" : \"node\" }, \"targets\" : [ \"<broker_dns_1>:11002\" , \"<broker_dns_2>:11002\" , \"<broker_dns_N>:11002\" ] } ] To run Prometheus on Docker, execute the following command: sudo docker run -d -p 9090 :9090 --name = prometheus -v /home/ec2-user/environment/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml -v /home/ec2-user/environment/prometheus/targets.json:/etc/prometheus/targets.json prom/prometheus --config.file = /etc/prometheus/prometheus.yml This command will pull down the Prometheus container, run it, and mount the configuration files created earlier into the container. Additionally, it will expose the Prometheus service on port 9090. Before running Prometheus on Docker, please double-check and ensure the correct path to your configuration files. Make sure the path you provide in the command reflects the actual location of the configuration files on your system. Docker Basics \u00b6 The container will run in the background, allowing other tasks to proceed concurrently. To check the logs, execute the following command: sudo docker logs <containerID> To terminate the container, you can use the following command: sudo docker stop prometheus To completely remove the container, you must first stop it using the command mentioned earlier. Once the container is stopped, you can proceed to remove it using the following command: sudo docker rm prometheus Update Security Group on your Cloud9 instance for Prometheus and Grafana \u00b6 To configure the inbound rules for the AWS Cloud9 security group, follow these steps: Open the EC2 service in the AWS Management Console. Select \"Security Groups\" from the navigation menu. Locate and select the checkbox next to the security group named \"aws-cloud9-msklab...\". Click on the \"Actions\" button and choose \"Edit Inbound Rules\" from the dropdown menu. Click on the \"Add Rule\" button to add the following rules: Rule 1 - Prometheus: Type: Custom TCP Port Range: 9090 Source: MyIP and add the security group \"aws-cloud9-msklab...\" (the group you're editing) as well Description: Prometheus Rule 2 - Grafana: Type: Custom TCP Port Range: 3000 Source: MyIP Description: Grafana Once you have added both rules, click on the \"Save Rules\" button located at the bottom right corner of the window. Connect to Prometheus User Interface \u00b6 To obtain the IPv4 Public IP address of your AWS Cloud9 instance, follow these steps: Open the AWS Management Console. Switch to the EC2 service. Locate and click on your Cloud9 instance in the list. In the details pane at the bottom, find the \"IPv4 Public IP\" field. Copy the IPv4 Public IP address displayed in that field. Open your web browser and enter the following URL in the address bar, replacing <IPv4 Public IP> with the IPv4 Public IP address you copied earlier: http://<IPv4 Public IP>:9090 Please note that the instructions provided assume that you have already launched and can access your AWS Cloud9 instance.","title":"3 - Run Prometheus"},{"location":"day1/part2/run_prometheus/exercise/#run-prometheus-using-docker","text":"Open Cloud9 terminal. Create a prometheus directory to work in mkdir prometheus cd prometheus Create a service configuration file and name it prometheus.yml # file: prometheus.yml # my global config global : scrape_interval : 10s # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs : # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config. - job_name : 'prometheus' static_configs : # 9090 is the prometheus server port - targets : [ 'localhost:9090' ] - job_name : 'broker' file_sd_configs : - files : - 'targets.json' Navigate to the Cluster details section, and under the Properties tab, copy the broker endpoints. Please create a new file called targets.json . In this file, replace the placeholders <broker_dns_[1,2,N]> with the actual values of your broker endpoints that were collected in step 3. [ { \"labels\" : { \"job\" : \"jmx\" }, \"targets\" : [ \"<broker_dns_1>:11001\" , \"<broker_dns_2>:11001\" , \"<broker_dns_N>:11001\" ] }, { \"labels\" : { \"job\" : \"node\" }, \"targets\" : [ \"<broker_dns_1>:11002\" , \"<broker_dns_2>:11002\" , \"<broker_dns_N>:11002\" ] } ] To run Prometheus on Docker, execute the following command: sudo docker run -d -p 9090 :9090 --name = prometheus -v /home/ec2-user/environment/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml -v /home/ec2-user/environment/prometheus/targets.json:/etc/prometheus/targets.json prom/prometheus --config.file = /etc/prometheus/prometheus.yml This command will pull down the Prometheus container, run it, and mount the configuration files created earlier into the container. Additionally, it will expose the Prometheus service on port 9090. Before running Prometheus on Docker, please double-check and ensure the correct path to your configuration files. Make sure the path you provide in the command reflects the actual location of the configuration files on your system.","title":"Run Prometheus using Docker"},{"location":"day1/part2/run_prometheus/exercise/#docker-basics","text":"The container will run in the background, allowing other tasks to proceed concurrently. To check the logs, execute the following command: sudo docker logs <containerID> To terminate the container, you can use the following command: sudo docker stop prometheus To completely remove the container, you must first stop it using the command mentioned earlier. Once the container is stopped, you can proceed to remove it using the following command: sudo docker rm prometheus","title":"Docker Basics"},{"location":"day1/part2/run_prometheus/exercise/#update-security-group-on-your-cloud9-instance-for-prometheus-and-grafana","text":"To configure the inbound rules for the AWS Cloud9 security group, follow these steps: Open the EC2 service in the AWS Management Console. Select \"Security Groups\" from the navigation menu. Locate and select the checkbox next to the security group named \"aws-cloud9-msklab...\". Click on the \"Actions\" button and choose \"Edit Inbound Rules\" from the dropdown menu. Click on the \"Add Rule\" button to add the following rules: Rule 1 - Prometheus: Type: Custom TCP Port Range: 9090 Source: MyIP and add the security group \"aws-cloud9-msklab...\" (the group you're editing) as well Description: Prometheus Rule 2 - Grafana: Type: Custom TCP Port Range: 3000 Source: MyIP Description: Grafana Once you have added both rules, click on the \"Save Rules\" button located at the bottom right corner of the window.","title":"Update Security Group on your Cloud9 instance for Prometheus and Grafana"},{"location":"day1/part2/run_prometheus/exercise/#connect-to-prometheus-user-interface","text":"To obtain the IPv4 Public IP address of your AWS Cloud9 instance, follow these steps: Open the AWS Management Console. Switch to the EC2 service. Locate and click on your Cloud9 instance in the list. In the details pane at the bottom, find the \"IPv4 Public IP\" field. Copy the IPv4 Public IP address displayed in that field. Open your web browser and enter the following URL in the address bar, replacing <IPv4 Public IP> with the IPv4 Public IP address you copied earlier: http://<IPv4 Public IP>:9090 Please note that the instructions provided assume that you have already launched and can access your AWS Cloud9 instance.","title":"Connect to Prometheus User Interface"},{"location":"day1/part2/setup/exercise/","text":"Step 1 - Enabling open monitoring for an existing Amazon MSK cluster \u00b6 To enable open monitoring, make sure that the cluster is in the ACTIVE state. Using the AWS Management Console 1. Sign in to the AWS Management Console, and open the Amazon MSK console at https://console.aws.amazon.com/msk/home?region=us-east-1#/home/. 2. Choose the name of the cluster that you want to update. This takes you to a page the contains details for the cluster. 3. On the Properties tab, scroll down to find the Monitoring section. 4. Choose Edit. 5. Select the check box next to Enable open monitoring with Prometheus. 6. Choose Save changes. Step 2 - Create Security group rules to allow monitoring access \u00b6 Step 2.1 Create new security group \u00b6 Start by creating a new security group called \"MSK_Monitoring\" without any rules. Navigate to the EC2 service and choose the \"Security Groups\" option in the left-side menu. At the top of the screen, click on \"Create Security Group.\" Provide the name \"MSK_Monitoring\" for the security group. Add a description explaining that it allows access to MSK monitoring from monitoring services. Make sure to select the VPC (Virtual Private Cloud) where your Amazon MSK Cluster is deployed, which is referred to as \"MSKVPC.\" After confirming the settings, click on \"Create\" without adding any specific rules. Step 2.2 Modify the MSK Workshop Service \u00b6 Access the EC2 service and navigate to the \"Security Groups\" section. Locate the security group named \"MSKWorkshop-KafkaService\" and select it. Click on the \"Actions\" button and then select \"Edit inbound rules\" to modify the security group's rules. Add a new rule with the following specifications: Type: Custom TCP Port: 11001-11002 Source: Select the \"MSK_Monitoring\" security group Description: Specify \"Prometheus monitoring\" By following these steps, you will open the \"MSKWorkshop-KafkaService\" security group, add a custom TCP rule for ports 11001 to 11002, allowing access from the \"MSK_Monitoring\" security group. The purpose of this rule is to enable Prometheus monitoring. Step 2.3 Attach the MSK_Monitoring SG to your Cloud9 instance \u00b6 Open the EC2 console and navigate to the \"Instances\" section. Locate your Cloud9 host with the name \"aws-cloud9-msklab..\" in the list of instances. Click on \"Actions\" from the top bar. From the dropdown menu, select \"Security\" and then choose \"Change Security Groups.\" Search for the \"MSK_Monitoring\" security group and select it. Click on \"Add security group\" to include the \"MSK_Monitoring\" group in the Cloud9 instance's security configuration. Finally, press \"Save\" in the bottom right corner to save the changes.","title":"2 - Setup"},{"location":"day1/part2/setup/exercise/#step-1-enabling-open-monitoring-for-an-existing-amazon-msk-cluster","text":"To enable open monitoring, make sure that the cluster is in the ACTIVE state. Using the AWS Management Console 1. Sign in to the AWS Management Console, and open the Amazon MSK console at https://console.aws.amazon.com/msk/home?region=us-east-1#/home/. 2. Choose the name of the cluster that you want to update. This takes you to a page the contains details for the cluster. 3. On the Properties tab, scroll down to find the Monitoring section. 4. Choose Edit. 5. Select the check box next to Enable open monitoring with Prometheus. 6. Choose Save changes.","title":"Step 1 - Enabling open monitoring for an existing Amazon MSK cluster"},{"location":"day1/part2/setup/exercise/#step-2-create-security-group-rules-to-allow-monitoring-access","text":"","title":"Step 2 - Create Security group rules to allow monitoring access"},{"location":"day1/part2/setup/exercise/#step-21-create-new-security-group","text":"Start by creating a new security group called \"MSK_Monitoring\" without any rules. Navigate to the EC2 service and choose the \"Security Groups\" option in the left-side menu. At the top of the screen, click on \"Create Security Group.\" Provide the name \"MSK_Monitoring\" for the security group. Add a description explaining that it allows access to MSK monitoring from monitoring services. Make sure to select the VPC (Virtual Private Cloud) where your Amazon MSK Cluster is deployed, which is referred to as \"MSKVPC.\" After confirming the settings, click on \"Create\" without adding any specific rules.","title":"Step 2.1 Create new security group"},{"location":"day1/part2/setup/exercise/#step-22-modify-the-msk-workshop-service","text":"Access the EC2 service and navigate to the \"Security Groups\" section. Locate the security group named \"MSKWorkshop-KafkaService\" and select it. Click on the \"Actions\" button and then select \"Edit inbound rules\" to modify the security group's rules. Add a new rule with the following specifications: Type: Custom TCP Port: 11001-11002 Source: Select the \"MSK_Monitoring\" security group Description: Specify \"Prometheus monitoring\" By following these steps, you will open the \"MSKWorkshop-KafkaService\" security group, add a custom TCP rule for ports 11001 to 11002, allowing access from the \"MSK_Monitoring\" security group. The purpose of this rule is to enable Prometheus monitoring.","title":"Step 2.2 Modify the MSK Workshop Service"},{"location":"day1/part2/setup/exercise/#step-23-attach-the-msk_monitoring-sg-to-your-cloud9-instance","text":"Open the EC2 console and navigate to the \"Instances\" section. Locate your Cloud9 host with the name \"aws-cloud9-msklab..\" in the list of instances. Click on \"Actions\" from the top bar. From the dropdown menu, select \"Security\" and then choose \"Change Security Groups.\" Search for the \"MSK_Monitoring\" security group and select it. Click on \"Add security group\" to include the \"MSK_Monitoring\" group in the Cloud9 instance's security configuration. Finally, press \"Save\" in the bottom right corner to save the changes.","title":"Step 2.3 Attach the MSK_Monitoring SG to your Cloud9 instance"},{"location":"day2/part3/1_intro/exercise/","text":"Migrate to Amazon MSK Serverless \u00b6 In this section, we will be performing a migration from Amazon MSK to Amazon MSK Serverless with the help of MirrorMaker 2 . Go to your event dashboard . Select Accept Terms and Conditions and click on Join event . Click on Open AWS console (us-east-1) on the bottom left. Once logged in, go to your CloudFormation console . You should be able to see the following 3 CloudFormation stacks in your account in CREATE_COMPLETE state. If you see these stacks, go to next page. If you do not see the stacks in your assigned account, launch the following CFN stack in N. Virginia (us-east-1) region. Make sure that the stack name is \"msk- \". For example: msk-team20 . Provide ws-default-keypair as the PEM key and /aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2 as LatestAmiId. Accept the IAM capabilities and launch the stack. The stacks take about 25-30 minutes to launch successfully.","title":"1 - Introduction"},{"location":"day2/part3/1_intro/exercise/#migrate-to-amazon-msk-serverless","text":"In this section, we will be performing a migration from Amazon MSK to Amazon MSK Serverless with the help of MirrorMaker 2 . Go to your event dashboard . Select Accept Terms and Conditions and click on Join event . Click on Open AWS console (us-east-1) on the bottom left. Once logged in, go to your CloudFormation console . You should be able to see the following 3 CloudFormation stacks in your account in CREATE_COMPLETE state. If you see these stacks, go to next page. If you do not see the stacks in your assigned account, launch the following CFN stack in N. Virginia (us-east-1) region. Make sure that the stack name is \"msk- \". For example: msk-team20 . Provide ws-default-keypair as the PEM key and /aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2 as LatestAmiId. Accept the IAM capabilities and launch the stack. The stacks take about 25-30 minutes to launch successfully.","title":"Migrate to Amazon MSK Serverless"},{"location":"day2/part3/2_labsetup/exercise/","text":"Lab Setup \u00b6 Setup SSH Keys in Cloud9 Enviroment \u00b6 Go to your event dashboard and click on Get EC2 SSH Key on the bottom left. Download the keypair ws-default-keypair.pem Now, go to the AWS Cloud9 console . You will see a Cloud9 environment with the name msk-teamXX-Cloud9EC2Bastion . Open the Cloud9 IDE. In the Getting started section, click on Upload files Click on Select files . Pick the ws-default-keypair.pem file from your desktop. Click Open . The file will be copied to the /home/ec2-user/environment dir and will also be visible in the left pane. Go to the bash pane at the bottom (you can enlarge the section if you want) and type in the following commands to setup the ssh environment so that you can access the Kafka Client EC2 instances. Run the following commands. chmod 600 ws-default-keypair.pem eval `ssh-agent` ssh-add -k ws-default-keypair.pem","title":"2 - Lab Setup"},{"location":"day2/part3/2_labsetup/exercise/#lab-setup","text":"","title":"Lab Setup"},{"location":"day2/part3/2_labsetup/exercise/#setup-ssh-keys-in-cloud9-enviroment","text":"Go to your event dashboard and click on Get EC2 SSH Key on the bottom left. Download the keypair ws-default-keypair.pem Now, go to the AWS Cloud9 console . You will see a Cloud9 environment with the name msk-teamXX-Cloud9EC2Bastion . Open the Cloud9 IDE. In the Getting started section, click on Upload files Click on Select files . Pick the ws-default-keypair.pem file from your desktop. Click Open . The file will be copied to the /home/ec2-user/environment dir and will also be visible in the left pane. Go to the bash pane at the bottom (you can enlarge the section if you want) and type in the following commands to setup the ssh environment so that you can access the Kafka Client EC2 instances. Run the following commands. chmod 600 ws-default-keypair.pem eval `ssh-agent` ssh-add -k ws-default-keypair.pem","title":"Setup SSH Keys in Cloud9 Enviroment"},{"location":"day2/part3/3_monitoring/exercise/","text":"Setup Monitoring \u00b6 In this section, we will setup Grafana and Prometheus for monitoring MirrorMaker. Monitoring MirrorMaker 2 on Kafka Connect \u00b6 Using same bash, download the monitoring setup script from s3 and make it executable by running the following command on Cloud9 terminal aws s3 cp s3://aws-streaming-artifacts/msk-lab-resources/setup-monitoring.sh /home/ec2-user/environment && chmod +x setup-monitoring.sh Example: Now, let's run the monitoring setup script Get the CloudFormation stack name which looks like msk-teamxx . For example: msk-team22 . The IP address is the IP that will be given access to the Grafana and Prometheus dashboard urls. Easy way to get your local desktop IP address is to go to EC2 Security Groups Console . Open any security group in your account and click on Edit inbound rules . Click on Add rule and under Source , select My IP . Make a note of your IP address. You can cancel the changes since we are not actually trying to edit the Inbound Rules of any security group. Now, run the following command: . / setup - monitoring . sh < stackName > < region > < IPAddress of laptop / 32 > < filesystem location to install grafana and prometheus > Example: In the Output check to make sure both the grafana-server and the prometheus services are running. Run the following commands to get the URL of grafana (first one) and prometheus (second one) servers: echo \"http://$(curl -X GET http://169.254.169.254/latest/meta-data/public-hostname):3000\" echo \"http://$(curl -X GET http://169.254.169.254/latest/meta-data/public-hostname):9090\" Go to a browser window and paste in the URL for grafana (first one). Then in the login screen type in admin for username and admin for password. You will be asked to change the password. Please provide a new password and note it down. For the sake of this lab, you can also use admin so that you do not forget. You will now see the home page. On the left panel, click on the gear icon and click on Data Sources . A prometheus data source is already configured for you. Click on prometheus1 . Scroll down and click on Save & Test . You should get a message saying Data source is working . Click on the Dashboard icon in the left panel. Then click on Manage . In the bottom panel, click on MirrorMaker2 . Then click on MM2 . The pre-created dashboard will launch. However, you won't see any data yet. Later, when you start the Clickstream producer, consumer and MM2, this dashboard will start getting populated with data. We will come back to the same dashboard and periodically hit the refresh button in the top right corner or adjust the time range to show data in the graph. The most important metric here is the MM2-Consumer-Lag . It indicates how far behind the end of the log for each partition in the ExampleTopic in the source Amazon MSK cluster, the MM2 consumer is. In this graph, I had started the producer first and some time later started MM2. You can see that the lag was pretty high but then dropped to zero as the consumers caught up. Before cutting over the producer, check to make sure that the lag is zero to avoid ordering issues.","title":"3 - Setup Monitoring"},{"location":"day2/part3/3_monitoring/exercise/#setup-monitoring","text":"In this section, we will setup Grafana and Prometheus for monitoring MirrorMaker.","title":"Setup Monitoring"},{"location":"day2/part3/3_monitoring/exercise/#monitoring-mirrormaker-2-on-kafka-connect","text":"Using same bash, download the monitoring setup script from s3 and make it executable by running the following command on Cloud9 terminal aws s3 cp s3://aws-streaming-artifacts/msk-lab-resources/setup-monitoring.sh /home/ec2-user/environment && chmod +x setup-monitoring.sh Example: Now, let's run the monitoring setup script Get the CloudFormation stack name which looks like msk-teamxx . For example: msk-team22 . The IP address is the IP that will be given access to the Grafana and Prometheus dashboard urls. Easy way to get your local desktop IP address is to go to EC2 Security Groups Console . Open any security group in your account and click on Edit inbound rules . Click on Add rule and under Source , select My IP . Make a note of your IP address. You can cancel the changes since we are not actually trying to edit the Inbound Rules of any security group. Now, run the following command: . / setup - monitoring . sh < stackName > < region > < IPAddress of laptop / 32 > < filesystem location to install grafana and prometheus > Example: In the Output check to make sure both the grafana-server and the prometheus services are running. Run the following commands to get the URL of grafana (first one) and prometheus (second one) servers: echo \"http://$(curl -X GET http://169.254.169.254/latest/meta-data/public-hostname):3000\" echo \"http://$(curl -X GET http://169.254.169.254/latest/meta-data/public-hostname):9090\" Go to a browser window and paste in the URL for grafana (first one). Then in the login screen type in admin for username and admin for password. You will be asked to change the password. Please provide a new password and note it down. For the sake of this lab, you can also use admin so that you do not forget. You will now see the home page. On the left panel, click on the gear icon and click on Data Sources . A prometheus data source is already configured for you. Click on prometheus1 . Scroll down and click on Save & Test . You should get a message saying Data source is working . Click on the Dashboard icon in the left panel. Then click on Manage . In the bottom panel, click on MirrorMaker2 . Then click on MM2 . The pre-created dashboard will launch. However, you won't see any data yet. Later, when you start the Clickstream producer, consumer and MM2, this dashboard will start getting populated with data. We will come back to the same dashboard and periodically hit the refresh button in the top right corner or adjust the time range to show data in the graph. The most important metric here is the MM2-Consumer-Lag . It indicates how far behind the end of the log for each partition in the ExampleTopic in the source Amazon MSK cluster, the MM2 consumer is. In this graph, I had started the producer first and some time later started MM2. You can see that the lag was pretty high but then dropped to zero as the consumers caught up. Before cutting over the producer, check to make sure that the lag is zero to avoid ordering issues.","title":"Monitoring MirrorMaker 2 on Kafka Connect"},{"location":"day2/part3/4_premigration/exercise/","text":"Setup pre-migration environment \u00b6 Simulate pre-migration producer and consumerHeader anchor link \u00b6 In this section of the lab, we will be simulating a pre-migration environment with an existing Apache Kafka source cluster (in this lab, this will be an AWS MSK cluster, but it doesn't have to be). This source cluster will have one topic (ExampleTopic), one producer producing to this topic, and a consumer reading from this topic. We will setup a sample source cluster used to simulate existing cluster. Start a producer against the source Amazon MSK cluster \u00b6 In the Cloud9 terminal, lets setup environment variables and connect to KafkaClientInstance1 export MSK_STACK =<< Stack Name >> # Looks like msk-team22 for example export ssh_cmd1 = $ ( aws cloudformation describe - stacks -- stack - name $MSK_STACK -- query 'Stacks[0].Outputs[?OutputKey==`SSHKafkaClientEC2Instance1`].OutputValue' -- output text ) $ssh_cmd1 Answer yes to \"Are you sure you want to continue connecting (yes/no)\" and you should be connected to KafkaClientInstance1 . Go to the /tmp/kafka directory and take a quick look where configuration files and scripts have already been downloaded to this EC2 instance. cd /tmp/kafka ls -l We will be using many of these files in the following steps of this lab. Get MSK Cluster client information Go to the Amazon MSK console . Click on the Provisioned MSK cluster that was created by CloudFormation (default name: MSKSrc-XXXX ) Click on View client information on the top right side of the page under Cluster summary . Click on Copy under Bootstrap servers and paste it in a notepad application. Repeat the same steps for the Serverless MSK Cluster that was created by CloudFormation (default name: MSKServerlessDest ) Run Environment Variable setup script We use various environment variables in this lab, so let's run a small shell script to make things more convenient. export brokersmsksource =< Source Bootstrap servers address > export brokersmskdest =< Serverless Bootstrap servers address > Example: We add some variables to the bash profile and will verify the variables are set correctly, with the final \"echo\" statement. export region =$ ( curl http : // 169.254 . 169.254 / latest / meta - data / placement / region ) echo \"export brokersmsksource=${brokersmsksource}\" | tee - a ~/. bash_profile echo \"export brokersmskdest=${brokersmskdest}\" | tee - a ~/. bash_profile You should see a value from the last echo command. Make sure you see a value for $brokersmsksource before proceeding. Next, we configure the KafkaClientInstance1 with Amazon MSK IAM authentication client. cd / home / ec2 - user / kafka / libs wget https : // github . com / aws / aws - msk - iam - auth / releases / download / 1.1 . 0 / aws - msk - iam - auth - 1.1 . 0 - all . jar cd / home / ec2 - user mkdir iam - auth && cd ./ iam - auth wget https : // github . com / aws / aws - msk - iam - auth / releases / download / 1.1 . 0 / aws - msk - iam - auth - 1.1 . 0 - all . jar cd ../ cat << EOF > / home / ec2 - user / kafka / config / client - config . properties # Sets up TLS for encryption and SASL for authN. security . protocol = SASL_SSL # Identifies the SASL mechanism to use. sasl . mechanism = AWS_MSK_IAM # Binds SASL client implementation. sasl . jaas . config = software . amazon . msk . auth . iam . IAMLoginModule required ; # Encapsulates constructing a SigV4 signature based on extracted credentials. # The SASL client bound by \"sasl.jaas.config\" invokes this class. sasl . client . callback . handler . class = software . amazon . msk . auth . iam . IAMClientCallbackHandler EOF export CLASSPATH =/ home / ec2 - user / iam - auth / aws - msk - iam - auth - 1.1 . 0 - all . jar echo \"export CLASSPATH=${CLASSPATH}\" | tee - a ~/. bash_profile Let's go to the /home/ec2-user/kafka dir and create a topic called ExampleTopic . cd /home/ec2-user/kafka bin/kafka-topics.sh --create --bootstrap-server=$brokersmsksource --command-config /home/ec2-user/kafka/config/client-config.properties --replication-factor 3 --partitions 3 --topic ExampleTopic Setup the Producer settings (including Glue Schema Registry and Monitoring) cd / tmp / kafka cp producer . properties_msk producer . properties_msk_dest sed - i - e \"s/BOOTSTRAP_SERVERS_CONFIG=/BOOTSTRAP_SERVERS_CONFIG=$brokersmsksource/g\" producer . properties_msk export schema_compatibility = FULL_ALL export EXTRA_ARGS =- javaagent : / home / ec2 - user / prometheus / jmx_prometheus_javaagent - 0.13 . 0.j ar = 3800 : / home / ec2 - user / prometheus / kafka - producer - consumer . yml Run the Producer and confirm the log output java $EXTRA_ARGS - jar KafkaClickstreamClient - 1.0 - SNAPSHOT . jar - t ExampleTopic - pfp / tmp / kafka / producer . properties_msk - nt 8 - rf 10800 - nle - gsr - gsrr $region - iam - gar - gcs $schema_compatibility > / tmp / producer . log 2 >& 1 & To kill the producer before the 3 hours are up, note down the pid (process id) of the producer process. Use kill to kill the process. The javaagent is a Prometheus JMX exporter that will export the Apacke Kafka producer metrics for Prometheus to scrape and store for queries and visualization. To get the source code of the producer see github . The output of the previous command: Tail the producer log file to see the producer sending events. Ctrl-C to exit from the tail command. tail -f /tmp/producer.log [Optional] Check to see if the schema got registered in Schema Registry. In the AWS Glue Console , under Schema registries -> Schemas , you should see the ExampleTopic registered as the Producer was run with Glue Schema Registry args: -gsr -gsrr $region -gar -gcs $schema_compatibility Run a Consumer \u00b6 Now, let's configure and run a Kafka Consumer application reading from the previously created ExampleTopic. Setup Consumer environment settings cd / tmp / kafka cp consumer . properties consumer . properties_dest sed - i - e \"s/BOOTSTRAP_SERVERS_CONFIG=/BOOTSTRAP_SERVERS_CONFIG=$brokersmsksource/g\" consumer . properties export EXTRA_ARGS =- javaagent : / home / ec2 - user / prometheus / jmx_prometheus_javaagent - 0.13 . 0.j ar = 3900 : / home / ec2 - user / prometheus / kafka - producer - consumer . yml Run the Clickstream consumer. The consumer will run in the background for 3 hours. To kill the consumer before the 3 hours are up, note down the pid (process id) of the consumer process. Use kill to kill the process. The javaagent is a Prometheus JMX exporter that will export the Apacke Kafka consumer metrics for Prometheus to scrape and store for queries and visualization.* To get the source code of the consumer see github . java $EXTRA_ARGS - jar KafkaClickstreamConsumer - 1.0 - SNAPSHOT . jar - t ExampleTopic - pfp / tmp / kafka / consumer . properties - nt 3 - rf 10800 - src msksource - gsr - iam - gsrr $region > / tmp / consumer . log 2 >& 1 & The output of the previous command should be similar to this: Tail the consumer log file to see the consumer reading messages and making progress. Ctrl-C to exit from the tail command. tail -f /tmp/consumer.log","title":"4 - Setup Pre-migration Environment"},{"location":"day2/part3/4_premigration/exercise/#setup-pre-migration-environment","text":"","title":"Setup pre-migration environment"},{"location":"day2/part3/4_premigration/exercise/#simulate-pre-migration-producer-and-consumerheader-anchor-link","text":"In this section of the lab, we will be simulating a pre-migration environment with an existing Apache Kafka source cluster (in this lab, this will be an AWS MSK cluster, but it doesn't have to be). This source cluster will have one topic (ExampleTopic), one producer producing to this topic, and a consumer reading from this topic. We will setup a sample source cluster used to simulate existing cluster.","title":"Simulate pre-migration producer and consumerHeader anchor link"},{"location":"day2/part3/4_premigration/exercise/#start-a-producer-against-the-source-amazon-msk-cluster","text":"In the Cloud9 terminal, lets setup environment variables and connect to KafkaClientInstance1 export MSK_STACK =<< Stack Name >> # Looks like msk-team22 for example export ssh_cmd1 = $ ( aws cloudformation describe - stacks -- stack - name $MSK_STACK -- query 'Stacks[0].Outputs[?OutputKey==`SSHKafkaClientEC2Instance1`].OutputValue' -- output text ) $ssh_cmd1 Answer yes to \"Are you sure you want to continue connecting (yes/no)\" and you should be connected to KafkaClientInstance1 . Go to the /tmp/kafka directory and take a quick look where configuration files and scripts have already been downloaded to this EC2 instance. cd /tmp/kafka ls -l We will be using many of these files in the following steps of this lab. Get MSK Cluster client information Go to the Amazon MSK console . Click on the Provisioned MSK cluster that was created by CloudFormation (default name: MSKSrc-XXXX ) Click on View client information on the top right side of the page under Cluster summary . Click on Copy under Bootstrap servers and paste it in a notepad application. Repeat the same steps for the Serverless MSK Cluster that was created by CloudFormation (default name: MSKServerlessDest ) Run Environment Variable setup script We use various environment variables in this lab, so let's run a small shell script to make things more convenient. export brokersmsksource =< Source Bootstrap servers address > export brokersmskdest =< Serverless Bootstrap servers address > Example: We add some variables to the bash profile and will verify the variables are set correctly, with the final \"echo\" statement. export region =$ ( curl http : // 169.254 . 169.254 / latest / meta - data / placement / region ) echo \"export brokersmsksource=${brokersmsksource}\" | tee - a ~/. bash_profile echo \"export brokersmskdest=${brokersmskdest}\" | tee - a ~/. bash_profile You should see a value from the last echo command. Make sure you see a value for $brokersmsksource before proceeding. Next, we configure the KafkaClientInstance1 with Amazon MSK IAM authentication client. cd / home / ec2 - user / kafka / libs wget https : // github . com / aws / aws - msk - iam - auth / releases / download / 1.1 . 0 / aws - msk - iam - auth - 1.1 . 0 - all . jar cd / home / ec2 - user mkdir iam - auth && cd ./ iam - auth wget https : // github . com / aws / aws - msk - iam - auth / releases / download / 1.1 . 0 / aws - msk - iam - auth - 1.1 . 0 - all . jar cd ../ cat << EOF > / home / ec2 - user / kafka / config / client - config . properties # Sets up TLS for encryption and SASL for authN. security . protocol = SASL_SSL # Identifies the SASL mechanism to use. sasl . mechanism = AWS_MSK_IAM # Binds SASL client implementation. sasl . jaas . config = software . amazon . msk . auth . iam . IAMLoginModule required ; # Encapsulates constructing a SigV4 signature based on extracted credentials. # The SASL client bound by \"sasl.jaas.config\" invokes this class. sasl . client . callback . handler . class = software . amazon . msk . auth . iam . IAMClientCallbackHandler EOF export CLASSPATH =/ home / ec2 - user / iam - auth / aws - msk - iam - auth - 1.1 . 0 - all . jar echo \"export CLASSPATH=${CLASSPATH}\" | tee - a ~/. bash_profile Let's go to the /home/ec2-user/kafka dir and create a topic called ExampleTopic . cd /home/ec2-user/kafka bin/kafka-topics.sh --create --bootstrap-server=$brokersmsksource --command-config /home/ec2-user/kafka/config/client-config.properties --replication-factor 3 --partitions 3 --topic ExampleTopic Setup the Producer settings (including Glue Schema Registry and Monitoring) cd / tmp / kafka cp producer . properties_msk producer . properties_msk_dest sed - i - e \"s/BOOTSTRAP_SERVERS_CONFIG=/BOOTSTRAP_SERVERS_CONFIG=$brokersmsksource/g\" producer . properties_msk export schema_compatibility = FULL_ALL export EXTRA_ARGS =- javaagent : / home / ec2 - user / prometheus / jmx_prometheus_javaagent - 0.13 . 0.j ar = 3800 : / home / ec2 - user / prometheus / kafka - producer - consumer . yml Run the Producer and confirm the log output java $EXTRA_ARGS - jar KafkaClickstreamClient - 1.0 - SNAPSHOT . jar - t ExampleTopic - pfp / tmp / kafka / producer . properties_msk - nt 8 - rf 10800 - nle - gsr - gsrr $region - iam - gar - gcs $schema_compatibility > / tmp / producer . log 2 >& 1 & To kill the producer before the 3 hours are up, note down the pid (process id) of the producer process. Use kill to kill the process. The javaagent is a Prometheus JMX exporter that will export the Apacke Kafka producer metrics for Prometheus to scrape and store for queries and visualization. To get the source code of the producer see github . The output of the previous command: Tail the producer log file to see the producer sending events. Ctrl-C to exit from the tail command. tail -f /tmp/producer.log [Optional] Check to see if the schema got registered in Schema Registry. In the AWS Glue Console , under Schema registries -> Schemas , you should see the ExampleTopic registered as the Producer was run with Glue Schema Registry args: -gsr -gsrr $region -gar -gcs $schema_compatibility","title":"Start a producer against the source Amazon MSK cluster"},{"location":"day2/part3/4_premigration/exercise/#run-a-consumer","text":"Now, let's configure and run a Kafka Consumer application reading from the previously created ExampleTopic. Setup Consumer environment settings cd / tmp / kafka cp consumer . properties consumer . properties_dest sed - i - e \"s/BOOTSTRAP_SERVERS_CONFIG=/BOOTSTRAP_SERVERS_CONFIG=$brokersmsksource/g\" consumer . properties export EXTRA_ARGS =- javaagent : / home / ec2 - user / prometheus / jmx_prometheus_javaagent - 0.13 . 0.j ar = 3900 : / home / ec2 - user / prometheus / kafka - producer - consumer . yml Run the Clickstream consumer. The consumer will run in the background for 3 hours. To kill the consumer before the 3 hours are up, note down the pid (process id) of the consumer process. Use kill to kill the process. The javaagent is a Prometheus JMX exporter that will export the Apacke Kafka consumer metrics for Prometheus to scrape and store for queries and visualization.* To get the source code of the consumer see github . java $EXTRA_ARGS - jar KafkaClickstreamConsumer - 1.0 - SNAPSHOT . jar - t ExampleTopic - pfp / tmp / kafka / consumer . properties - nt 3 - rf 10800 - src msksource - gsr - iam - gsrr $region > / tmp / consumer . log 2 >& 1 & The output of the previous command should be similar to this: Tail the consumer log file to see the consumer reading messages and making progress. Ctrl-C to exit from the tail command. tail -f /tmp/consumer.log","title":"Run a Consumer"},{"location":"day2/part3/5_mirrormaker/exercise/","text":"MirrorMaker 2 on Kafka Connect \u00b6 Setup and start MirrorMaker 2 on Kafka Connect \u00b6 Since we now have an environment which mimics and existing an Apache Kafka environment with existing Producer and Consumer, let's take the next step to replicate from this Source cluster to a new Destination cluster. In this section, we setup Kafka Connect and the MirrorMaker 2 Kafka Connect connectors. Setup Kafka Connect cluster \u00b6 This section picks up from the previous section. You should still be at a terminal prompt in KafkaClientInstance1 . Configure Kafka Connect. cd / tmp / kafka sed - i - e \" s/bootstrap.servers=/bootstrap.servers=$brokersmskdest/g \" connect - distributed - iam - auth . properties cp connect - distributed - iam - auth . properties connect - distributed . properties Start the Kafka Connect service. It will use the ssl parameters from the /tmp/connect-distributed.properties file and connect to the Amazon MSK cluster. sudo systemctl start kafka - connect . service sudo systemctl status kafka - connect . service This is the expected output from running these commands: Make sure the Kafka Connect service started properly. cat / tmp / kafka / kafka - connect . log | grep Herder You should see an output similar to this: Note \u00b6 It might take a few seconds for it to start up. If you get an output which does not look like the picture below, give it a few seconds and retry the command. A Distributed herder coordinates with other workers to spread work across multiple processes. In the output you can see that the Herder started successfully and could connect to the Amazon MSK cluster and read the internal Kafka connect topics.* Confirm Kafka Connect REST Interface Kafka Connect supports a REST API for managing connectors. The default port for the service is 8083 and we did not change the port in the connect-distributed.properties file. On each of the Kafka Client Instances, the service is available at http://localhost:8083 . Run the following command: curl -X GET http://localhost:8083| jq . You should get an output like the following: Observe the topics currently in the source and destination Amazon MSK clusters. Run the following commands: cd /home/ec2-user/kafka ./bin/kafka-topics.sh --bootstrap-server=$brokersmsksource --command-config /home/ec2-user/kafka/config/client-config.properties --list Note: The source cluster has the ExampleTopic topic the producer is sending records to, in addition to __consumer_offsets , and __amazon_msk_canary internal topics. ./bin/kafka-topics.sh --bootstrap-server=$brokersmskdest --command-config /home/ec2-user/kafka/config/client-config.properties --list Note: The destination cluster has 3 Kafka connect internal topics starting with the name connect- . You now have a Kafka Connect cluster running. (Optional) Kafka Connect multi-node cluster required for MirrorMaker2 \u00b6 Kafka Connect clusters may be deployed across multiple nodes for both high-availability (HA) and throughput purposes. In this lab, we do not configure an additional Kafka Connect node, but there is the additional EC2 Instance available to do so. Just follow similar steps as the previous sections, but connect to Kafka EC2 Instance 2. To connect to Instance 2 from Cloud9, you can use right side tab and issue the following (similar to steps for Instance 1): export MSK_STACK =<< Stack Name >> # Looks like msk-XXXXXXXXXX export ssh_cmd2 = $ ( aws cloudformation describe - stacks -- stack - name $MSK_STACK -- query 'Stacks[0].Outputs[?OutputKey==`SSHKafkaClientEC2Instance2`].OutputValue' -- output text ) $ssh_cmd2 And then follow similar steps to configure Kafka Connect node as we did on Instance 1. We are not going to cover running HA Kafka Connect in this lab, but it's important to know it's an option. Configure and start MirrorMaker 2 connectors (with Custom Replication Policy) \u00b6 To read more about the connectors and what they do, see the Connectors section in KIP-382. Note: there is not a MM2 Sink Connector/Task available yet as originally described in KIP-382. You may wish to keep on eye on KIP-656 We are going to configure and run all 3 of the MirrorMaker2 Connectors Edit the MirrorMaker 2 Kakfa Connect Connectors properties files cd /tmp/kafka sed -i -e \"s/\\\"target.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"target.cluster.bootstrap.servers\\\": \\\"$brokersmskdest\\\"/g\" mm2-msc-cust-repl-policy-iam-auth.json sed -i -e \"s/\\\"source.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"source.cluster.bootstrap.servers\\\": \\\"$brokersmsksource\\\"/g\" mm2-msc-cust-repl-policy-iam-auth.json sed -i -e \"s/\\\"target.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"target.cluster.bootstrap.servers\\\": \\\"$brokersmskdest\\\"/g\" mm2-cpc-cust-repl-policy-iam-auth-sync.json sed -i -e \"s/\\\"source.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"source.cluster.bootstrap.servers\\\": \\\"$brokersmsksource\\\"/g\" mm2-cpc-cust-repl-policy-iam-auth-sync.json sed -i -e \"s/\\\"target.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"target.cluster.bootstrap.servers\\\": \\\"$brokersmskdest\\\"/g\" mm2-hbc-iam-auth.json sed -i -e \"s/\\\"source.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"source.cluster.bootstrap.servers\\\": \\\"$brokersmsksource\\\"/g\" mm2-hbc-iam-auth.json We are now ready to start each of these connectors. Feel free to review the 3 .json files we modified in the previous sed commands before continuing. Start MirrorSourceConnectorHeader \u00b6 Create a new MirrorSourceConnector connector by submitting a request to the REST interface. curl - X PUT - H \"Content-Type: application/json\" --data @mm2-msc-cust-repl-policy-iam-auth.json http://localhost:8083/connectors/mm2-msc/config | jq '.' The expected output of the command: Check the status of the connector. curl -s localhost:8083/connectors/mm2-msc/status | jq . The expected output of the command is: Note: Even though the tasks.max configuration is set to 4, 3 tasks are started as there are 3 partitions in the topic. MirrorCheckpointConnector \u00b6 Create a new MirrorCheckpointConnector connector by submitting a request to the REST interface. curl - X PUT - H \"Content-Type: application/json\" --data @mm2-cpc-cust-repl-policy-iam-auth-sync.json http://localhost:8083/connectors/mm2-cpc/config | jq . The expected output of the command is: Check the status of the connector: curl -s localhost:8083/connectors/mm2-cpc/status | jq . The expected output of the command is: MirrorHeartbeatConnector \u00b6 Create a new MirrorHeartbeatConnector connector by submitting a request to the REST interface. curl - X PUT - H \"Content-Type: application/json\" --data @mm2-hbc-iam-auth.json http://localhost:8083/connectors/mm2-hbc/config | jq '.' The expected output of the command is: Check the status of the connector: curl -s localhost:8083/connectors/mm2-hbc/status | jq . The expected output of the command is: Observe the topics now in the source and destination Amazon MSK clusters. Run the following commands: cd /home/ec2-user/kafka ./bin/kafka-topics.sh --bootstrap-server=$brokersmsksource --command-config /home/ec2-user/kafka/config/client-config.properties --list Note: The source cluster has an additional topic called mm2-offset-syncs.mskdest.internal which was created by the MirrorSourceConnector and is used to sync offsets between the source and destination Amazon MSK clusters as described in KIP-382 . ./bin/kafka-topics.sh --bootstrap-server=$brokersmskdest --command-config /home/ec2-user/kafka/config/client-config.properties --list Note: The destination cluster has 3 additional topics now. The ExampleTopic which was created by the MirrorSourceConnector and is the replicated topic. Also, the MirrorMaker 2 internal topics heartbeats and msksource.checkpoints.internal topics which were created by the MirrorHeartbeatConnector and the MirrorCheckpointConnector connectors respectively. To learn more on MirrorMaker 2 internal topics as described in KIP-382, see MirrorMaker2 Internal Topics . You now have a MirrorMaker 2 cluster running on Kafka Connect that is replicating topics, topic configurations, topic acls, groups and topic messages to the destination Amazon MSK cluster. Verify MirrorMaker2 replication status using Grafana setup in the monitoring section \u00b6 Go back to the browser window with the Grafana dashboard from the Monitoring section and hit refresh in the top right corner. You will now see data in the dashboard, and you can see the consumer lag starting high but going to zero shortly as the MM2 consumers catch up in the graph in the top right.","title":"5 - MirrorMaker 2 on Kafka Connect"},{"location":"day2/part3/5_mirrormaker/exercise/#mirrormaker-2-on-kafka-connect","text":"","title":"MirrorMaker 2 on Kafka Connect"},{"location":"day2/part3/5_mirrormaker/exercise/#setup-and-start-mirrormaker-2-on-kafka-connect","text":"Since we now have an environment which mimics and existing an Apache Kafka environment with existing Producer and Consumer, let's take the next step to replicate from this Source cluster to a new Destination cluster. In this section, we setup Kafka Connect and the MirrorMaker 2 Kafka Connect connectors.","title":"Setup and start MirrorMaker 2 on Kafka Connect"},{"location":"day2/part3/5_mirrormaker/exercise/#setup-kafka-connect-cluster","text":"This section picks up from the previous section. You should still be at a terminal prompt in KafkaClientInstance1 . Configure Kafka Connect. cd / tmp / kafka sed - i - e \" s/bootstrap.servers=/bootstrap.servers=$brokersmskdest/g \" connect - distributed - iam - auth . properties cp connect - distributed - iam - auth . properties connect - distributed . properties Start the Kafka Connect service. It will use the ssl parameters from the /tmp/connect-distributed.properties file and connect to the Amazon MSK cluster. sudo systemctl start kafka - connect . service sudo systemctl status kafka - connect . service This is the expected output from running these commands: Make sure the Kafka Connect service started properly. cat / tmp / kafka / kafka - connect . log | grep Herder You should see an output similar to this:","title":"Setup Kafka Connect cluster"},{"location":"day2/part3/5_mirrormaker/exercise/#note","text":"It might take a few seconds for it to start up. If you get an output which does not look like the picture below, give it a few seconds and retry the command. A Distributed herder coordinates with other workers to spread work across multiple processes. In the output you can see that the Herder started successfully and could connect to the Amazon MSK cluster and read the internal Kafka connect topics.* Confirm Kafka Connect REST Interface Kafka Connect supports a REST API for managing connectors. The default port for the service is 8083 and we did not change the port in the connect-distributed.properties file. On each of the Kafka Client Instances, the service is available at http://localhost:8083 . Run the following command: curl -X GET http://localhost:8083| jq . You should get an output like the following: Observe the topics currently in the source and destination Amazon MSK clusters. Run the following commands: cd /home/ec2-user/kafka ./bin/kafka-topics.sh --bootstrap-server=$brokersmsksource --command-config /home/ec2-user/kafka/config/client-config.properties --list Note: The source cluster has the ExampleTopic topic the producer is sending records to, in addition to __consumer_offsets , and __amazon_msk_canary internal topics. ./bin/kafka-topics.sh --bootstrap-server=$brokersmskdest --command-config /home/ec2-user/kafka/config/client-config.properties --list Note: The destination cluster has 3 Kafka connect internal topics starting with the name connect- . You now have a Kafka Connect cluster running.","title":"Note"},{"location":"day2/part3/5_mirrormaker/exercise/#optional-kafka-connect-multi-node-cluster-required-for-mirrormaker2","text":"Kafka Connect clusters may be deployed across multiple nodes for both high-availability (HA) and throughput purposes. In this lab, we do not configure an additional Kafka Connect node, but there is the additional EC2 Instance available to do so. Just follow similar steps as the previous sections, but connect to Kafka EC2 Instance 2. To connect to Instance 2 from Cloud9, you can use right side tab and issue the following (similar to steps for Instance 1): export MSK_STACK =<< Stack Name >> # Looks like msk-XXXXXXXXXX export ssh_cmd2 = $ ( aws cloudformation describe - stacks -- stack - name $MSK_STACK -- query 'Stacks[0].Outputs[?OutputKey==`SSHKafkaClientEC2Instance2`].OutputValue' -- output text ) $ssh_cmd2 And then follow similar steps to configure Kafka Connect node as we did on Instance 1. We are not going to cover running HA Kafka Connect in this lab, but it's important to know it's an option.","title":"(Optional) Kafka Connect multi-node cluster required for MirrorMaker2"},{"location":"day2/part3/5_mirrormaker/exercise/#configure-and-start-mirrormaker-2-connectors-with-custom-replication-policy","text":"To read more about the connectors and what they do, see the Connectors section in KIP-382. Note: there is not a MM2 Sink Connector/Task available yet as originally described in KIP-382. You may wish to keep on eye on KIP-656 We are going to configure and run all 3 of the MirrorMaker2 Connectors Edit the MirrorMaker 2 Kakfa Connect Connectors properties files cd /tmp/kafka sed -i -e \"s/\\\"target.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"target.cluster.bootstrap.servers\\\": \\\"$brokersmskdest\\\"/g\" mm2-msc-cust-repl-policy-iam-auth.json sed -i -e \"s/\\\"source.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"source.cluster.bootstrap.servers\\\": \\\"$brokersmsksource\\\"/g\" mm2-msc-cust-repl-policy-iam-auth.json sed -i -e \"s/\\\"target.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"target.cluster.bootstrap.servers\\\": \\\"$brokersmskdest\\\"/g\" mm2-cpc-cust-repl-policy-iam-auth-sync.json sed -i -e \"s/\\\"source.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"source.cluster.bootstrap.servers\\\": \\\"$brokersmsksource\\\"/g\" mm2-cpc-cust-repl-policy-iam-auth-sync.json sed -i -e \"s/\\\"target.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"target.cluster.bootstrap.servers\\\": \\\"$brokersmskdest\\\"/g\" mm2-hbc-iam-auth.json sed -i -e \"s/\\\"source.cluster.bootstrap.servers\\\": \\\"\\\"/\\\"source.cluster.bootstrap.servers\\\": \\\"$brokersmsksource\\\"/g\" mm2-hbc-iam-auth.json We are now ready to start each of these connectors. Feel free to review the 3 .json files we modified in the previous sed commands before continuing.","title":"Configure and start MirrorMaker 2 connectors (with Custom Replication Policy)"},{"location":"day2/part3/5_mirrormaker/exercise/#start-mirrorsourceconnectorheader","text":"Create a new MirrorSourceConnector connector by submitting a request to the REST interface. curl - X PUT - H \"Content-Type: application/json\" --data @mm2-msc-cust-repl-policy-iam-auth.json http://localhost:8083/connectors/mm2-msc/config | jq '.' The expected output of the command: Check the status of the connector. curl -s localhost:8083/connectors/mm2-msc/status | jq . The expected output of the command is: Note: Even though the tasks.max configuration is set to 4, 3 tasks are started as there are 3 partitions in the topic.","title":"Start MirrorSourceConnectorHeader"},{"location":"day2/part3/5_mirrormaker/exercise/#mirrorcheckpointconnector","text":"Create a new MirrorCheckpointConnector connector by submitting a request to the REST interface. curl - X PUT - H \"Content-Type: application/json\" --data @mm2-cpc-cust-repl-policy-iam-auth-sync.json http://localhost:8083/connectors/mm2-cpc/config | jq . The expected output of the command is: Check the status of the connector: curl -s localhost:8083/connectors/mm2-cpc/status | jq . The expected output of the command is:","title":"MirrorCheckpointConnector"},{"location":"day2/part3/5_mirrormaker/exercise/#mirrorheartbeatconnector","text":"Create a new MirrorHeartbeatConnector connector by submitting a request to the REST interface. curl - X PUT - H \"Content-Type: application/json\" --data @mm2-hbc-iam-auth.json http://localhost:8083/connectors/mm2-hbc/config | jq '.' The expected output of the command is: Check the status of the connector: curl -s localhost:8083/connectors/mm2-hbc/status | jq . The expected output of the command is: Observe the topics now in the source and destination Amazon MSK clusters. Run the following commands: cd /home/ec2-user/kafka ./bin/kafka-topics.sh --bootstrap-server=$brokersmsksource --command-config /home/ec2-user/kafka/config/client-config.properties --list Note: The source cluster has an additional topic called mm2-offset-syncs.mskdest.internal which was created by the MirrorSourceConnector and is used to sync offsets between the source and destination Amazon MSK clusters as described in KIP-382 . ./bin/kafka-topics.sh --bootstrap-server=$brokersmskdest --command-config /home/ec2-user/kafka/config/client-config.properties --list Note: The destination cluster has 3 additional topics now. The ExampleTopic which was created by the MirrorSourceConnector and is the replicated topic. Also, the MirrorMaker 2 internal topics heartbeats and msksource.checkpoints.internal topics which were created by the MirrorHeartbeatConnector and the MirrorCheckpointConnector connectors respectively. To learn more on MirrorMaker 2 internal topics as described in KIP-382, see MirrorMaker2 Internal Topics . You now have a MirrorMaker 2 cluster running on Kafka Connect that is replicating topics, topic configurations, topic acls, groups and topic messages to the destination Amazon MSK cluster.","title":"MirrorHeartbeatConnector"},{"location":"day2/part3/5_mirrormaker/exercise/#verify-mirrormaker2-replication-status-using-grafana-setup-in-the-monitoring-section","text":"Go back to the browser window with the Grafana dashboard from the Monitoring section and hit refresh in the top right corner. You will now see data in the dashboard, and you can see the consumer lag starting high but going to zero shortly as the MM2 consumers catch up in the graph in the top right.","title":"Verify MirrorMaker2 replication status using Grafana setup in the monitoring section"},{"location":"day2/part3/6_migration/exercise/","text":"Client Migration and Cutover \u00b6 We will perform the following steps in this section: Consumer Migration Terminate consumer reading from source cluster. Start consumer reading from destination MSK cluster. Producer Migration Terminate producer sending to source cluster. Start producer sending to destination MSK cluster. Stop MM2 and Kafka Connect Consumer Migration \u00b6 Again, we will continue where we last left off and assume you are still connected to KafkaClientInstance1. (The linux prompt should include the instance name.) Terminate the Consumer. We need the pid of the Consumer. If you don't remember it, you can issue the following command to obtain the pid : jps -l | grep Consumer And then, stop the Consumer with the following command: kill <pid> Tail the consumer log file to check if it exited properly and note down the last processed Global Seq no and the last offset. Ctrl-C to exit from the tail command. tail -100 /tmp/consumer.log | grep Global tail -100 /tmp/consumer.log | grep \"Last Offsets\" Update Consumer connection configuration to use Destination cluster. cd /tmp/kafka sed -i -e \"s/BOOTSTRAP_SERVERS_CONFIG=/BOOTSTRAP_SERVERS_CONFIG=$brokersmskdest/g\" consumer.properties_dest Backup log and Run the Consumer against the destination Amazon MSK cluster. cp / tmp / consumer . log / tmp / consumer . log_src java $EXTRA_ARGS - jar KafkaClickstreamConsumer - 1.0 - SNAPSHOT . jar - t ExampleTopic - pfp / tmp / kafka / consumer . properties_dest - nt 3 - rf 10800 - src msksource - iam - gsr - gsrr $region > / tmp / consumer . log 2 >& 1 & Check the consumer log to make sure it is consuming messages. tail -f /tmp/consumer.log Check to make sure that the consumer started consuming from the last offset synced by the MirrorCheckpointConnector . grep 'Consumer position:' /tmp/consumer.log At this point the consumer is migrated to the destination Amazon MSK cluster.* Producer Migration \u00b6 Terminate the Producer Again, we need the pid that you had recorded earlier when starting the producer. If you don't remember it, run the following command: jps -l | grep KafkaClickstreamClient and then: kill <pid> Tail the producer log file to check if it exited properly. When exiting, the producer records the last Global Seq No . Ctrl-C to exit. tail -f /tmp/producer.log Update Producer configuration sed - i - e \"s/BOOTSTRAP_SERVERS_CONFIG=/BOOTSTRAP_SERVERS_CONFIG=$brokersmskdest/g\" producer . properties_msk_dest export EXTRA_ARGS =- javaagent : / home / ec2 - user / prometheus / jmx_prometheus_javaagent - 0.13 . 0.j ar = 3800 : / home / ec2 - user / prometheus / kafka - producer - consumer . yml Now, run the Producer against the destination Amazon MSK cluster mv / tmp / producer . log / tmp / producer . log_src java $EXTRA_ARGS - jar KafkaClickstreamClient - 1.0 - SNAPSHOT . jar - t ExampleTopic - pfp / tmp / kafka / producer . properties_msk_dest - nt 8 - rf 10800 - nle - gsr - iam - gsrr $region - gar - gcs $schema_compatibility > / tmp / producer . log 2 >& 1 & Tail the producer log file. Ctrl-C to exit. tail -f /tmp/producer.log Run the following command to check if the consumer picked up the new partitions for the newly created ExampleTopic in the destination Amazon MSK cluster. grep \"Consumer assignment\" / tmp / consumer . log Check the consumer.log file to see if the consumer is reading messages from the newly created ExampleTopic in the destination Amazon MSK cluster. tail -f /tmp/consumer.log At this point the producer is migrated to the destination Amazon MSK cluster.* Stop MirrorMaker 2 and Kafka Connect \u00b6 At this point, we have successfully migrated from our Source to Destination cluster, and we can stop Kafka Connect (and this will stop the MirrorMaker 2 connectors). Run the following commands: sudo systemctl stop kafka - connect sudo systemctl status kafka - connect","title":"6 - Client Migration and Cutover"},{"location":"day2/part3/6_migration/exercise/#client-migration-and-cutover","text":"We will perform the following steps in this section: Consumer Migration Terminate consumer reading from source cluster. Start consumer reading from destination MSK cluster. Producer Migration Terminate producer sending to source cluster. Start producer sending to destination MSK cluster. Stop MM2 and Kafka Connect","title":"Client Migration and Cutover"},{"location":"day2/part3/6_migration/exercise/#consumer-migration","text":"Again, we will continue where we last left off and assume you are still connected to KafkaClientInstance1. (The linux prompt should include the instance name.) Terminate the Consumer. We need the pid of the Consumer. If you don't remember it, you can issue the following command to obtain the pid : jps -l | grep Consumer And then, stop the Consumer with the following command: kill <pid> Tail the consumer log file to check if it exited properly and note down the last processed Global Seq no and the last offset. Ctrl-C to exit from the tail command. tail -100 /tmp/consumer.log | grep Global tail -100 /tmp/consumer.log | grep \"Last Offsets\" Update Consumer connection configuration to use Destination cluster. cd /tmp/kafka sed -i -e \"s/BOOTSTRAP_SERVERS_CONFIG=/BOOTSTRAP_SERVERS_CONFIG=$brokersmskdest/g\" consumer.properties_dest Backup log and Run the Consumer against the destination Amazon MSK cluster. cp / tmp / consumer . log / tmp / consumer . log_src java $EXTRA_ARGS - jar KafkaClickstreamConsumer - 1.0 - SNAPSHOT . jar - t ExampleTopic - pfp / tmp / kafka / consumer . properties_dest - nt 3 - rf 10800 - src msksource - iam - gsr - gsrr $region > / tmp / consumer . log 2 >& 1 & Check the consumer log to make sure it is consuming messages. tail -f /tmp/consumer.log Check to make sure that the consumer started consuming from the last offset synced by the MirrorCheckpointConnector . grep 'Consumer position:' /tmp/consumer.log At this point the consumer is migrated to the destination Amazon MSK cluster.*","title":"Consumer Migration"},{"location":"day2/part3/6_migration/exercise/#producer-migration","text":"Terminate the Producer Again, we need the pid that you had recorded earlier when starting the producer. If you don't remember it, run the following command: jps -l | grep KafkaClickstreamClient and then: kill <pid> Tail the producer log file to check if it exited properly. When exiting, the producer records the last Global Seq No . Ctrl-C to exit. tail -f /tmp/producer.log Update Producer configuration sed - i - e \"s/BOOTSTRAP_SERVERS_CONFIG=/BOOTSTRAP_SERVERS_CONFIG=$brokersmskdest/g\" producer . properties_msk_dest export EXTRA_ARGS =- javaagent : / home / ec2 - user / prometheus / jmx_prometheus_javaagent - 0.13 . 0.j ar = 3800 : / home / ec2 - user / prometheus / kafka - producer - consumer . yml Now, run the Producer against the destination Amazon MSK cluster mv / tmp / producer . log / tmp / producer . log_src java $EXTRA_ARGS - jar KafkaClickstreamClient - 1.0 - SNAPSHOT . jar - t ExampleTopic - pfp / tmp / kafka / producer . properties_msk_dest - nt 8 - rf 10800 - nle - gsr - iam - gsrr $region - gar - gcs $schema_compatibility > / tmp / producer . log 2 >& 1 & Tail the producer log file. Ctrl-C to exit. tail -f /tmp/producer.log Run the following command to check if the consumer picked up the new partitions for the newly created ExampleTopic in the destination Amazon MSK cluster. grep \"Consumer assignment\" / tmp / consumer . log Check the consumer.log file to see if the consumer is reading messages from the newly created ExampleTopic in the destination Amazon MSK cluster. tail -f /tmp/consumer.log At this point the producer is migrated to the destination Amazon MSK cluster.*","title":"Producer Migration"},{"location":"day2/part3/6_migration/exercise/#stop-mirrormaker-2-and-kafka-connect","text":"At this point, we have successfully migrated from our Source to Destination cluster, and we can stop Kafka Connect (and this will stop the MirrorMaker 2 connectors). Run the following commands: sudo systemctl stop kafka - connect sudo systemctl status kafka - connect","title":"Stop MirrorMaker 2 and Kafka Connect"},{"location":"day2/part4/1_Intro/exercise/","text":"Introduction \u00b6 Serverless services allow us to build applications without having to worry about the underlying infrastructure. This allows developers to avoid provisioning, scaling, and managing resource utilization. In this workshop we will build a serverless data pipeline using Amazon MSK Serverless which enables data to be consumed from many different client applications to accomplish downstream tasks such as dashboards and analytics. Attendees will will learn how to: 1. Start a Serverless MSK Cluster 2. Deploy a Kafka Client Container based Lambda Function 3. Ingest data from various sources into a Kafka Client 4. Consume data for downstream tasks such as Quicksight Dashboards This is a 300-level workshop, so some familiarly with using serverless services such as Lambda and Fargate ishelpful. No Apache Kafka experience is necessary. This workshop is intended to be finished in 2 hours.","title":"1 - Introduction"},{"location":"day2/part4/1_Intro/exercise/#introduction","text":"Serverless services allow us to build applications without having to worry about the underlying infrastructure. This allows developers to avoid provisioning, scaling, and managing resource utilization. In this workshop we will build a serverless data pipeline using Amazon MSK Serverless which enables data to be consumed from many different client applications to accomplish downstream tasks such as dashboards and analytics. Attendees will will learn how to: 1. Start a Serverless MSK Cluster 2. Deploy a Kafka Client Container based Lambda Function 3. Ingest data from various sources into a Kafka Client 4. Consume data for downstream tasks such as Quicksight Dashboards This is a 300-level workshop, so some familiarly with using serverless services such as Lambda and Fargate ishelpful. No Apache Kafka experience is necessary. This workshop is intended to be finished in 2 hours.","title":"Introduction"},{"location":"day2/part4/2_Setup/exercise/","text":"Setup MSK Serverless cluster \u00b6 MSK Serverless Overview \u00b6 Apache Kafka is a distributed event store and stream-processing platform. Kafka provides a mechanism to decouple data processing from the source and target destinations as it's highly scalable and resilient. Kafka is very customizable, based on your workload, which introduces operational overhead. With serverless Kafka the tradeoff is you lose the flexibility of being able to configure the capacity of your cluster while gaining the ability to use Kafka through a single interface that just provides an endpoint for clients. In this module we will stand up a Serverless Apache Kafka Cluster by navigating through the AWS Console. Create MSK Serverless Cluster \u00b6 Navigate to Amazon MSK console page and click the Create cluster button on the top right. Cluster Settings \u00b6 Choose Custom create to customize cluster networking and other settings. Provide the Cluster name . Ensure cluster type is selected as Serverless and click Next button. Networking \u00b6 In the VPC Configuration section, click Add subnet button to have cluster spread across 3 Availability Zones Select MMVPC from the VPC dropdown. For Subnets, select the zones us-east-2a, us-east-2b, us-east-2c and choose Subnets with name starting PrivateSubnetMSK from dropdown for each zone. Choose Custom security groups , remove the default security group and choose security group with name MSK Security Group from dropdown list and click Next button. Security \u00b6 MSK Serverless defaults to IAM role-based authentication . Click Next to proceed. Metrics and tags \u00b6 Leave it to default and click Next to proceed. Review and create \u00b6 Review the configuration and click Create cluster button. Wait for couple of minutes for cluster to be created and available to use. Wait for cluster status to change from Creating to Active Copy Cluster Endpoint \u00b6 Click on the View client information button and copy the details of cluster endpoint and save it on notepad for later use. Create MSK Topics \u00b6 Now that the cluster is ready and available to use, we need to create Kafka topics to produce and consume data. Please follow instructions below to create Kafka topics needed for this workshop. Connect to Kafka Client \u00b6 Navigate to Amazon EC2 console page. On the EC2 home page click on Instances(running) link as show in below image. On the EC2 instances page select the checkbox for the instance named KafkaClientInstance and click on Connec t button on top right as shown in below image. On the page Connect to instance , ensure you select the Session Manager tab and click on the Connect button. This would open a new tab with EC2 terminal. Create Topics \u00b6 On the Terminal, please execute below command to change to ec2-user by running the below command: sudo su - ec2-user Please execute below command to set your MSK cluster broker endpoint to the shell variable BS. Please replace YOUR_CLUSTER_ENDPOINT in below command with the endpoint you copied in the last step of previous section as shown in the image. export BS = YOUR_CLUSTER_ENDPOINT Execute command below to create the topics needed for workshop as shown in image ./create-topics.sh You will see warnings printed to the terminal like below. You may ignore them. SLF4J : Failed to load class \"org.slf4j.impl.StaticLoggerBinder\" . SLF4J : Defaulting to no - operation ( NOP ) logger implementation SLF4J : See http : // www . slf4j . org / codes . html #StaticLoggerBinder for further details. You should see the four MSK topics ( clickstream, Departments_Agg, ClickEvents_UserId_Agg_Result, User_Sessions_Aggregates_With_Order_Checkout ) created.","title":"2 - Setup MSK Serverless cluster"},{"location":"day2/part4/2_Setup/exercise/#setup-msk-serverless-cluster","text":"","title":"Setup MSK Serverless cluster"},{"location":"day2/part4/2_Setup/exercise/#msk-serverless-overview","text":"Apache Kafka is a distributed event store and stream-processing platform. Kafka provides a mechanism to decouple data processing from the source and target destinations as it's highly scalable and resilient. Kafka is very customizable, based on your workload, which introduces operational overhead. With serverless Kafka the tradeoff is you lose the flexibility of being able to configure the capacity of your cluster while gaining the ability to use Kafka through a single interface that just provides an endpoint for clients. In this module we will stand up a Serverless Apache Kafka Cluster by navigating through the AWS Console.","title":"MSK Serverless Overview"},{"location":"day2/part4/2_Setup/exercise/#create-msk-serverless-cluster","text":"Navigate to Amazon MSK console page and click the Create cluster button on the top right.","title":"Create MSK Serverless Cluster"},{"location":"day2/part4/2_Setup/exercise/#cluster-settings","text":"Choose Custom create to customize cluster networking and other settings. Provide the Cluster name . Ensure cluster type is selected as Serverless and click Next button.","title":"Cluster Settings"},{"location":"day2/part4/2_Setup/exercise/#networking","text":"In the VPC Configuration section, click Add subnet button to have cluster spread across 3 Availability Zones Select MMVPC from the VPC dropdown. For Subnets, select the zones us-east-2a, us-east-2b, us-east-2c and choose Subnets with name starting PrivateSubnetMSK from dropdown for each zone. Choose Custom security groups , remove the default security group and choose security group with name MSK Security Group from dropdown list and click Next button.","title":"Networking"},{"location":"day2/part4/2_Setup/exercise/#security","text":"MSK Serverless defaults to IAM role-based authentication . Click Next to proceed.","title":"Security"},{"location":"day2/part4/2_Setup/exercise/#metrics-and-tags","text":"Leave it to default and click Next to proceed.","title":"Metrics and tags"},{"location":"day2/part4/2_Setup/exercise/#review-and-create","text":"Review the configuration and click Create cluster button. Wait for couple of minutes for cluster to be created and available to use. Wait for cluster status to change from Creating to Active","title":"Review and create"},{"location":"day2/part4/2_Setup/exercise/#copy-cluster-endpoint","text":"Click on the View client information button and copy the details of cluster endpoint and save it on notepad for later use.","title":"Copy Cluster Endpoint"},{"location":"day2/part4/2_Setup/exercise/#create-msk-topics","text":"Now that the cluster is ready and available to use, we need to create Kafka topics to produce and consume data. Please follow instructions below to create Kafka topics needed for this workshop.","title":"Create MSK Topics"},{"location":"day2/part4/2_Setup/exercise/#connect-to-kafka-client","text":"Navigate to Amazon EC2 console page. On the EC2 home page click on Instances(running) link as show in below image. On the EC2 instances page select the checkbox for the instance named KafkaClientInstance and click on Connec t button on top right as shown in below image. On the page Connect to instance , ensure you select the Session Manager tab and click on the Connect button. This would open a new tab with EC2 terminal.","title":"Connect to Kafka Client"},{"location":"day2/part4/2_Setup/exercise/#create-topics","text":"On the Terminal, please execute below command to change to ec2-user by running the below command: sudo su - ec2-user Please execute below command to set your MSK cluster broker endpoint to the shell variable BS. Please replace YOUR_CLUSTER_ENDPOINT in below command with the endpoint you copied in the last step of previous section as shown in the image. export BS = YOUR_CLUSTER_ENDPOINT Execute command below to create the topics needed for workshop as shown in image ./create-topics.sh You will see warnings printed to the terminal like below. You may ignore them. SLF4J : Failed to load class \"org.slf4j.impl.StaticLoggerBinder\" . SLF4J : Defaulting to no - operation ( NOP ) logger implementation SLF4J : See http : // www . slf4j . org / codes . html #StaticLoggerBinder for further details. You should see the four MSK topics ( clickstream, Departments_Agg, ClickEvents_UserId_Agg_Result, User_Sessions_Aggregates_With_Order_Checkout ) created.","title":"Create Topics"},{"location":"day2/part4/3_Producer/exercise/","text":"Produce clickstream data to MSK Serverless using Elastic Container Service \u00b6 Now that we have successfully created topics in our cluster, our next step is to produce data to the cluster. In this step we will deploy a serverlessECS Fargate container that runs an application to produce sample clickstream data to MSK Serverless cluster. Navigate to Amazon ECS console page. On the left side menu click on Task Definitions to navigate to page that displays available Task Definitions. Select the checkbox against the available Task Definition and Click on Run Task option from Deploy menu. Run Task \u00b6 On the Run Task page, select Fargate for Launch type option and for theOperating system family select Linux from drop down. Refer to below image for more details on other fields Expand the Networking section. VPC and security groups \u00b6 Change VPC to MMVPC . Select PrivateSubnetMSKOne , PrivateSubnetMSKTwo and PrivateSubnetMSKThree . For Security Groups , select Use an existing security group, uncheck thedefault security group, and select the security group name starting with msk-serverless-workshop-cfn-ProducerECSTaskSecurity . Advanced Options \u00b6 Expand the section under Container Overrides . For BOOTSTRAP_STRING enter the value of your MSK Serverless cluster broker endpoint (you copied this earlier from the Amazon MSK cluster console page , with View client information ). Scroll to the bottom of the page and click on the Create button . On the new page, wait for your task to get into Running status as shown in below image. You have now successfully setup a producer ECS task that will continuously keep on producing clickstream data to Kafka topic. Check schema in AWS Glue Schema Registry \u00b6 Now that the producer ECS task is running, it would create the clickstream schema in AWS Glue Schema Registry. Navigate to Amazon Glue console page and select Stream schema registries from left menu. You would see the schema registry name serverless . Click on the registry name. This would show the schema clickstream within the registry. Click on the schema name to see the schema versions. You would see the v1 over there. Click on the version v1 , this would show you the avro schema of the clickstream data produced by the ECS task.","title":"3 - Produce clickstream data to MSK Serverless using Elastic Container Service"},{"location":"day2/part4/3_Producer/exercise/#produce-clickstream-data-to-msk-serverless-using-elastic-container-service","text":"Now that we have successfully created topics in our cluster, our next step is to produce data to the cluster. In this step we will deploy a serverlessECS Fargate container that runs an application to produce sample clickstream data to MSK Serverless cluster. Navigate to Amazon ECS console page. On the left side menu click on Task Definitions to navigate to page that displays available Task Definitions. Select the checkbox against the available Task Definition and Click on Run Task option from Deploy menu.","title":"Produce clickstream data to MSK Serverless using Elastic Container Service"},{"location":"day2/part4/3_Producer/exercise/#run-task","text":"On the Run Task page, select Fargate for Launch type option and for theOperating system family select Linux from drop down. Refer to below image for more details on other fields Expand the Networking section.","title":"Run Task"},{"location":"day2/part4/3_Producer/exercise/#vpc-and-security-groups","text":"Change VPC to MMVPC . Select PrivateSubnetMSKOne , PrivateSubnetMSKTwo and PrivateSubnetMSKThree . For Security Groups , select Use an existing security group, uncheck thedefault security group, and select the security group name starting with msk-serverless-workshop-cfn-ProducerECSTaskSecurity .","title":"VPC and security groups"},{"location":"day2/part4/3_Producer/exercise/#advanced-options","text":"Expand the section under Container Overrides . For BOOTSTRAP_STRING enter the value of your MSK Serverless cluster broker endpoint (you copied this earlier from the Amazon MSK cluster console page , with View client information ). Scroll to the bottom of the page and click on the Create button . On the new page, wait for your task to get into Running status as shown in below image. You have now successfully setup a producer ECS task that will continuously keep on producing clickstream data to Kafka topic.","title":"Advanced Options"},{"location":"day2/part4/3_Producer/exercise/#check-schema-in-aws-glue-schema-registry","text":"Now that the producer ECS task is running, it would create the clickstream schema in AWS Glue Schema Registry. Navigate to Amazon Glue console page and select Stream schema registries from left menu. You would see the schema registry name serverless . Click on the registry name. This would show the schema clickstream within the registry. Click on the schema name to see the schema versions. You would see the v1 over there. Click on the version v1 , this would show you the avro schema of the clickstream data produced by the ECS task.","title":"Check schema in AWS Glue Schema Registry"},{"location":"day2/part4/4_LambdaConsumer/exercise/","text":"Consume data from MSK Serverless using Lambda \u00b6 Now that we have setup our MSK Serverless cluster we want to store the datain Amazon S3. There are various options to do that, but in this lab, we will use AWS Lambda. The AWS Lambda function is already deployed for you in your AWS account. The only thing we need to setup is the Trigger. This Functions convert the records from Avro to CSV. Navigate to the AWS Lambda Console and choose click on the MskLambda-Function . Setup Amazon MSK Trigger \u00b6 Click on the Add trigger button to create a new trigger for the Lambda function. Choose MSK as Source. Select your cluster in the drop down menu. Set the configuration parameters for the trigger: - Batch Size: 20 - Starting Position: Latest - Batch window: 20 - Topic name: clickstream After setting the configuration click Add to create the trigger. Wait for the trigger to become active (this can take a few minutes). You have now successfully setup a Lambda functions that reads messages from a Kafka topic, transforms it into csv format and then stores it in Amazon S3.","title":"4 - Consume data from MSK Serverless using Lambda"},{"location":"day2/part4/4_LambdaConsumer/exercise/#consume-data-from-msk-serverless-using-lambda","text":"Now that we have setup our MSK Serverless cluster we want to store the datain Amazon S3. There are various options to do that, but in this lab, we will use AWS Lambda. The AWS Lambda function is already deployed for you in your AWS account. The only thing we need to setup is the Trigger. This Functions convert the records from Avro to CSV. Navigate to the AWS Lambda Console and choose click on the MskLambda-Function .","title":"Consume data from MSK Serverless using Lambda"},{"location":"day2/part4/4_LambdaConsumer/exercise/#setup-amazon-msk-trigger","text":"Click on the Add trigger button to create a new trigger for the Lambda function. Choose MSK as Source. Select your cluster in the drop down menu. Set the configuration parameters for the trigger: - Batch Size: 20 - Starting Position: Latest - Batch window: 20 - Topic name: clickstream After setting the configuration click Add to create the trigger. Wait for the trigger to become active (this can take a few minutes). You have now successfully setup a Lambda functions that reads messages from a Kafka topic, transforms it into csv format and then stores it in Amazon S3.","title":"Setup Amazon MSK Trigger"},{"location":"day2/part4/5_QS_Dashboard/exercise/","text":"Create Quicksight Dashboard \u00b6 Now that we have transformed data, we can now use Amazon QuickSight to visualize and analyze data. Create a QuickSight Account \u00b6 To begin head to the QuickSight page and create a new standard QuickSight account. Create a unique QuickSight account user name (e.g workshopuserRANDOM_NUMBERS) and you can use a fake email address for notifications. You must also select your s3 bucket with the clickstream data Once s3 bucket selected, you can finish and create your QuickSight Account Creating a Dataset \u00b6 Once your account is setup head over to the QuickSight Datasets Console . In the Dataset console click New dataset on the top right to create our dataset. Select S3 and enter a name for your dataset. Additionally, we have to create a manifest file to specify the exact data we want to utilize for our analysis. Open a text editor and create a JSON file (e.g. quicksight_manifest.json) and enter the following. Make sure to replace YOUR_DEST_BUCKET with your destination bucket. You may find the name of your destination bucket by navigating to the Amazon S3 Console Page . Select your bucket, copy the name from the bucket detail page, andpaste into your manifest file. { \"fileLocations\": [ { \"URIPrefixes\": [ \"s3://YOUR_DEST_BUCKET/\" ] } ] } Click connect once file is uploaded, then press Visualize to get to the QuickSight analysis creator. You will be presented with the following pop-up. Select Interactive Sheet. Playtime \u00b6 Now its Playtime, what type of graphs can you create with the data provided? Can you create a pie chart of the data by device type? How about a bar chart highlighting records by event type? *What about a Metric that just has the total number of Events? In the top right corner, you can publish your analysis as a Dashboard or export to a PDF. Feel free to check out what others around you have built.","title":"5 - Create Quicksight Dashboard"},{"location":"day2/part4/5_QS_Dashboard/exercise/#create-quicksight-dashboard","text":"Now that we have transformed data, we can now use Amazon QuickSight to visualize and analyze data.","title":"Create Quicksight Dashboard"},{"location":"day2/part4/5_QS_Dashboard/exercise/#create-a-quicksight-account","text":"To begin head to the QuickSight page and create a new standard QuickSight account. Create a unique QuickSight account user name (e.g workshopuserRANDOM_NUMBERS) and you can use a fake email address for notifications. You must also select your s3 bucket with the clickstream data Once s3 bucket selected, you can finish and create your QuickSight Account","title":"Create a QuickSight Account"},{"location":"day2/part4/5_QS_Dashboard/exercise/#creating-a-dataset","text":"Once your account is setup head over to the QuickSight Datasets Console . In the Dataset console click New dataset on the top right to create our dataset. Select S3 and enter a name for your dataset. Additionally, we have to create a manifest file to specify the exact data we want to utilize for our analysis. Open a text editor and create a JSON file (e.g. quicksight_manifest.json) and enter the following. Make sure to replace YOUR_DEST_BUCKET with your destination bucket. You may find the name of your destination bucket by navigating to the Amazon S3 Console Page . Select your bucket, copy the name from the bucket detail page, andpaste into your manifest file. { \"fileLocations\": [ { \"URIPrefixes\": [ \"s3://YOUR_DEST_BUCKET/\" ] } ] } Click connect once file is uploaded, then press Visualize to get to the QuickSight analysis creator. You will be presented with the following pop-up. Select Interactive Sheet.","title":"Creating a Dataset"},{"location":"day2/part4/5_QS_Dashboard/exercise/#playtime","text":"Now its Playtime, what type of graphs can you create with the data provided? Can you create a pie chart of the data by device type? How about a bar chart highlighting records by event type? *What about a Metric that just has the total number of Events? In the top right corner, you can publish your analysis as a Dashboard or export to a PDF. Feel free to check out what others around you have built.","title":"Playtime"},{"location":"day2/part4/6_KDA_Consumer/exercise/","text":"Consume using Kinesis Data Analytics and write to Amazon OpenSearch Service \u00b6 In this module, we would like to consume data from MSK Serverless cluster using Amazon Kinesis Data Analytics - Flink, process the data and write the data in Amazon OpenSearch Service The OpenSearch Service is deployed in your AWS account and Dashboards are already configured. We need to configure Kinesis Data Analytics application with correct runtime parameters. Navigate to the AWS Kinesis Analytics Console and click on the application KDAFlinkClickstream-msk-serverless-workshop-cfn . Configure Kinesis Analytics Application \u00b6 Click on the Configure button to update the Kinesis Data Analytics configuration. Scroll to RunTime Properties section. Update BootStrapServers and keep restof the value as default. Save your changes. Run Kinesis Analytics Application \u00b6 Click on the Run button to run the application. This takes a few minutes. Open Apache Flink Dashboard \u00b6 Once the Kinesis Analytics application is running, click on Open Apache Flink dashboard to open the Flink dashboard. Click on the Job Name Flink Streaming Job This would show the Job details including the operator directed acyclic graph and data flowing through the operators. You have now successfully setup a Kinesis Analytics application that reads messages from a Kafka topic, process the data and then write it to Amazon OpenSearch Service. Lets check the data in OpenSearch Dashboard! Amazon OpenSearch Dashboard Visualisation \u00b6 In this module, we would see the dashboard visualisation generated based onthe ingested data from Kinesis Analytics application. Amazon OpenSearch Service \u00b6 Go to AWS CloudFormation Console and click on stack named msk-serverless-workshop-cfn. Go to the Outputs tab of the stack. Right-click on the OpenSearchDashboardEndpoint and click Open Link in new tab . This would try to redirect you to the OpenSearch Dashboard login page. As OpenSearch Service is deployed in a VPC, we are using NGinx reverse proxy to access the OpenSearch Dashboard outside of the VPC. We are using self signed certificate for the Nginx . however recommended to use valid certificate for production . If you are accessing the url using Google Chrome, you have to click on the webpage body and type thisisunsafe. This would redirect you to actual OpenSearch login page. Go back to the CloudFormation output, retrieve the values for OpenSearchMasterUserName and OpenSearchMasterPassword and use it for login. Ensure that there are no spaces copied for OpenSearchMasterPassword , else you won ' t be able to login to OpenSearch Dashboard. Select Global tenant on the popup dialog box. Amazon OpenSearch Dashboard \u00b6 Click on the hamburger menu on the left of the screen as highlighted below and then click on Dashboard . This would open the OpenSearch Dashboard where you can see the data gets plotted. You have now confirmed data flowing to OpenSearch Service and visualizations are rendered.","title":"6 - Consume using Kinesis Data Analytics and write to Amazon OpenSearch Service"},{"location":"day2/part4/6_KDA_Consumer/exercise/#consume-using-kinesis-data-analytics-and-write-to-amazon-opensearch-service","text":"In this module, we would like to consume data from MSK Serverless cluster using Amazon Kinesis Data Analytics - Flink, process the data and write the data in Amazon OpenSearch Service The OpenSearch Service is deployed in your AWS account and Dashboards are already configured. We need to configure Kinesis Data Analytics application with correct runtime parameters. Navigate to the AWS Kinesis Analytics Console and click on the application KDAFlinkClickstream-msk-serverless-workshop-cfn .","title":"Consume using Kinesis Data Analytics and write to Amazon OpenSearch Service"},{"location":"day2/part4/6_KDA_Consumer/exercise/#configure-kinesis-analytics-application","text":"Click on the Configure button to update the Kinesis Data Analytics configuration. Scroll to RunTime Properties section. Update BootStrapServers and keep restof the value as default. Save your changes.","title":"Configure Kinesis Analytics Application"},{"location":"day2/part4/6_KDA_Consumer/exercise/#run-kinesis-analytics-application","text":"Click on the Run button to run the application. This takes a few minutes.","title":"Run Kinesis Analytics Application"},{"location":"day2/part4/6_KDA_Consumer/exercise/#open-apache-flink-dashboard","text":"Once the Kinesis Analytics application is running, click on Open Apache Flink dashboard to open the Flink dashboard. Click on the Job Name Flink Streaming Job This would show the Job details including the operator directed acyclic graph and data flowing through the operators. You have now successfully setup a Kinesis Analytics application that reads messages from a Kafka topic, process the data and then write it to Amazon OpenSearch Service. Lets check the data in OpenSearch Dashboard!","title":"Open Apache Flink Dashboard"},{"location":"day2/part4/6_KDA_Consumer/exercise/#amazon-opensearch-dashboard-visualisation","text":"In this module, we would see the dashboard visualisation generated based onthe ingested data from Kinesis Analytics application.","title":"Amazon OpenSearch Dashboard Visualisation"},{"location":"day2/part4/6_KDA_Consumer/exercise/#amazon-opensearch-service","text":"Go to AWS CloudFormation Console and click on stack named msk-serverless-workshop-cfn. Go to the Outputs tab of the stack. Right-click on the OpenSearchDashboardEndpoint and click Open Link in new tab . This would try to redirect you to the OpenSearch Dashboard login page. As OpenSearch Service is deployed in a VPC, we are using NGinx reverse proxy to access the OpenSearch Dashboard outside of the VPC. We are using self signed certificate for the Nginx . however recommended to use valid certificate for production . If you are accessing the url using Google Chrome, you have to click on the webpage body and type thisisunsafe. This would redirect you to actual OpenSearch login page. Go back to the CloudFormation output, retrieve the values for OpenSearchMasterUserName and OpenSearchMasterPassword and use it for login. Ensure that there are no spaces copied for OpenSearchMasterPassword , else you won ' t be able to login to OpenSearch Dashboard. Select Global tenant on the popup dialog box.","title":"Amazon OpenSearch Service"},{"location":"day2/part4/6_KDA_Consumer/exercise/#amazon-opensearch-dashboard","text":"Click on the hamburger menu on the left of the screen as highlighted below and then click on Dashboard . This would open the OpenSearch Dashboard where you can see the data gets plotted. You have now confirmed data flowing to OpenSearch Service and visualizations are rendered.","title":"Amazon OpenSearch Dashboard"},{"location":"day2/part5/Prerequisites/exercise/","text":"1. Security Group Configuration \u00b6 Add self route to MSK cluster SG Click on Services in the top left corner of the console, and select MSK 2. Go to the MSK (Right click -> Open Link in New Tab) and choose the cluster MSKCluster-msk-labs-default 3. Click on Properties Tab and scroll down to Networking settings 4. In Networking settings , under Primary VPC configuration look for Security groups applied 5. Right click and open the Security Group in a New Tab 6. Copy the Security group name 7. Scroll down and you will find Inbound rules , then click Edit Inbound rules 8. Scroll down and Add rule: (Add a self route as below) Type: All TCP Protocol: TCP Port range: 0 - 65535 Source: [paste the value of the Security Group Id you copied in the step-6] Description: Plaintext Kafka - Lambda 9. Click Save rules 2. Create S3 Bucket \u00b6 This S3 bucket will be used to store athena query information and spill data information from Lambda connector setup. Navigate to S3 Console Click Create bucket 3. In General configuration , provide the Bucket name as msk-athena-bucket-< AWS-Account-Number > 4. Scroll down completely and click Create bucket . Leave all other configuration options as default 3. Configure Athena \u00b6 This is used to configure Athena result location. Navigate to Athena Console and click on Launch query editor 2. Click on Settings tab 3. In Query result and encryption settings, click on Manage 4. In Query result location and encryption, click on Browse S3 5. Choose the radio button beside the bucket msk-athena-bucket-< AWS Account Number > 6. Click Choose 7. Add the folder path to the Location of query result as below: athena-spill/ Click Save 4. Setting up IAM \u00b6 This is used to create IAM policies and IAM role for the redshift cluster Create IAM Policy \u00b6 Create an IAM Policy, which provides permission for communication with the Amazon MSK cluster. The policy you need depends on the authentication method used on your cluster, if you use Amazon MSK. See Authentication and Authorization for Apache Kafka APIs for authentication methods available in Amazon MSK. Navigate to IAM Console , Click on left pane and choose Policies in Acess management section 2. Click on Create policy 3. In Policy editor , choose JSON button 4. Copy and paste the below policy in the Policy editor section ( Overwrite the default provided policy ) An IAM policy for Amazon MSK using unauthenticated access: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"kafka:GetBootstrapBrokers\" ], \"Resource\": \"*\" } ] } 5. Click Next 6. In Policy details , provide below details Policy name: MSK-unauthenticated-access Description: An IAM policy for Amazon MSK using unauthenticated access 7. Click Create policy Create IAM Role \u00b6 Create an IAM role with a trust policy that allows your Amazon Redshift cluster to assume the role. For information about how to configure the trust policy for the IAM role, see Authorizing Amazon Redshift to access other AWS services on your behalf . Navigate to IAM Console , Click on left pane and choose Roles in Acess management section 2. Click on Create role 3. In Use cases for other AWS services , choose Redshift from the drop down 4. Choose Redshift - Customizable and click Next 5. Select the above create policy ( MSK-unauthenticated-access ) and Click Next 6. In Role details section, provide below details: Role name: MSK-Redshift-role 7. Click Create role 5. Create Redshift Subnet Group \u00b6 Navigate to Redshift Console , Click on left pane and choose Subnet groups in Configurations section 2. Click Create cluster subnet group 3. In Cluster subnet group details , provide below configuration details: Name: msk-redshift-vpc-subnet-group Description: This subnet group contains msk and redshift subnet groups 4. In Add subnets section, go to VPC drop down and choose MSKVPC 5. Click on Add all the subnets for this VPC 6. Click Create cluster subnet group 6. Create Redshift Cluster \u00b6 Navigate to Redshift Console , Click on left pane and choose Provisioned clusters dashboard and click on Create cluster 2. In Cluster configuration , provide the below details: Cluster identifier : redshift-cluster-1 Choose the size of the cluster : I'll choose Node type : dc2.large Number of nodes : 1 3. In Database configurations , provide the below details: Admin user name : awsuser Admin user password : < Password > 4. In Associated IAM roles , click on Associate IAM roles 5. Select the radio button beside the IAM role msk-redshift-role and click Associate IAM roles 6. In Additional configurations , toggle the Use defaults option. 7. Expand Network and security section and provide below configuration: Virtual private cloud (VPC) : MSKVPC VPC security groups : msk-labs-default-MSKSecurityGroup Cluster subnet group : msk-redshift-vpc-subnet-group Availability Zone : us-east-2a Enhanced VPC routing : Turn off Publicly accessible : Check Box (True) Elastic IP address : None 8. Click Create cluster 7. Cloud 9 Setup \u00b6 Open Cloud9 , select the host msk-labs-default-Cloud9EC2Bastion , open Cloud9 IDE and install following tools: Install kafka tools \u00b6 In this step, you install Apache Kafka client libraries and tools on the cloud9 setup: wget https://archive.apache.org/dist/kafka/2.6.2/kafka_2.12-2.6.2.tgz tar -xzf kafka_2.12-2.6.2.tgz ln -s kafka_2.12-2.6.2 kafka Install jq, envsubst \u00b6 sudo yum -y install jq gettext bash-completion moreutils 8. Kafka Setup \u00b6 Create Topic \u00b6 Go to the MSK (Right click -> Open Link in New Tab) and choose the cluster MSKCluster-msk-labs-default 2. In Cluster summary, Click on View client information 3. Copy any one of the broker-ids(connection string for the private endpoint) from Authentication type - Plaintext Note: You will get three endpoints for each of the brokers. You only need one broker endpoint for the following step. 4. Go to the EC2 console and open aws-cloud9 instance properties by clicking on it.Copy the security group id and save it. 5. Go back to the MSK console. Select Properties scroll down, and under Networking settings click on the security group. This will open the security group. 6. From the security group, click on Edit inbound rules . 7. Click on Add rule with the following configuration. Type: All TCP Protocol: TCP Port range: 0-65535 Source type: Custom Source: Paste the security group that you copied from the EC2 console 8. Now we will be creating a sample topic using cloud9 host. 9. Open Cloud9 , Click open beside the host msk-labs-default-Cloud9EC2Bastion 10. Click on icon (+), choose New Terminal [Please check the below screenshot] 11. In the above terminal, first we are going to create a MSK Topic. To create a Kafka Topic : Run the following command, replacing BootstrapServerString with one of the broker endpoints that you obtained in the previous step. path-to-your-kafka-installation/bin/kafka-topics.sh --create --bootstrap-server BootstrapServerString --replication-factor 3 --partitions 1 --topic MSKTopicName Example command : kafka_2.12-2.6.2/bin/kafka-topics.sh --create --bootstrap-server b-1.mskclustermsklabsdefa.1je9hf.c21.kafka.us-east-1.amazonaws.com:9092 --replication-factor 3 --partitions 1 --topic orders If the command succeeds, you see the following message: Created topic orders. Produce and consume data \u00b6 To produce and consume messages, in the above terminal itself we will be running the following command to start a console producer. To produce data to a Kafka Topic : Replace BootstrapServerString with the plaintext connection string that you obtained in create topic path-to-your-kafka-installation/bin/kafka-console-producer.sh --broker-list BootstrapServerString --producer.config client.properties --topic MSKTopicName Example command : kafka_2.12-2.6.2/bin/kafka-console-producer.sh --broker-list b-1.mskclustermsklabsdefa.1je9hf.c21.kafka.us-east-1.amazonaws.com:9092 --topic orders Enter the following data, and press Enter. Data : \u00b6 {\"customer_id\": \"000\",\"item_id\":1} {\"customer_id\": \"abe\",\"item_id\":2} {\"customer_id\": \"def\",\"item_id\":3} {\"customer_id\": \"ghi\",\"item_id\":4} {\"customer_id\": \"jkl\",\"item_id\":5} {\"customer_id\": \"mno\",\"item_id\":6} {\"customer_id\": \"pqr\",\"item_id\":7} {\"customer_id\": \"rst\",\"item_id\":8} {\"customer_id\": \"uvw\",\"item_id\":9} {\"customer_id\": \"xyz\",\"item_id\":10} {\"customer_id\": \"000\",\"item_id\":11} {\"customer_id\": \"abe\",\"item_id\":12} {\"customer_id\": \"000\",\"item_id\":13} Note: Every time you enter a line and press Enter, that line is sent to your Apache Kafka cluster as a separate message. To consume data from a Kafka Topic \u00b6 In the below terminal, we will be running the following command to start a console consumer. Replace BootstrapServerString with the plaintext connection string that you saved earlier. path-to-your-kafka-installation/bin/kafka-console-consumer.sh --bootstrap-server BootstrapServerString --topic MSKTopicName --from-beginning Example command : kafka_2.12-2.6.2/bin/kafka-console-consumer.sh --bootstrap-server b-1.mskclustermsklabsdefa.1je9hf.c21.kafka.us-east-1.amazonaws.com:9092 --topic orders --from-beginning You start seeing the messages you entered earlier when you used the console producer command .","title":"2 - Prerequisites"},{"location":"day2/part5/Prerequisites/exercise/#1-security-group-configuration","text":"Add self route to MSK cluster SG Click on Services in the top left corner of the console, and select MSK 2. Go to the MSK (Right click -> Open Link in New Tab) and choose the cluster MSKCluster-msk-labs-default 3. Click on Properties Tab and scroll down to Networking settings 4. In Networking settings , under Primary VPC configuration look for Security groups applied 5. Right click and open the Security Group in a New Tab 6. Copy the Security group name 7. Scroll down and you will find Inbound rules , then click Edit Inbound rules 8. Scroll down and Add rule: (Add a self route as below) Type: All TCP Protocol: TCP Port range: 0 - 65535 Source: [paste the value of the Security Group Id you copied in the step-6] Description: Plaintext Kafka - Lambda 9. Click Save rules","title":"1. Security Group Configuration"},{"location":"day2/part5/Prerequisites/exercise/#2-create-s3-bucket","text":"This S3 bucket will be used to store athena query information and spill data information from Lambda connector setup. Navigate to S3 Console Click Create bucket 3. In General configuration , provide the Bucket name as msk-athena-bucket-< AWS-Account-Number > 4. Scroll down completely and click Create bucket . Leave all other configuration options as default","title":"2. Create S3 Bucket"},{"location":"day2/part5/Prerequisites/exercise/#3-configure-athena","text":"This is used to configure Athena result location. Navigate to Athena Console and click on Launch query editor 2. Click on Settings tab 3. In Query result and encryption settings, click on Manage 4. In Query result location and encryption, click on Browse S3 5. Choose the radio button beside the bucket msk-athena-bucket-< AWS Account Number > 6. Click Choose 7. Add the folder path to the Location of query result as below: athena-spill/ Click Save","title":"3. Configure Athena"},{"location":"day2/part5/Prerequisites/exercise/#4-setting-up-iam","text":"This is used to create IAM policies and IAM role for the redshift cluster","title":"4. Setting up IAM"},{"location":"day2/part5/Prerequisites/exercise/#create-iam-policy","text":"Create an IAM Policy, which provides permission for communication with the Amazon MSK cluster. The policy you need depends on the authentication method used on your cluster, if you use Amazon MSK. See Authentication and Authorization for Apache Kafka APIs for authentication methods available in Amazon MSK. Navigate to IAM Console , Click on left pane and choose Policies in Acess management section 2. Click on Create policy 3. In Policy editor , choose JSON button 4. Copy and paste the below policy in the Policy editor section ( Overwrite the default provided policy ) An IAM policy for Amazon MSK using unauthenticated access: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"kafka:GetBootstrapBrokers\" ], \"Resource\": \"*\" } ] } 5. Click Next 6. In Policy details , provide below details Policy name: MSK-unauthenticated-access Description: An IAM policy for Amazon MSK using unauthenticated access 7. Click Create policy","title":"Create IAM Policy"},{"location":"day2/part5/Prerequisites/exercise/#create-iam-role","text":"Create an IAM role with a trust policy that allows your Amazon Redshift cluster to assume the role. For information about how to configure the trust policy for the IAM role, see Authorizing Amazon Redshift to access other AWS services on your behalf . Navigate to IAM Console , Click on left pane and choose Roles in Acess management section 2. Click on Create role 3. In Use cases for other AWS services , choose Redshift from the drop down 4. Choose Redshift - Customizable and click Next 5. Select the above create policy ( MSK-unauthenticated-access ) and Click Next 6. In Role details section, provide below details: Role name: MSK-Redshift-role 7. Click Create role","title":"Create IAM Role"},{"location":"day2/part5/Prerequisites/exercise/#5-create-redshift-subnet-group","text":"Navigate to Redshift Console , Click on left pane and choose Subnet groups in Configurations section 2. Click Create cluster subnet group 3. In Cluster subnet group details , provide below configuration details: Name: msk-redshift-vpc-subnet-group Description: This subnet group contains msk and redshift subnet groups 4. In Add subnets section, go to VPC drop down and choose MSKVPC 5. Click on Add all the subnets for this VPC 6. Click Create cluster subnet group","title":"5. Create Redshift Subnet Group"},{"location":"day2/part5/Prerequisites/exercise/#6-create-redshift-cluster","text":"Navigate to Redshift Console , Click on left pane and choose Provisioned clusters dashboard and click on Create cluster 2. In Cluster configuration , provide the below details: Cluster identifier : redshift-cluster-1 Choose the size of the cluster : I'll choose Node type : dc2.large Number of nodes : 1 3. In Database configurations , provide the below details: Admin user name : awsuser Admin user password : < Password > 4. In Associated IAM roles , click on Associate IAM roles 5. Select the radio button beside the IAM role msk-redshift-role and click Associate IAM roles 6. In Additional configurations , toggle the Use defaults option. 7. Expand Network and security section and provide below configuration: Virtual private cloud (VPC) : MSKVPC VPC security groups : msk-labs-default-MSKSecurityGroup Cluster subnet group : msk-redshift-vpc-subnet-group Availability Zone : us-east-2a Enhanced VPC routing : Turn off Publicly accessible : Check Box (True) Elastic IP address : None 8. Click Create cluster","title":"6. Create Redshift Cluster"},{"location":"day2/part5/Prerequisites/exercise/#7-cloud-9-setup","text":"Open Cloud9 , select the host msk-labs-default-Cloud9EC2Bastion , open Cloud9 IDE and install following tools:","title":"7. Cloud 9 Setup"},{"location":"day2/part5/Prerequisites/exercise/#install-kafka-tools","text":"In this step, you install Apache Kafka client libraries and tools on the cloud9 setup: wget https://archive.apache.org/dist/kafka/2.6.2/kafka_2.12-2.6.2.tgz tar -xzf kafka_2.12-2.6.2.tgz ln -s kafka_2.12-2.6.2 kafka","title":"Install kafka tools"},{"location":"day2/part5/Prerequisites/exercise/#install-jq-envsubst","text":"sudo yum -y install jq gettext bash-completion moreutils","title":"Install jq, envsubst"},{"location":"day2/part5/Prerequisites/exercise/#8-kafka-setup","text":"","title":"8. Kafka Setup"},{"location":"day2/part5/Prerequisites/exercise/#create-topic","text":"Go to the MSK (Right click -> Open Link in New Tab) and choose the cluster MSKCluster-msk-labs-default 2. In Cluster summary, Click on View client information 3. Copy any one of the broker-ids(connection string for the private endpoint) from Authentication type - Plaintext Note: You will get three endpoints for each of the brokers. You only need one broker endpoint for the following step. 4. Go to the EC2 console and open aws-cloud9 instance properties by clicking on it.Copy the security group id and save it. 5. Go back to the MSK console. Select Properties scroll down, and under Networking settings click on the security group. This will open the security group. 6. From the security group, click on Edit inbound rules . 7. Click on Add rule with the following configuration. Type: All TCP Protocol: TCP Port range: 0-65535 Source type: Custom Source: Paste the security group that you copied from the EC2 console 8. Now we will be creating a sample topic using cloud9 host. 9. Open Cloud9 , Click open beside the host msk-labs-default-Cloud9EC2Bastion 10. Click on icon (+), choose New Terminal [Please check the below screenshot] 11. In the above terminal, first we are going to create a MSK Topic. To create a Kafka Topic : Run the following command, replacing BootstrapServerString with one of the broker endpoints that you obtained in the previous step. path-to-your-kafka-installation/bin/kafka-topics.sh --create --bootstrap-server BootstrapServerString --replication-factor 3 --partitions 1 --topic MSKTopicName Example command : kafka_2.12-2.6.2/bin/kafka-topics.sh --create --bootstrap-server b-1.mskclustermsklabsdefa.1je9hf.c21.kafka.us-east-1.amazonaws.com:9092 --replication-factor 3 --partitions 1 --topic orders If the command succeeds, you see the following message: Created topic orders.","title":"Create Topic"},{"location":"day2/part5/Prerequisites/exercise/#produce-and-consume-data","text":"To produce and consume messages, in the above terminal itself we will be running the following command to start a console producer. To produce data to a Kafka Topic : Replace BootstrapServerString with the plaintext connection string that you obtained in create topic path-to-your-kafka-installation/bin/kafka-console-producer.sh --broker-list BootstrapServerString --producer.config client.properties --topic MSKTopicName Example command : kafka_2.12-2.6.2/bin/kafka-console-producer.sh --broker-list b-1.mskclustermsklabsdefa.1je9hf.c21.kafka.us-east-1.amazonaws.com:9092 --topic orders Enter the following data, and press Enter.","title":"Produce and consume data"},{"location":"day2/part5/Prerequisites/exercise/#data","text":"{\"customer_id\": \"000\",\"item_id\":1} {\"customer_id\": \"abe\",\"item_id\":2} {\"customer_id\": \"def\",\"item_id\":3} {\"customer_id\": \"ghi\",\"item_id\":4} {\"customer_id\": \"jkl\",\"item_id\":5} {\"customer_id\": \"mno\",\"item_id\":6} {\"customer_id\": \"pqr\",\"item_id\":7} {\"customer_id\": \"rst\",\"item_id\":8} {\"customer_id\": \"uvw\",\"item_id\":9} {\"customer_id\": \"xyz\",\"item_id\":10} {\"customer_id\": \"000\",\"item_id\":11} {\"customer_id\": \"abe\",\"item_id\":12} {\"customer_id\": \"000\",\"item_id\":13} Note: Every time you enter a line and press Enter, that line is sent to your Apache Kafka cluster as a separate message.","title":"Data:"},{"location":"day2/part5/Prerequisites/exercise/#to-consume-data-from-a-kafka-topic","text":"In the below terminal, we will be running the following command to start a console consumer. Replace BootstrapServerString with the plaintext connection string that you saved earlier. path-to-your-kafka-installation/bin/kafka-console-consumer.sh --bootstrap-server BootstrapServerString --topic MSKTopicName --from-beginning Example command : kafka_2.12-2.6.2/bin/kafka-console-consumer.sh --bootstrap-server b-1.mskclustermsklabsdefa.1je9hf.c21.kafka.us-east-1.amazonaws.com:9092 --topic orders --from-beginning You start seeing the messages you entered earlier when you used the console producer command .","title":"To consume data from a Kafka Topic"},{"location":"day2/part5/athena/exercise/","text":"MSK Integration with Athena \u00b6 In this lab, we will analyze real-time streaming data in Amazon MSK with Amazon Athena. Solution overview \u00b6 First, we will show you how to get started with real-time SQL analytics using Athena and its connector for MSK. The process involves: Registering the schema of your streaming data with AWS Glue Schema Registry . Schema Registry is a feature of AWS Glue that allows you to validate and reliably evolve streaming data against JSON schemas. It can also serialize data into a compressed format, which helps you save on data transfer and storage costs. Creating a new instance of the Amazon Athena MSK Connector . Athena connectors are pre-built applications that run as serverless AWS Lambda applications, so there\u2019s no need for standalone data export processes. Using the Athena console to run interactive SQL queries on your Kafka topics. Get started with Athena\u2019s connector for Amazon MSK \u00b6 In this section, we\u2019ll cover the steps necessary to set up your MSK cluster to work with Athena to run SQL queries on your Kafka topics. 1. Define the schema of your Kafka topics with AWS Glue Schema Registry \u00b6 To run SQL queries on your Kafka topics, you\u2019ll first need to define the schema of your topics as Athena uses this metadata for query planning. AWS Glue makes it easy to do this with its Schema Registry feature for streaming data sources. Creating Glue Stream schema registries \u00b6 In Stream schema registries, click on Add registry 2. Provide the below configuration: Name: customer_schema Description: {AthenaFederationMSK} 3.Click Add registry Schema Registry allows you to centrally discover, control, and evolve streaming data schemas for use in analytics applications such as Athena. With AWS Glue Schema Registry, you can manage and enforce schemas on your data streaming applications using convenient integrations with Apache Kafka. To learn more, see AWS Glue Schema Registry and Getting started with Schema Registry . If configured to do so, the producer of data can auto-register its schema and changes to it with AWS Glue. This is especially useful in use cases where the contents of the data is likely to change over time. However, you can also specify the schema manually, resembling the following JSON structure. Creating Schema in Glue Stream schema registries \u00b6 Choose the Stream schehma registry : customer_schema Click Create schema 3. Provide the below configuration Schema name: orders Registry: customer_schema Data format: JSON Compatibility mode: Full - combination of 'Backward' and 'Forward' Description: {AthenaFederationMSK} ##### First schema version { \"topicName\": \"orders\", \"message\": { \"dataFormat\": \"json\", \"fields\": [ { \"name\": \"customer_id\", \"mapping\": \"customer_id\", \"type\": \"VARCHAR\" }, { \"name\": \"item_id\", \"mapping\": \"item_id\", \"type\": \"INTEGER\" } ] } } 4. Click Create schema and version For additional information on schema set up, see Schema examples for the AWS Glue Schema Registry . 2. Configure the Athena connector for MSK \u00b6 With your schema registered with Glue, the next step is to set up the Athena connector for MSK. We recommend using the Athena console for this step. For more background on the steps involved, see Deploying a connector and connecting to a data source . In Athena, federated data source connectors are applications that run on AWS Lambda and handle communication between your target data source and Athena. When a query runs on a federated source, Athena calls the Lambda function and tasks it with running the parts of your query that are specific to that source. To learn more about the query execution workflow, see Using Amazon Athena Federated Query in the Amazon Athena User Guide. Navigate to Athena console and selecting Data sources on the left navigation, then choose Create data source 2. Click on Create Data sources 3. Choose a data source: Type MSK 4. Choose the radio button beside the connector Amazon MSK and click Next 5. Enter the following details in Data source details section: Data source name: msk Description - To connect to amazon msk cluster 6. Under Connection details section, select Create Lambda function . This will bring you to the AWS Lambda console where you\u2019ll provide additional configuration properties 7. Scroll down to Application settings and provide below details ##### Fetch MSK Configuration To get some of the details you will have to navigate to MSK console and click on cluster name as MSKCluster-msk-labs-default In Cluster summary, Click on View client Information Copy any one of the broker-ids(connection string for the private endpoint) from Authentication type - Plaintext and paste it in the Lambda configuration \"KafkaEndpoint\" Note: You will get three endpoints for each of the brokers. You only need one broker endpoint for the following step. (Paste this in KafkaEndpoint) and click Done Click on Properties Tab and scroll down to Networking settings In Networking settings , under Primary VPC configuration look for Subnets and Security groups applied. Copy security-group-id and one subnet-id , paste them in the below configuration accordingly KafkaEndpoint: <paste the broker-id here> LambdaFunctionName: msk-athena-lambda-function SecurityGroupIds: <paste the security-group-id here> SpillBucket: msk-athena-bucket-<paste the AWS-Account-Number> SpillPrefix: msk-athena-spill SubnetIds: <paste the subnet-id here > 8. Click on I acknowledge that this app creates custom IAM roles and resource policies . 9. Click Deploy (wait for a minute to auto-refresh the page) 10. Close the Lambda page and go back to previous tab (Athena Console - Enter data source details) 11. In Connection details, use the refresh button and choose Lambda function which we created in the previous step ( msk-athena-lambda-function ) 12. Click Next 13. Review the details and click Create data source 3. Run queries on streaming data using Athena \u00b6 With your MSK data connector set up, you can now run SQL queries on the data. Let\u2019s explore a few use cases in more detail. Use case: interactive analysis If you want to run queries that aggregate, group, or filter your MSK data, you can run interactive queries using Athena. These queries will run against the current state of your Kafka topics at the time the query was submitted. Navigate to Athena Console Under Editor tab, in Data section, you will observe the following: 3. Choose msk from the drop down. 4. Choose customer_schema from the database Before running any queries, it may be helpful to validate the schema and data types available within your Kafka topics. To do this, run the DESCRIBE command on your Kafka topic, which appears in Athena as a table, as shown below. In this query, the orders table corresponds to the topic you specified in the Schema Registry customer_schema . DESCRIBE msk.customer_schema.orders Now that you know the contents of your topic, you can begin to develop analytical queries. A sample query for querying all data in a topic is: select * from msk.customer_schema.orders; You can proceed to next lab!","title":"3 - Integration with Athena"},{"location":"day2/part5/athena/exercise/#msk-integration-with-athena","text":"In this lab, we will analyze real-time streaming data in Amazon MSK with Amazon Athena.","title":"MSK Integration with Athena"},{"location":"day2/part5/athena/exercise/#solution-overview","text":"First, we will show you how to get started with real-time SQL analytics using Athena and its connector for MSK. The process involves: Registering the schema of your streaming data with AWS Glue Schema Registry . Schema Registry is a feature of AWS Glue that allows you to validate and reliably evolve streaming data against JSON schemas. It can also serialize data into a compressed format, which helps you save on data transfer and storage costs. Creating a new instance of the Amazon Athena MSK Connector . Athena connectors are pre-built applications that run as serverless AWS Lambda applications, so there\u2019s no need for standalone data export processes. Using the Athena console to run interactive SQL queries on your Kafka topics.","title":"Solution overview"},{"location":"day2/part5/athena/exercise/#get-started-with-athenas-connector-for-amazon-msk","text":"In this section, we\u2019ll cover the steps necessary to set up your MSK cluster to work with Athena to run SQL queries on your Kafka topics.","title":"Get started with Athena\u2019s connector for Amazon MSK"},{"location":"day2/part5/athena/exercise/#1-define-the-schema-of-your-kafka-topics-with-aws-glue-schema-registry","text":"To run SQL queries on your Kafka topics, you\u2019ll first need to define the schema of your topics as Athena uses this metadata for query planning. AWS Glue makes it easy to do this with its Schema Registry feature for streaming data sources.","title":"1. Define the schema of your Kafka topics with AWS Glue Schema Registry"},{"location":"day2/part5/athena/exercise/#creating-glue-stream-schema-registries","text":"In Stream schema registries, click on Add registry 2. Provide the below configuration: Name: customer_schema Description: {AthenaFederationMSK} 3.Click Add registry Schema Registry allows you to centrally discover, control, and evolve streaming data schemas for use in analytics applications such as Athena. With AWS Glue Schema Registry, you can manage and enforce schemas on your data streaming applications using convenient integrations with Apache Kafka. To learn more, see AWS Glue Schema Registry and Getting started with Schema Registry . If configured to do so, the producer of data can auto-register its schema and changes to it with AWS Glue. This is especially useful in use cases where the contents of the data is likely to change over time. However, you can also specify the schema manually, resembling the following JSON structure.","title":"Creating Glue Stream schema registries"},{"location":"day2/part5/athena/exercise/#creating-schema-in-glue-stream-schema-registries","text":"Choose the Stream schehma registry : customer_schema Click Create schema 3. Provide the below configuration Schema name: orders Registry: customer_schema Data format: JSON Compatibility mode: Full - combination of 'Backward' and 'Forward' Description: {AthenaFederationMSK} ##### First schema version { \"topicName\": \"orders\", \"message\": { \"dataFormat\": \"json\", \"fields\": [ { \"name\": \"customer_id\", \"mapping\": \"customer_id\", \"type\": \"VARCHAR\" }, { \"name\": \"item_id\", \"mapping\": \"item_id\", \"type\": \"INTEGER\" } ] } } 4. Click Create schema and version For additional information on schema set up, see Schema examples for the AWS Glue Schema Registry .","title":"Creating Schema in Glue Stream schema registries"},{"location":"day2/part5/athena/exercise/#2-configure-the-athena-connector-for-msk","text":"With your schema registered with Glue, the next step is to set up the Athena connector for MSK. We recommend using the Athena console for this step. For more background on the steps involved, see Deploying a connector and connecting to a data source . In Athena, federated data source connectors are applications that run on AWS Lambda and handle communication between your target data source and Athena. When a query runs on a federated source, Athena calls the Lambda function and tasks it with running the parts of your query that are specific to that source. To learn more about the query execution workflow, see Using Amazon Athena Federated Query in the Amazon Athena User Guide. Navigate to Athena console and selecting Data sources on the left navigation, then choose Create data source 2. Click on Create Data sources 3. Choose a data source: Type MSK 4. Choose the radio button beside the connector Amazon MSK and click Next 5. Enter the following details in Data source details section: Data source name: msk Description - To connect to amazon msk cluster 6. Under Connection details section, select Create Lambda function . This will bring you to the AWS Lambda console where you\u2019ll provide additional configuration properties 7. Scroll down to Application settings and provide below details ##### Fetch MSK Configuration To get some of the details you will have to navigate to MSK console and click on cluster name as MSKCluster-msk-labs-default In Cluster summary, Click on View client Information Copy any one of the broker-ids(connection string for the private endpoint) from Authentication type - Plaintext and paste it in the Lambda configuration \"KafkaEndpoint\" Note: You will get three endpoints for each of the brokers. You only need one broker endpoint for the following step. (Paste this in KafkaEndpoint) and click Done Click on Properties Tab and scroll down to Networking settings In Networking settings , under Primary VPC configuration look for Subnets and Security groups applied. Copy security-group-id and one subnet-id , paste them in the below configuration accordingly KafkaEndpoint: <paste the broker-id here> LambdaFunctionName: msk-athena-lambda-function SecurityGroupIds: <paste the security-group-id here> SpillBucket: msk-athena-bucket-<paste the AWS-Account-Number> SpillPrefix: msk-athena-spill SubnetIds: <paste the subnet-id here > 8. Click on I acknowledge that this app creates custom IAM roles and resource policies . 9. Click Deploy (wait for a minute to auto-refresh the page) 10. Close the Lambda page and go back to previous tab (Athena Console - Enter data source details) 11. In Connection details, use the refresh button and choose Lambda function which we created in the previous step ( msk-athena-lambda-function ) 12. Click Next 13. Review the details and click Create data source","title":"2. Configure the Athena connector for MSK"},{"location":"day2/part5/athena/exercise/#3-run-queries-on-streaming-data-using-athena","text":"With your MSK data connector set up, you can now run SQL queries on the data. Let\u2019s explore a few use cases in more detail. Use case: interactive analysis If you want to run queries that aggregate, group, or filter your MSK data, you can run interactive queries using Athena. These queries will run against the current state of your Kafka topics at the time the query was submitted. Navigate to Athena Console Under Editor tab, in Data section, you will observe the following: 3. Choose msk from the drop down. 4. Choose customer_schema from the database Before running any queries, it may be helpful to validate the schema and data types available within your Kafka topics. To do this, run the DESCRIBE command on your Kafka topic, which appears in Athena as a table, as shown below. In this query, the orders table corresponds to the topic you specified in the Schema Registry customer_schema . DESCRIBE msk.customer_schema.orders Now that you know the contents of your topic, you can begin to develop analytical queries. A sample query for querying all data in a topic is: select * from msk.customer_schema.orders; You can proceed to next lab!","title":"3. Run queries on streaming data using Athena"},{"location":"day2/part5/overview/exercise/","text":"MSK Integration with Athena and Redshift \u00b6 Integrating MSK with Athena and Redshift helps in building real-time analytics solution on streaming data, enabling timely insights and data-driven decision-making. Amazon Athena provides serverless interactive queries on data stored in Amazon S3. By integrating MSK with Athena, you can directly query the data in yout Kafka topics, without the need for additional data movement or transformations. This simplifies the data processing pipeline and reduces latency in accessing and analyzing the data. Leran more about Amazon Athena MSK Connector . Amazon Redshift is a fully managed data warehousing service that offers high-performance analysis of large-scale data sets. By integrating MSK with Redshift, you can stream data from Kafka into Redshift for near-real-time analysis. This allows you to leverage Redshift's advanced anlaytics capabilities and perform complex queries on the streaming data. Learn more about Integrating MSK with Redshift .","title":"1 - Architecture Introduction"},{"location":"day2/part5/overview/exercise/#msk-integration-with-athena-and-redshift","text":"Integrating MSK with Athena and Redshift helps in building real-time analytics solution on streaming data, enabling timely insights and data-driven decision-making. Amazon Athena provides serverless interactive queries on data stored in Amazon S3. By integrating MSK with Athena, you can directly query the data in yout Kafka topics, without the need for additional data movement or transformations. This simplifies the data processing pipeline and reduces latency in accessing and analyzing the data. Leran more about Amazon Athena MSK Connector . Amazon Redshift is a fully managed data warehousing service that offers high-performance analysis of large-scale data sets. By integrating MSK with Redshift, you can stream data from Kafka into Redshift for near-real-time analysis. This allows you to leverage Redshift's advanced anlaytics capabilities and perform complex queries on the streaming data. Learn more about Integrating MSK with Redshift .","title":"MSK Integration with Athena and Redshift"},{"location":"day2/part5/redshift/exercise/","text":"MSK Integration with Redshift \u00b6 In this lab, we will analyze real-time streaming data in Amazon MSK with Amazon Redshift. Solution overview \u00b6 The purpose of Amazon Redshift streaming ingestion is to simplify the process for directly ingesting stream data from a streaming service into Amazon Redshift. This works with Amazon MSK and Amazon MSK Serverless. Amazon Redshift streaming ingestion removes the need to stage an Amazon MSK topic in Amazon S3 before ingesting the stream data into Amazon Redshift. On a technical level, streaming ingestion, from Amazon Managed Streaming for Apache Kafka, provides low-latency, high-speed ingestion of stream or topic data into an Amazon Redshift materialized view. Following setup, using materialized view refresh, you can take in large data volumes. Set up Amazon Redshift streaming ingestion for Amazon MSK by performing the following steps: Create an external schema that maps to the streaming data source. Create a materialized view that references the external schema. Streaming ingestion and Amazon Redshift Serverless - The configuration steps in this topic apply both to provisioned Amazon Redshift clusters and to Amazon Redshift Serverless. For more information, see Streaming ingestion considerations. Fetching IAM Role info \u00b6 Navigate to Redshift console 2. Scroll down to Associated IAM roles and click on the role msk-redshift-role 3. Copy the ARN from the Summary section. (Paste it in a note-pad) Fetching MSK cluster info \u00b6 Navigate to MSK Console Click on the Cluster name - MSKCluster-msk-labs-default Copy the ARN from the Cluster summary section. (Paste it in a note-pad) Create an external schema \u00b6 Navigate to Redshift query editor v2 2. In the left pane, choose the redshift cluster: redshift-cluster-1 3. Once it is explanded, go to editor section and create an external schema to map to the Amazon MSK cluster. CREATE EXTERNAL SCHEMA MySchema FROM MSK IAM_ROLE { default | 'iam-role-arn' } AUTHENTICATION { none | iam } CLUSTER_ARN 'msk-cluster-arn'; In the FROM clause , Amazon MSK denotes that the schema maps data from Managed Kafka Services . Streaming ingestion for Amazon MSK provides the following authentication types , when you create the external schema : none \u2013 Specifies that there is no authentication step . iam \u2013 Specifies IAM authentication . When you choose this , make sure that the IAM role has permissions for IAM authentication . Additional Amazon MSK authentication methods , such as TLS authentication or a username and password , aren ' t supported for streaming ingestion. CLUSTER_ARN specifies the Amazon MSK cluster that you \u2019 re streaming from . Final Command: CREATE EXTERNAL SCHEMA msk_schema FROM MSK IAM_ROLE 'arn:aws:iam::< AWS_Account_Number >:role/msk-redshift-role' AUTHENTICATION none CLUSTER_ARN 'arn:aws:kafka:us-east-1:< AWS_Account_Number >:cluster/MSKCluster-msk-labs-default/0ae312ea-a86b-44dd-xxxxxxxxxxxxxxxx' ; Once you execute this command you should get Returned rows as 0 ( RequestID should appear in green) Create a Materialized view \u00b6 Navigate to Redshift query editor v2 In the left pane, choose the redshift cluster: redshift-cluster-1 Once it is explanded, go to editor section and create a Materialized view to map topic to a queryable MV. Materialized view command : CREATE MATERIALIZED VIEW msk_topic_orders AUTO REFRESH YES AS SELECT \"kafka_partition\", \"kafka_offset\", \"kafka_timestamp_type\", \"kafka_timestamp\", \"kafka_key\", JSON_PARSE(\"kafka_value\") as Data, \"kafka_headers\" FROM msk_schema.orders; -> Once you execute this command you should get Returned rows as 0 ( RequestID should appear in green) 4. Refresh the view, which invokes Amazon Redshift to read from the topic and load data into the materialized view. REFRESH MATERIALIZED VIEW msk_topic_orders; 5. Query data in the materialized view: select data from msk_topic_orders; -> The materialized view is updated directly from the topic when REFRESH is run. You create a materialized view that maps to the Kafka topic data source. You can perform filtering and aggregations on the data as part of the materialized view definition. Your streaming ingestion materialized view (base materialized view) can reference only one Kafka topic, but you can create additional materialized views that join with the base materialized view and with other materialized views or tables. You have reached the end of workshop!","title":"4 - Integration with Redshift"},{"location":"day2/part5/redshift/exercise/#msk-integration-with-redshift","text":"In this lab, we will analyze real-time streaming data in Amazon MSK with Amazon Redshift.","title":"MSK Integration with Redshift"},{"location":"day2/part5/redshift/exercise/#solution-overview","text":"The purpose of Amazon Redshift streaming ingestion is to simplify the process for directly ingesting stream data from a streaming service into Amazon Redshift. This works with Amazon MSK and Amazon MSK Serverless. Amazon Redshift streaming ingestion removes the need to stage an Amazon MSK topic in Amazon S3 before ingesting the stream data into Amazon Redshift. On a technical level, streaming ingestion, from Amazon Managed Streaming for Apache Kafka, provides low-latency, high-speed ingestion of stream or topic data into an Amazon Redshift materialized view. Following setup, using materialized view refresh, you can take in large data volumes. Set up Amazon Redshift streaming ingestion for Amazon MSK by performing the following steps: Create an external schema that maps to the streaming data source. Create a materialized view that references the external schema. Streaming ingestion and Amazon Redshift Serverless - The configuration steps in this topic apply both to provisioned Amazon Redshift clusters and to Amazon Redshift Serverless. For more information, see Streaming ingestion considerations.","title":"Solution overview"},{"location":"day2/part5/redshift/exercise/#fetching-iam-role-info","text":"Navigate to Redshift console 2. Scroll down to Associated IAM roles and click on the role msk-redshift-role 3. Copy the ARN from the Summary section. (Paste it in a note-pad)","title":"Fetching IAM Role info"},{"location":"day2/part5/redshift/exercise/#fetching-msk-cluster-info","text":"Navigate to MSK Console Click on the Cluster name - MSKCluster-msk-labs-default Copy the ARN from the Cluster summary section. (Paste it in a note-pad)","title":"Fetching MSK cluster info"},{"location":"day2/part5/redshift/exercise/#create-an-external-schema","text":"Navigate to Redshift query editor v2 2. In the left pane, choose the redshift cluster: redshift-cluster-1 3. Once it is explanded, go to editor section and create an external schema to map to the Amazon MSK cluster. CREATE EXTERNAL SCHEMA MySchema FROM MSK IAM_ROLE { default | 'iam-role-arn' } AUTHENTICATION { none | iam } CLUSTER_ARN 'msk-cluster-arn'; In the FROM clause , Amazon MSK denotes that the schema maps data from Managed Kafka Services . Streaming ingestion for Amazon MSK provides the following authentication types , when you create the external schema : none \u2013 Specifies that there is no authentication step . iam \u2013 Specifies IAM authentication . When you choose this , make sure that the IAM role has permissions for IAM authentication . Additional Amazon MSK authentication methods , such as TLS authentication or a username and password , aren ' t supported for streaming ingestion. CLUSTER_ARN specifies the Amazon MSK cluster that you \u2019 re streaming from . Final Command: CREATE EXTERNAL SCHEMA msk_schema FROM MSK IAM_ROLE 'arn:aws:iam::< AWS_Account_Number >:role/msk-redshift-role' AUTHENTICATION none CLUSTER_ARN 'arn:aws:kafka:us-east-1:< AWS_Account_Number >:cluster/MSKCluster-msk-labs-default/0ae312ea-a86b-44dd-xxxxxxxxxxxxxxxx' ; Once you execute this command you should get Returned rows as 0 ( RequestID should appear in green)","title":"Create an external schema"},{"location":"day2/part5/redshift/exercise/#create-a-materialized-view","text":"Navigate to Redshift query editor v2 In the left pane, choose the redshift cluster: redshift-cluster-1 Once it is explanded, go to editor section and create a Materialized view to map topic to a queryable MV. Materialized view command : CREATE MATERIALIZED VIEW msk_topic_orders AUTO REFRESH YES AS SELECT \"kafka_partition\", \"kafka_offset\", \"kafka_timestamp_type\", \"kafka_timestamp\", \"kafka_key\", JSON_PARSE(\"kafka_value\") as Data, \"kafka_headers\" FROM msk_schema.orders; -> Once you execute this command you should get Returned rows as 0 ( RequestID should appear in green) 4. Refresh the view, which invokes Amazon Redshift to read from the topic and load data into the materialized view. REFRESH MATERIALIZED VIEW msk_topic_orders; 5. Query data in the materialized view: select data from msk_topic_orders; -> The materialized view is updated directly from the topic when REFRESH is run. You create a materialized view that maps to the Kafka topic data source. You can perform filtering and aggregations on the data as part of the materialized view definition. Your streaming ingestion materialized view (base materialized view) can reference only one Kafka topic, but you can create additional materialized views that join with the base materialized view and with other materialized views or tables. You have reached the end of workshop!","title":"Create a Materialized view"}]}